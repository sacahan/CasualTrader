{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ .env 已載入: /Users/sacahan/Documents/workspace/CasualTrader/backend/.env\n",
      "✓ OPENAI_API_KEY: sk-proj-T_8ONKeh5L1O...l90oicgENtP8nRj3ljgA\n",
      "✓ GITHUB_PERSONAL_ACCESS_TOKEN: ghp_HJYjAlbBoxrUSnE0...9nt7LU6xZnoIjQ2gt793\n",
      "✓ TAVILY_API_KEY: tvly-dev-ePjxQERPzxI...Jr3TphaFNjo6Km737Hqc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# 找到 .env 檔案\n",
    "env_file = Path.cwd().parent.parent / \".env\"\n",
    "if not env_file.exists():\n",
    "    env_file = Path.home() / \"Documents/workspace/CasualTrader/backend/.env\"\n",
    "\n",
    "# 讀取並設定環境變數\n",
    "if env_file.exists():\n",
    "    env_vars = dotenv_values(env_file)\n",
    "    for key, value in env_vars.items():\n",
    "        os.environ[key] = value.strip('\"').strip(\"'\") if value else \"\"\n",
    "\n",
    "# 取得 API Key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GITHUB_PERSONAL_ACCESS_TOKEN = os.getenv(\"GITHUB_PERSONAL_ACCESS_TOKEN\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "print(f\"✓ .env 已載入: {env_file}\")\n",
    "print(f\"✓ OPENAI_API_KEY: {OPENAI_API_KEY[:20]}...{OPENAI_API_KEY[-20:]}\" if OPENAI_API_KEY else \"✗ 未設定\")\n",
    "print(f\"✓ GITHUB_PERSONAL_ACCESS_TOKEN: {GITHUB_PERSONAL_ACCESS_TOKEN[:20]}...{GITHUB_PERSONAL_ACCESS_TOKEN[-20:]}\" if GITHUB_PERSONAL_ACCESS_TOKEN else \"✗ 未設定\")\n",
    "print(f\"✓ TAVILY_API_KEY: {TAVILY_API_KEY[:20]}...{TAVILY_API_KEY[-20:]}\" if TAVILY_API_KEY else \"✗ 未設定\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: LiteLLM GitHub Copilot - Authentication & Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion, acompletion\n",
    "import asyncio\n",
    "\n",
    "# Test 1: Non-streaming completion with GitHub Copilot\n",
    "# Note: On first run, LiteLLM will prompt with OAuth device code\n",
    "\n",
    "def test_github_copilot_basic():\n",
    "    \"\"\"\n",
    "    Test basic GitHub Copilot completion via LiteLLM.\n",
    "    \n",
    "    First execution triggers OAuth device flow:\n",
    "    - LiteLLM displays a device code and verification URL\n",
    "    - Visit the URL and enter the code\n",
    "    - Authenticate with your GitHub account\n",
    "    - OAuth tokens are cached for future use\n",
    "    \"\"\"\n",
    "\n",
    "    model = \"github_copilot/gemini-2.5-pro\"\n",
    "\n",
    "    print(\"\\n=== Test 1: Basic Completion (Non-Streaming) ===\")\n",
    "    print(f\"Model: {model}\")\n",
    "    print(\"Status: Awaiting response...\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = completion(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Write a Python function to calculate the Fibonacci sequence up to n numbers, just python code without any explanation\",\n",
    "                }\n",
    "            ],\n",
    "            # temperature=0.7,\n",
    "            max_tokens=500,\n",
    "            extra_headers={\n",
    "                \"editor-version\": \"vscode/1.85.1\",\n",
    "                \"Copilot-Integration-Id\": \"vscode-chat\",\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        # print(\"Response received:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "        print(\"-\" * 50)\n",
    "        # print(f\"\\nUsage: {response.get('usage', 'N/A')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {type(e).__name__}\")\n",
    "        print(f\"Message: {str(e)}\")\n",
    "        print(\"\\nNote: This is expected if:\")\n",
    "        print(\"  1. OAuth authentication is needed (first run)\")\n",
    "        print(\"  2. GitHub Copilot subscription is not active\")\n",
    "        print(\"  3. Network connectivity issue\")\n",
    "\n",
    "# Run the test\n",
    "test_github_copilot_basic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: LiteLLM GitHub Copilot - Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion, acompletion\n",
    "\n",
    "\n",
    "def test_github_copilot_streaming():\n",
    "    \"\"\"\n",
    "    Test streaming responses from GitHub Copilot via LiteLLM.\n",
    "    \n",
    "    Streaming is useful for real-time feedback in UI applications.\n",
    "    \"\"\"\n",
    "\n",
    "    model = \"github_copilot/gpt-5-mini\"\n",
    "\n",
    "    print(\"\\n=== Test 2: Streaming Completion ===\")\n",
    "    print(f\"Model: {model}\")\n",
    "    print(\"Status: Streaming response...\\n\")\n",
    "    \n",
    "    try:\n",
    "        stream = completion(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Explain async/await in Python with a simple example\"\n",
    "                }\n",
    "            ],\n",
    "            stream=True,\n",
    "            # temperature=0.8,\n",
    "            max_tokens=300,\n",
    "            extra_headers={\n",
    "                \"editor-version\": \"vscode/1.85.1\",\n",
    "                \"Copilot-Integration-Id\": \"vscode-chat\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(\"Streaming response:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        full_response = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content is not None:\n",
    "                content = chunk.choices[0].delta.content\n",
    "                print(content, end=\"\", flush=True)\n",
    "                full_response += content\n",
    "        \n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(f\"\\nTotal characters received: {len(full_response)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {type(e).__name__}: {str(e)}\")\n",
    "\n",
    "# Run the test\n",
    "test_github_copilot_streaming()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Example - Using GitHub Copilot with Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example configuration for using GitHub Copilot with OpenAI Agents\n",
    "\n",
    "from agents import Agent, Runner, function_tool, ModelSettings, gen_trace_id, trace\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "import json\n",
    "\n",
    "\n",
    "model = \"github_copilot/gpt-5-mini\"\n",
    "print(f\"\\nUsing model: {model}\")\n",
    "\n",
    "model_settings = ModelSettings(\n",
    "    include_usage=True,\n",
    "    extra_headers={\n",
    "        \"editor-version\": \"vscode/1.85.1\",\n",
    "        \"Copilot-Integration-Id\": \"vscode-chat\",\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str):\n",
    "    print(f\"[debug] getting weather for {city}\")\n",
    "    return f\"The weather in {city} is rainy.\"\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You only respond in haikus.\",\n",
    "    # model=LitellmModel(model=model, api_key=GITHUB_PERSONAL_ACCESS_TOKEN),\n",
    "    model=LitellmModel(model=model),\n",
    "    tools=[get_weather],\n",
    "    model_settings=model_settings,\n",
    ")\n",
    "\n",
    "trace_id = gen_trace_id()\n",
    "with trace(workflow_name=\"lab_agent\", trace_id=trace_id):\n",
    "    result = await Runner.run(agent, \"What's the weather in Tokyo?\")\n",
    "    print(json.dumps(result.final_output, indent=2))\n",
    "\n",
    "print(\"\\n=== GitHub Copilot + Agents Configuration ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Agent with MCP Tool Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model: github_copilot/claude-haiku-4.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:04:31 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - \n",
      "\n",
      "\u001b[92m19:04:31 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m19:04:31 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - \u001b[92mlitellm.acompletion(model='github_copilot/claude-haiku-4.5', messages=[{'content': 'You using web search to answer user queries.', 'role': 'system'}, {'role': 'user', 'content': '明天東京的天氣如何？ (目前時間：2025-10-30 19:04)'}], tools=[{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}], temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, max_tokens=None, tool_choice='required', response_format=None, parallel_tool_calls=None, stream=False, stream_options=None, reasoning_effort=None, top_logprobs=None, extra_headers={'User-Agent': 'Agents/Python 0.4.0', 'editor-version': 'vscode/1.85.1', 'Copilot-Integration-Id': 'vscode-chat'}, api_key=None, base_url=None)\u001b[0m\n",
      "\u001b[92m19:04:31 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - \n",
      "\n",
      "\u001b[92m19:04:31 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:486 - self.optional_params: {}\n",
      "\u001b[92m19:04:31 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None\n",
      "\u001b[92m19:04:31 - LiteLLM:DEBUG\u001b[0m: main.py:493 - 🔄 NO SHARED SESSION: acompletion called without shared_session\n",
      "\u001b[92m19:04:31 - LiteLLM:WARNING\u001b[0m: authenticator.py:99 - API key expired, refreshing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tavily_mcp server initialized\n",
      "message: 明天東京的天氣如何？ (目前時間：2025-10-30 19:04)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: utils.py:2111 - Model not found or error in checking supports_reasoning support. You passed model=claude-haiku-4.5, custom_llm_provider=None. Error: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=claude-haiku-4.5\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "\u001b[92m19:04:32 - LiteLLM:INFO\u001b[0m: utils.py:3388 - \n",
      "LiteLLM completion() model= claude-haiku-4.5; provider = github_copilot\n",
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: utils.py:3391 - \n",
      "LiteLLM: Params passed to completion() {'model': 'claude-haiku-4.5', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': False, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'github_copilot', 'response_format': None, 'seed': None, 'tools': [{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}], 'tool_choice': 'required', 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': 'You using web search to answer user queries.', 'role': 'system'}, {'role': 'user', 'content': '明天東京的天氣如何？ (目前時間：2025-10-30 19:04)'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}\n",
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: utils.py:3394 - \n",
      "LiteLLM: Non-Default params passed to completion() {'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}], 'tool_choice': 'required'}\n",
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - Final returned optional params: {'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}], 'tool_choice': 'required', 'extra_body': {}}\n",
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:486 - self.optional_params: {'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}], 'tool_choice': 'required', 'extra_body': {}}\n",
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: main.py:908 - Error getting model info: This model isn't mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: http_handler.py:619 - Using AiohttpTransport...\n",
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: http_handler.py:677 - Creating AiohttpTransport...\n",
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: http_handler.py:687 - NEW SESSION: Creating new ClientSession (no shared session provided)\n",
      "\u001b[92m19:04:32 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:954 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.individual.githubcopilot.com \\\n",
      "-H 'Authorization: Be****e8' \\\n",
      "-d '{'model': 'claude-haiku-4.5', 'messages': [{'content': 'You using web search to answer user queries.', 'role': 'assistant'}, {'role': 'user', 'content': '明天東京的天氣如何？ (目前時間：2025-10-30 19:04)'}], 'tools': [{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}], 'tool_choice': 'required', 'extra_body': {}, 'extra_headers': {'User-Agent': 'Agents/Python 0.4.0', 'editor-version': 'vscode/1.85.1', 'Copilot-Integration-Id': 'vscode-chat'}}'\n",
      "\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1027 - RAW RESPONSE:\n",
      "{\"id\": \"msg_01A6erRR76BoAsAvCKzA5bGK\", \"choices\": [{\"finish_reason\": \"tool_calls\", \"index\": null, \"logprobs\": null, \"message\": {\"content\": null, \"refusal\": null, \"role\": \"assistant\", \"annotations\": null, \"audio\": null, \"function_call\": null, \"tool_calls\": [{\"id\": \"toolu_01VDw7Eb9c1fstKVyyLk9abY\", \"function\": {\"arguments\": \"{\\\"query\\\":\\\"\\u660e\\u5929\\u6771\\u4eac\\u5929\\u6c23 2025\\u5e7410\\u670831\\u65e5\\\",\\\"country\\\":\\\"japan\\\",\\\"max_results\\\":10}\", \"name\": \"tavily-search\"}, \"type\": \"function\"}]}}], \"created\": 1761822274, \"model\": \"claude-haiku-4.5\", \"object\": null, \"service_tier\": null, \"system_fingerprint\": null, \"usage\": {\"completion_tokens\": 89, \"prompt_tokens\": 3264, \"total_tokens\": 3353, \"completion_tokens_details\": null, \"prompt_tokens_details\": {\"audio_tokens\": null, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2918 - Filtered callbacks: []\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:775 - selected model name for cost calculation: github_copilot/claude-haiku-4.5\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:1048 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=github_copilot/claude-haiku-4.5 - This model isn't mapped yet. model=github_copilot/claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:775 - selected model name for cost calculation: github_copilot/claude-haiku-4.5\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:1048 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=github_copilot/claude-haiku-4.5 - This model isn't mapped yet. model=github_copilot/claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1322 - response_cost_failure_debug_information: {'error_str': \"This model isn't mapped yet. model=github_copilot/claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\", 'traceback_str': 'Traceback (most recent call last):\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 4851, in _get_model_info_helper\\n    raise ValueError(\\nValueError: This model isn\\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/litellm_logging.py\", line 1304, in _response_cost_calculator\\n    response_cost = litellm.response_cost_calculator(\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1166, in response_cost_calculator\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1149, in response_cost_calculator\\n    response_cost = completion_cost(\\n                    ^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1061, in completion_cost\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1054, in completion_cost\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 993, in completion_cost\\n    ) = cost_per_token(\\n        ^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 368, in cost_per_token\\n    model_info = _cached_get_model_info_helper(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 4703, in _cached_get_model_info_helper\\n    return _get_model_info_helper(model=model, custom_llm_provider=custom_llm_provider)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 5004, in _get_model_info_helper\\n    raise Exception(\\nException: This model isn\\'t mapped yet. model=github_copilot/claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\\n', 'model': 'github_copilot/claude-haiku-4.5', 'cache_hit': False, 'custom_llm_provider': 'github_copilot', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - Async Wrapper: Completed Call, calling async_success_handler: <bound method Logging.async_success_handler of <litellm.litellm_core_utils.litellm_logging.Logging object at 0x13e444320>>\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2918 - Filtered callbacks: []\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - Logging Details LiteLLM-Async Success Call, cache_hit=None\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:2111 - Model not found or error in checking supports_reasoning support. You passed model=claude-haiku-4.5, custom_llm_provider=github_copilot. Error: This model isn't mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:4169 - Model=github_copilot/claude-haiku-4.5 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - Async success callbacks: Got a complete streaming response\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:775 - selected model name for cost calculation: github_copilot/claude-haiku-4.5\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:1048 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=github_copilot/claude-haiku-4.5 - This model isn't mapped yet. model=github_copilot/claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:775 - selected model name for cost calculation: claude-haiku-4.5\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:1048 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=claude-haiku-4.5 - This model isn't mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1322 - response_cost_failure_debug_information: {'error_str': \"This model isn't mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\", 'traceback_str': 'Traceback (most recent call last):\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 4851, in _get_model_info_helper\\n    raise ValueError(\\nValueError: This model isn\\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/litellm_logging.py\", line 1304, in _response_cost_calculator\\n    response_cost = litellm.response_cost_calculator(\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1166, in response_cost_calculator\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1149, in response_cost_calculator\\n    response_cost = completion_cost(\\n                    ^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1061, in completion_cost\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1054, in completion_cost\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 993, in completion_cost\\n    ) = cost_per_token(\\n        ^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 368, in cost_per_token\\n    model_info = _cached_get_model_info_helper(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 4703, in _cached_get_model_info_helper\\n    return _get_model_info_helper(model=model, custom_llm_provider=custom_llm_provider)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 5004, in _get_model_info_helper\\n    raise Exception(\\nException: This model isn\\'t mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\\n', 'model': 'claude-haiku-4.5', 'cache_hit': None, 'custom_llm_provider': 'github_copilot', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2255 - Model=claude-haiku-4.5; cost=None\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:2111 - Model not found or error in checking supports_reasoning support. You passed model=claude-haiku-4.5, custom_llm_provider=github_copilot. Error: This model isn't mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:34 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:4169 - Model=github_copilot/claude-haiku-4.5 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - \n",
      "\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - \u001b[92mlitellm.acompletion(model='github_copilot/claude-haiku-4.5', messages=[{'content': 'You using web search to answer user queries.', 'role': 'system'}, {'role': 'user', 'content': '明天東京的天氣如何？ (目前時間：2025-10-30 19:04)'}, {'role': 'assistant', 'tool_calls': [{'id': 'toolu_01VDw7Eb9c1fstKVyyLk9abY', 'type': 'function', 'function': {'name': 'tavily-search', 'arguments': '{\"query\":\"明天東京天氣 2025年10月31日\",\"country\":\"japan\",\"max_results\":10}'}}]}, {'role': 'tool', 'tool_call_id': 'toolu_01VDw7Eb9c1fstKVyyLk9abY', 'content': '{\"type\":\"text\",\"text\":\"Detailed Results:\\\\n\\\\nTitle: 東京（東京都) 2025年10月（日ごとの値） 主な要素\\\\nURL: https://www.data.jma.go.jp/stats/etrn/view/daily_s1.php?prec_no=44&block_no=47662&year=2025&month=10&day=&view=p1\\\\nContent: | 日 | 気圧(hPa) | 降水量(mm) | 気温(℃) | 湿度(％) | 風向・風速(m/s) | 日照 時間 (h) | 雪(cm) | 天気概況 | | 平均 | 平均 | 合計 | 最大 | 平均 | 最高 | 最低 | 平均 | 最小 | 平均 風速 | 最大風速 | 最大瞬間風速 | 降雪 | 最深積雪 | 昼 (06:00-18:00) | 夜 (18:00-翌日06:00) | | 1時間 | 10分間 | 風速 | 風向 | 風速 | 風向 | 合計 | 値 | | 1 | 1009.7 | 1012.5 | 4.5 | 1.0 | 0.5 | 20.5 | 23.6 | 18.3 | 93 | 73 | 2.1 | 5.6 | 北西 | 8.2 | 北西 | 0.0 | -- | -- | 雨 | 晴一時曇 |\\\\n\\\\nTitle: 東京都 2025年10月（日ごとの値） 最高気温（℃）\\\\nURL: https://www.data.jma.go.jp/stats/etrn/view/daily_h1.php?prec_no=44&block_no=00&year=2025&month=10&day=&view=p3\\\\nContent: * Other Languages * ENGLISH * ホーム * 防災情報 * 各種データ・資料 * 地域の情報 * 知識・解説 * 各種申請・ご案内 * ホーム\\xa0> * 各種データ・資料\\xa0> * 過去の気象データ検索\\xa0> * 日ごとの値 # 日ごとの値 ### 東京都\\u30002025年10月（日ごとの値）\\u3000最高気温（℃） | 日 | 小河内 | 八王子 | 東京\\\\\\\\* | 江戸川臨海 | 羽田 | 大島\\\\\\\\* | 三宅島\\\\\\\\* | 八丈島\\\\\\\\* | 青梅 | 練馬 | 府中 | 父島\\\\\\\\* | 大島北ノ山 | 八重見ヶ原 | 三宅坪田 | 新島 | 神津島 | 南鳥島\\\\\\\\* | * 値欄の記号の説明 * アスタリスク(\\\\\\\\*)が付いた地点は地上気象観測地点(気象台・測候所・特別地域気象観測所等)です。 * アスタリスクの付いていない地点はアメダス地点です。2021年3月2日より、アメダスの日照時間は「推計気象分布（日照時間）」から得る推計値となりましたので、日照計による観測値と単純比較できません。詳しくは要素ごとの値の補足説明をご覧ください。 | * 利用される方へ | * よくある質問（FAQ） | * 気象観測統計の解説 | * 年・季節・各月の天候 | このページのトップへ\\\\n\\\\nTitle: 東京, 東京都, 日本の月間予報 | AccuWeather\\\\nURL: https://www.accuweather.com/ja/jp/tokyo/226396/october-weather/226396\\\\nContent: 戻る  # 東京, 東京都 55°F  55° 東京, 東京都の天気 今日 WinterCast ローカル{stormName}トラッカー 毎時 毎日 レーダー MinuteCast® 月間 大気質 健康・アクティビティ ### ハリケーン ### 悪天候 ### レーダー&地図 ### ビデオ 今日   毎時   毎日   レーダー   MinuteCast®  ## 月間  大気質   健康・アクティビティ ## 10月 1月   2月   3月   4月   5月   6月   7月   8月   9月   10月   11月   12月 ## 毎日 84° 69° 29 88° 76° 30 83° 72° 1 74° 66° 2 82° 63° 3 79° 67° 4 77° 69° 5 84° 67° 6 85° 72° 7 77° 68° 8 83° 67° 9 76° 65° 10 76° 63° 11 69° 61° 12 75° 61° 13 ### 11月 2025 ### 12月 2025 ### 1月 2026 ### ハリケーン ### 悪天候 ### レーダー&地図 ### ビデオ 世界 アジア 日本 東京都 東京 * 八王子市, 東京都\\\\n\\\\nTitle: 10月31日(木) 東京都の天気\\\\nURL: https://weathernews.jp/news/202410/310500tokyo/\\\\nContent: 明後日31日(金)は太平洋側で雨雲発達 三連休初日は北日本で風雨強まる · 明日10月30日(木)の天気予報 全国的に晴れる所が多い 朝と昼間の気温差大 · 10月30\\\\n\\\\nTitle: 東京都の過去の天気(実況天気・2025年10月)\\\\nURL: https://tenki.jp/past/2025/10/weather/3/16/\\\\nContent: tenki.jpトップ｜ サイトマップ｜ ヘルプ # tenki.jp ## 東京都の過去の天気 翌月 前月   09月 * 2015年 * 2016年 * 2017年 * 2018年 * 2019年 * 2020年 * 2021年 * 2022年 * 1月 * 2月 * 3月 * 4月 * 5月 * 6月 * 7月 * 8月 * 9月 * 10月 * 11月 * 12月 * 雨雲レーダー[東京都 ： 伊豆諸島 ] * アメダス[気温 ：降水量 ：風向・風速 ：日照時間 ：積雪深 ] * 実況天気 [東京都心(大手町)： 大島： 三宅島： 八丈島： 父島： 南鳥島 ] | 日 | 月 | 火 | 水 | 木 | 金 | 土 | * ツイート%20-%20tenki.jp%20%40tenkijp&count=horizontal&lang=ja) ### 東京の過去天気(実況天気)(2025年10月) | 東京都 | * 東京都心(大手町) * 大島 * 三宅島 * 八丈島 * 父島 * 南鳥島 | * アメダス) ### 今日の天気 26日07:00発表 * 東京都(千代田区) tenki.jp公式SNS tenki.jp公式アプリ * tenki.jp * tenki.jp 登山天気\\\\n\\\\nTitle: 東京都心(大手町)(東京都)の過去の天気 2025年10月30日現在\\\\nURL: https://tenki.jp/past/2025/10/weather/3/16/47662/\\\\nContent: # tenki.jp ## 東京都心(大手町)(東京都)の過去の天気 * 雨雲レーダー[東京都 ： 伊豆諸島 ] * アメダス[気温 ： 降水量 ： 風向・風速 ： 日照時間 ： 積雪深 ] | 日 | 月 | 火 | 水 | 木 | 金 | 土 | | 12   曇  23.8 /15.9 | 13   曇のち晴  25.2 /19.8 | 14   曇  21.3 /17.6 | 15   雨のち曇  20.3 /15.2 | 16   雨  20.7 /15.8 | 17   晴  25.1 /16.7 | 18   曇のち晴  25.9 /15.5 | | 19   曇のち雨  24.5 /19.5 | 20   雨のち曇  19.7 /15.1 | 21   曇一時雨  17.2 /13.9 | 22   雨  15.4 /11.5 | 23   曇  17.9 /11.0 | 24   曇のち雨  16.9 /12.0 | 25   雨  13.5 /12.0 | tenki.jp公式SNS tenki.jp公式アプリ * tenki.jp * tenki.jp 登山天気\\\\n\\\\nTitle: 東京の天気・気温：今日・明日と14日間(2週間)の1時間ごと ...\\\\nURL: https://www.toshin.com/weather/forecast90days?id=56681\\\\nContent: 11月3日(月) 11月10日(月) 20℃ 12℃ 18℃ 11℃ 18℃ 12℃ 19℃ 11℃ 18℃ 11℃ 11月17日(月) 19℃ 10℃ 19℃ 10℃ 16℃ 11℃ 18℃ 11℃ 19℃ 11℃ 18℃ 9℃ 14℃ 7℃ 11月24日(月) 14℃ 9℃ 17℃ 9℃ 15℃ 9℃ 15℃ 9℃ 15℃ 9℃ 14℃ 9℃ 14℃ 9℃ 12月1日(月) 13℃ 8℃ 14℃ 6℃ 12℃ 4℃ 12℃ 6℃ 14℃ 8℃ 16℃ 5℃ 15℃ 6℃ 12月8日(月) 16℃ 4℃ 13℃ 4℃ 13℃ 3℃ 12℃ 4℃ 13℃ 3℃ 12℃ 7℃ 11℃ 7℃ 12月15日(月) 11℃ 7℃ 12℃ 8℃ 11℃ 6℃ 11℃ 6℃ 10℃ 6℃ 11℃ 7℃ 12℃ 7℃ 12月22日(月) 11℃ 7℃ 11℃ 6℃ 11℃ 7℃ 11℃ 6℃ 11℃ 6℃ 11℃ 5℃ 9℃ 4℃ 12月29日(月) 10℃ 6℃ 11℃ 5℃ 10℃ 5℃ 11℃ 5℃ 11℃ 5℃ 10℃ 5℃ 11℃ 5℃ 1月5日(月) 10℃ 5℃\\\\n\\\\nTitle: 東京の天気・気温：今日・明日と14日間(2週間)の1時間ごと ...\\\\nURL: https://www.toshin.com/weather/detail?id=66124\\\\nContent: Home  >  東京都  >  千代田区  >  東京  >  14日間(2週間)の1時間ごとの天気予報 天気 天気 風速(m/s) 天気 風速(m/s) | 0時 | 1時 | 2時 | 3時 | 4時 | 5時 | 6時 | 7時 | 8時 | 9時 | 10時 | 11時 | 12時 | 13時 | 14時 | 15時 | 16時 | 17時 | 18時 | 19時 | 20時 | 21時 | 22時 | 23時 | 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 小金井公園(東京都) 遠賀川(福岡県) 万博記念公園(大阪府) 乗鞍岳(岐阜県) 磐梯吾妻スカイライン(福島県) リゾナーレ八ヶ岳(山梨県) 二子玉川ライズ(東京都) 志摩スペイン村(三重県) むさしの村(埼玉県) 富士急ハイランド(山梨県) 大阪 天気 横浜 天気 札幌 天気 名古屋 天気 東京 天気 東京ディズニーランド ユニバーサルスタジオ・ジャパン 上高地 小金井公園(東京都) 遠賀川(福岡県) 万博記念公園(大阪府) 乗鞍岳(岐阜県) 磐梯吾妻スカイライン(福島県) リゾナーレ八ヶ岳(山梨県) 二子玉川ライズ(東京都) 志摩スペイン村(三重県) むさしの村(埼玉県) 富士急ハイランド(山梨県)\\\\n\\\\nTitle: 30日（今天）\\\\nURL: https://www.weather.com.cn/weather/103010100.shtml\\\\nContent: 首页 预报 预警 雷达 云图 天气地图 专业产品 资讯 视频 节气 我的天空 更多 台风路径 空间天气 图片 专题 环境 旅游 碳中和 气象科普 一带一路 产创平台 国内) 本地) 国际) :   北京 上海 成都 杭州 南京 天津 深圳 重庆 西安 广州 青岛 武汉 热门景点 :   故宫 阳朔漓江 龙门石窟 野三坡 颐和园 九寨沟 东方明珠 凤凰古城 秦始皇陵 桃花源 选择省市 高球 :   佘山 春城湖畔 华彬庄园 观澜湖 依必朗 旭宝 博鳌 玉龙雪山 番禺南沙 东方明珠 <<返回 全国 河北下辖区域 周边城市 周边景点 本地乡镇 热门城市 :   曼谷 东京 首尔 吉隆坡 新加坡 巴黎 罗马 伦敦 雅典 柏林 纽约 温哥华 墨西哥城 哈瓦那 圣何塞 巴西利亚 布宜诺斯艾利斯 圣地亚哥 利马 基多 悉尼 墨尔本 惠灵顿 奥克兰 苏瓦 开罗 内罗毕 开普敦 维多利亚 拉巴特 选择洲际 :   亚洲 欧洲 北美洲 南美洲 非洲 大洋洲 *13℃* 15℃/*13℃* 18℃/*15℃* 21℃/*13℃* 19℃/*11℃* 16℃/*10℃* 17℃/*11℃* # 更多>>高清图集 # 热点 *视频* *图片* *文章*\\\\n\\\\nTitle: SMG - 澳門特別行政區政府地球物理氣象局\\\\nURL: https://www.smg.gov.mo/\\\\nContent: SMG - 澳門特別行政區政府地球物理氣象局 Image 1 Image 3 *    天氣警告   熱帶氣旋現時熱帶氣旋信號熱帶氣旋路徑資訊熱帶氣旋路徑圖之說明信號之意義信號圖示風暴潮現時風暴潮警告警告級別說明各警告級別下受影響的地區暴雨現時暴雨警告信號雷達圖信號之意義雷暴現時雷暴警告信號閃電圖信號之意義強烈季候風信號(黑球)現時強烈季候風信號信號之意義       *    資源共享   氣象報告下載天氣報告惡劣天氣報告海浪報告氣象資料查詢資料查詢申請監測資料氣候資料統計資料各類報告下載百年氣候惡劣天氣記錄熱帶氣旋警告風暴潮警告暴雨警告信號記錄雷暴警告信號強烈季候風信號(黑球)空氣質量報告輻射監測報告地震發佈紀錄       *    關於我們   氣象局簡介架構和法規國際合作監測網絡氣象局服務服務項目服務承諾資訊發佈途徑滿意度調查特別支援設施氣象局總部導覽氣象局面面觀參觀申請意見反饋網頁資料使用登記表聯絡我們聲明使用聲明私隱聲明其他連結特區政府氣象航空氣象空氣質量輻射地震潮汐       Image 4 2025年08月28日 星期四 乙巳蛇年 七月初六日 Image 5 Image 10 Image 11 Image 12 Image 13 2025年08月27日 星期三 乙巳蛇年 七月初五日 Image 14 6 km/h  *   Image 21 *   Image 22 *   Image 23 *   Image 24 *   Image 25 *   Image 26 溫度(℃) 溫度(℃)日高溫(℃)日低溫(℃)濕度(%)風速(km/h)陣風(km/h)風向每小時雨量每日總雨量水位監測空氣質量指數 Himawari (IR)衛星 Himawari (IR)衛星Himawari (VIS)衛星 氹仔 - 雷達塔(向北) 氹仔 - 雷達塔(向北)氹仔 - 雷達塔(向東北)氹仔 - 雷達塔(向南)氹仔 - 雷達塔(向西)澳門 - 松山(向北)澳門 - 松山(向東)澳門 - 松山(向南)澳門 - 松山(向西)澳門 - 外港路環 - 颱風委員會 Image 27 Image 29 70% - 95%  Image 30 Image 32 75% - 95%  Image 33 *   特別推送 2025-08-26 低壓區再現，本週後期天氣趨不穩 *   特別推送 2025-08-21 週末天氣酷熱 打風與否仍需視乎距離 關於我們  澳門特別行政區政府地球物理氣象局 電子郵箱： meteo@smg.gov.mo\",\"annotations\":null,\"meta\":null}'}], tools=[{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}], temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, max_tokens=None, tool_choice=None, response_format=None, parallel_tool_calls=None, stream=False, stream_options=None, reasoning_effort=None, top_logprobs=None, extra_headers={'User-Agent': 'Agents/Python 0.4.0', 'editor-version': 'vscode/1.85.1', 'Copilot-Integration-Id': 'vscode-chat'}, api_key=None, base_url=None)\u001b[0m\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - \n",
      "\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:486 - self.optional_params: {}\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: main.py:493 - 🔄 NO SHARED SESSION: acompletion called without shared_session\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: utils.py:2111 - Model not found or error in checking supports_reasoning support. You passed model=claude-haiku-4.5, custom_llm_provider=None. Error: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=claude-haiku-4.5\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "\u001b[92m19:04:36 - LiteLLM:INFO\u001b[0m: utils.py:3388 - \n",
      "LiteLLM completion() model= claude-haiku-4.5; provider = github_copilot\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: utils.py:3391 - \n",
      "LiteLLM: Params passed to completion() {'model': 'claude-haiku-4.5', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': False, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'github_copilot', 'response_format': None, 'seed': None, 'tools': [{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}], 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'content': 'You using web search to answer user queries.', 'role': 'system'}, {'role': 'user', 'content': '明天東京的天氣如何？ (目前時間：2025-10-30 19:04)'}, {'role': 'assistant', 'tool_calls': [{'id': 'toolu_01VDw7Eb9c1fstKVyyLk9abY', 'type': 'function', 'function': {'name': 'tavily-search', 'arguments': '{\"query\":\"明天東京天氣 2025年10月31日\",\"country\":\"japan\",\"max_results\":10}'}}]}, {'role': 'tool', 'tool_call_id': 'toolu_01VDw7Eb9c1fstKVyyLk9abY', 'content': '{\"type\":\"text\",\"text\":\"Detailed Results:\\\\n\\\\nTitle: 東京（東京都) 2025年10月（日ごとの値） 主な要素\\\\nURL: https://www.data.jma.go.jp/stats/etrn/view/daily_s1.php?prec_no=44&block_no=47662&year=2025&month=10&day=&view=p1\\\\nContent: | 日 | 気圧(hPa) | 降水量(mm) | 気温(℃) | 湿度(％) | 風向・風速(m/s) | 日照 時間 (h) | 雪(cm) | 天気概況 | | 平均 | 平均 | 合計 | 最大 | 平均 | 最高 | 最低 | 平均 | 最小 | 平均 風速 | 最大風速 | 最大瞬間風速 | 降雪 | 最深積雪 | 昼 (06:00-18:00) | 夜 (18:00-翌日06:00) | | 1時間 | 10分間 | 風速 | 風向 | 風速 | 風向 | 合計 | 値 | | 1 | 1009.7 | 1012.5 | 4.5 | 1.0 | 0.5 | 20.5 | 23.6 | 18.3 | 93 | 73 | 2.1 | 5.6 | 北西 | 8.2 | 北西 | 0.0 | -- | -- | 雨 | 晴一時曇 |\\\\n\\\\nTitle: 東京都 2025年10月（日ごとの値） 最高気温（℃）\\\\nURL: https://www.data.jma.go.jp/stats/etrn/view/daily_h1.php?prec_no=44&block_no=00&year=2025&month=10&day=&view=p3\\\\nContent: * Other Languages * ENGLISH * ホーム * 防災情報 * 各種データ・資料 * 地域の情報 * 知識・解説 * 各種申請・ご案内 * ホーム\\xa0> * 各種データ・資料\\xa0> * 過去の気象データ検索\\xa0> * 日ごとの値 # 日ごとの値 ### 東京都\\u30002025年10月（日ごとの値）\\u3000最高気温（℃） | 日 | 小河内 | 八王子 | 東京\\\\\\\\* | 江戸川臨海 | 羽田 | 大島\\\\\\\\* | 三宅島\\\\\\\\* | 八丈島\\\\\\\\* | 青梅 | 練馬 | 府中 | 父島\\\\\\\\* | 大島北ノ山 | 八重見ヶ原 | 三宅坪田 | 新島 | 神津島 | 南鳥島\\\\\\\\* | * 値欄の記号の説明 * アスタリスク(\\\\\\\\*)が付いた地点は地上気象観測地点(気象台・測候所・特別地域気象観測所等)です。 * アスタリスクの付いていない地点はアメダス地点です。2021年3月2日より、アメダスの日照時間は「推計気象分布（日照時間）」から得る推計値となりましたので、日照計による観測値と単純比較できません。詳しくは要素ごとの値の補足説明をご覧ください。 | * 利用される方へ | * よくある質問（FAQ） | * 気象観測統計の解説 | * 年・季節・各月の天候 | このページのトップへ\\\\n\\\\nTitle: 東京, 東京都, 日本の月間予報 | AccuWeather\\\\nURL: https://www.accuweather.com/ja/jp/tokyo/226396/october-weather/226396\\\\nContent: 戻る  # 東京, 東京都 55°F  55° 東京, 東京都の天気 今日 WinterCast ローカル{stormName}トラッカー 毎時 毎日 レーダー MinuteCast® 月間 大気質 健康・アクティビティ ### ハリケーン ### 悪天候 ### レーダー&地図 ### ビデオ 今日   毎時   毎日   レーダー   MinuteCast®  ## 月間  大気質   健康・アクティビティ ## 10月 1月   2月   3月   4月   5月   6月   7月   8月   9月   10月   11月   12月 ## 毎日 84° 69° 29 88° 76° 30 83° 72° 1 74° 66° 2 82° 63° 3 79° 67° 4 77° 69° 5 84° 67° 6 85° 72° 7 77° 68° 8 83° 67° 9 76° 65° 10 76° 63° 11 69° 61° 12 75° 61° 13 ### 11月 2025 ### 12月 2025 ### 1月 2026 ### ハリケーン ### 悪天候 ### レーダー&地図 ### ビデオ 世界 アジア 日本 東京都 東京 * 八王子市, 東京都\\\\n\\\\nTitle: 10月31日(木) 東京都の天気\\\\nURL: https://weathernews.jp/news/202410/310500tokyo/\\\\nContent: 明後日31日(金)は太平洋側で雨雲発達 三連休初日は北日本で風雨強まる · 明日10月30日(木)の天気予報 全国的に晴れる所が多い 朝と昼間の気温差大 · 10月30\\\\n\\\\nTitle: 東京都の過去の天気(実況天気・2025年10月)\\\\nURL: https://tenki.jp/past/2025/10/weather/3/16/\\\\nContent: tenki.jpトップ｜ サイトマップ｜ ヘルプ # tenki.jp ## 東京都の過去の天気 翌月 前月   09月 * 2015年 * 2016年 * 2017年 * 2018年 * 2019年 * 2020年 * 2021年 * 2022年 * 1月 * 2月 * 3月 * 4月 * 5月 * 6月 * 7月 * 8月 * 9月 * 10月 * 11月 * 12月 * 雨雲レーダー[東京都 ： 伊豆諸島 ] * アメダス[気温 ：降水量 ：風向・風速 ：日照時間 ：積雪深 ] * 実況天気 [東京都心(大手町)： 大島： 三宅島： 八丈島： 父島： 南鳥島 ] | 日 | 月 | 火 | 水 | 木 | 金 | 土 | * ツイート%20-%20tenki.jp%20%40tenkijp&count=horizontal&lang=ja) ### 東京の過去天気(実況天気)(2025年10月) | 東京都 | * 東京都心(大手町) * 大島 * 三宅島 * 八丈島 * 父島 * 南鳥島 | * アメダス) ### 今日の天気 26日07:00発表 * 東京都(千代田区) tenki.jp公式SNS tenki.jp公式アプリ * tenki.jp * tenki.jp 登山天気\\\\n\\\\nTitle: 東京都心(大手町)(東京都)の過去の天気 2025年10月30日現在\\\\nURL: https://tenki.jp/past/2025/10/weather/3/16/47662/\\\\nContent: # tenki.jp ## 東京都心(大手町)(東京都)の過去の天気 * 雨雲レーダー[東京都 ： 伊豆諸島 ] * アメダス[気温 ： 降水量 ： 風向・風速 ： 日照時間 ： 積雪深 ] | 日 | 月 | 火 | 水 | 木 | 金 | 土 | | 12   曇  23.8 /15.9 | 13   曇のち晴  25.2 /19.8 | 14   曇  21.3 /17.6 | 15   雨のち曇  20.3 /15.2 | 16   雨  20.7 /15.8 | 17   晴  25.1 /16.7 | 18   曇のち晴  25.9 /15.5 | | 19   曇のち雨  24.5 /19.5 | 20   雨のち曇  19.7 /15.1 | 21   曇一時雨  17.2 /13.9 | 22   雨  15.4 /11.5 | 23   曇  17.9 /11.0 | 24   曇のち雨  16.9 /12.0 | 25   雨  13.5 /12.0 | tenki.jp公式SNS tenki.jp公式アプリ * tenki.jp * tenki.jp 登山天気\\\\n\\\\nTitle: 東京の天気・気温：今日・明日と14日間(2週間)の1時間ごと ...\\\\nURL: https://www.toshin.com/weather/forecast90days?id=56681\\\\nContent: 11月3日(月) 11月10日(月) 20℃ 12℃ 18℃ 11℃ 18℃ 12℃ 19℃ 11℃ 18℃ 11℃ 11月17日(月) 19℃ 10℃ 19℃ 10℃ 16℃ 11℃ 18℃ 11℃ 19℃ 11℃ 18℃ 9℃ 14℃ 7℃ 11月24日(月) 14℃ 9℃ 17℃ 9℃ 15℃ 9℃ 15℃ 9℃ 15℃ 9℃ 14℃ 9℃ 14℃ 9℃ 12月1日(月) 13℃ 8℃ 14℃ 6℃ 12℃ 4℃ 12℃ 6℃ 14℃ 8℃ 16℃ 5℃ 15℃ 6℃ 12月8日(月) 16℃ 4℃ 13℃ 4℃ 13℃ 3℃ 12℃ 4℃ 13℃ 3℃ 12℃ 7℃ 11℃ 7℃ 12月15日(月) 11℃ 7℃ 12℃ 8℃ 11℃ 6℃ 11℃ 6℃ 10℃ 6℃ 11℃ 7℃ 12℃ 7℃ 12月22日(月) 11℃ 7℃ 11℃ 6℃ 11℃ 7℃ 11℃ 6℃ 11℃ 6℃ 11℃ 5℃ 9℃ 4℃ 12月29日(月) 10℃ 6℃ 11℃ 5℃ 10℃ 5℃ 11℃ 5℃ 11℃ 5℃ 10℃ 5℃ 11℃ 5℃ 1月5日(月) 10℃ 5℃\\\\n\\\\nTitle: 東京の天気・気温：今日・明日と14日間(2週間)の1時間ごと ...\\\\nURL: https://www.toshin.com/weather/detail?id=66124\\\\nContent: Home  >  東京都  >  千代田区  >  東京  >  14日間(2週間)の1時間ごとの天気予報 天気 天気 風速(m/s) 天気 風速(m/s) | 0時 | 1時 | 2時 | 3時 | 4時 | 5時 | 6時 | 7時 | 8時 | 9時 | 10時 | 11時 | 12時 | 13時 | 14時 | 15時 | 16時 | 17時 | 18時 | 19時 | 20時 | 21時 | 22時 | 23時 | 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 小金井公園(東京都) 遠賀川(福岡県) 万博記念公園(大阪府) 乗鞍岳(岐阜県) 磐梯吾妻スカイライン(福島県) リゾナーレ八ヶ岳(山梨県) 二子玉川ライズ(東京都) 志摩スペイン村(三重県) むさしの村(埼玉県) 富士急ハイランド(山梨県) 大阪 天気 横浜 天気 札幌 天気 名古屋 天気 東京 天気 東京ディズニーランド ユニバーサルスタジオ・ジャパン 上高地 小金井公園(東京都) 遠賀川(福岡県) 万博記念公園(大阪府) 乗鞍岳(岐阜県) 磐梯吾妻スカイライン(福島県) リゾナーレ八ヶ岳(山梨県) 二子玉川ライズ(東京都) 志摩スペイン村(三重県) むさしの村(埼玉県) 富士急ハイランド(山梨県)\\\\n\\\\nTitle: 30日（今天）\\\\nURL: https://www.weather.com.cn/weather/103010100.shtml\\\\nContent: 首页 预报 预警 雷达 云图 天气地图 专业产品 资讯 视频 节气 我的天空 更多 台风路径 空间天气 图片 专题 环境 旅游 碳中和 气象科普 一带一路 产创平台 国内) 本地) 国际) :   北京 上海 成都 杭州 南京 天津 深圳 重庆 西安 广州 青岛 武汉 热门景点 :   故宫 阳朔漓江 龙门石窟 野三坡 颐和园 九寨沟 东方明珠 凤凰古城 秦始皇陵 桃花源 选择省市 高球 :   佘山 春城湖畔 华彬庄园 观澜湖 依必朗 旭宝 博鳌 玉龙雪山 番禺南沙 东方明珠 <<返回 全国 河北下辖区域 周边城市 周边景点 本地乡镇 热门城市 :   曼谷 东京 首尔 吉隆坡 新加坡 巴黎 罗马 伦敦 雅典 柏林 纽约 温哥华 墨西哥城 哈瓦那 圣何塞 巴西利亚 布宜诺斯艾利斯 圣地亚哥 利马 基多 悉尼 墨尔本 惠灵顿 奥克兰 苏瓦 开罗 内罗毕 开普敦 维多利亚 拉巴特 选择洲际 :   亚洲 欧洲 北美洲 南美洲 非洲 大洋洲 *13℃* 15℃/*13℃* 18℃/*15℃* 21℃/*13℃* 19℃/*11℃* 16℃/*10℃* 17℃/*11℃* # 更多>>高清图集 # 热点 *视频* *图片* *文章*\\\\n\\\\nTitle: SMG - 澳門特別行政區政府地球物理氣象局\\\\nURL: https://www.smg.gov.mo/\\\\nContent: SMG - 澳門特別行政區政府地球物理氣象局 Image 1 Image 3 *    天氣警告   熱帶氣旋現時熱帶氣旋信號熱帶氣旋路徑資訊熱帶氣旋路徑圖之說明信號之意義信號圖示風暴潮現時風暴潮警告警告級別說明各警告級別下受影響的地區暴雨現時暴雨警告信號雷達圖信號之意義雷暴現時雷暴警告信號閃電圖信號之意義強烈季候風信號(黑球)現時強烈季候風信號信號之意義       *    資源共享   氣象報告下載天氣報告惡劣天氣報告海浪報告氣象資料查詢資料查詢申請監測資料氣候資料統計資料各類報告下載百年氣候惡劣天氣記錄熱帶氣旋警告風暴潮警告暴雨警告信號記錄雷暴警告信號強烈季候風信號(黑球)空氣質量報告輻射監測報告地震發佈紀錄       *    關於我們   氣象局簡介架構和法規國際合作監測網絡氣象局服務服務項目服務承諾資訊發佈途徑滿意度調查特別支援設施氣象局總部導覽氣象局面面觀參觀申請意見反饋網頁資料使用登記表聯絡我們聲明使用聲明私隱聲明其他連結特區政府氣象航空氣象空氣質量輻射地震潮汐       Image 4 2025年08月28日 星期四 乙巳蛇年 七月初六日 Image 5 Image 10 Image 11 Image 12 Image 13 2025年08月27日 星期三 乙巳蛇年 七月初五日 Image 14 6 km/h  *   Image 21 *   Image 22 *   Image 23 *   Image 24 *   Image 25 *   Image 26 溫度(℃) 溫度(℃)日高溫(℃)日低溫(℃)濕度(%)風速(km/h)陣風(km/h)風向每小時雨量每日總雨量水位監測空氣質量指數 Himawari (IR)衛星 Himawari (IR)衛星Himawari (VIS)衛星 氹仔 - 雷達塔(向北) 氹仔 - 雷達塔(向北)氹仔 - 雷達塔(向東北)氹仔 - 雷達塔(向南)氹仔 - 雷達塔(向西)澳門 - 松山(向北)澳門 - 松山(向東)澳門 - 松山(向南)澳門 - 松山(向西)澳門 - 外港路環 - 颱風委員會 Image 27 Image 29 70% - 95%  Image 30 Image 32 75% - 95%  Image 33 *   特別推送 2025-08-26 低壓區再現，本週後期天氣趨不穩 *   特別推送 2025-08-21 週末天氣酷熱 打風與否仍需視乎距離 關於我們  澳門特別行政區政府地球物理氣象局 電子郵箱： meteo@smg.gov.mo\",\"annotations\":null,\"meta\":null}'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: utils.py:3394 - \n",
      "LiteLLM: Non-Default params passed to completion() {'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}]}\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - Final returned optional params: {'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}], 'extra_body': {}}\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:486 - self.optional_params: {'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}], 'extra_body': {}}\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: main.py:908 - Error getting model info: This model isn't mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:36 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:954 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.individual.githubcopilot.com \\\n",
      "-H 'Authorization: Be****e8' \\\n",
      "-d '{'model': 'claude-haiku-4.5', 'messages': [{'content': 'You using web search to answer user queries.', 'role': 'assistant'}, {'role': 'user', 'content': '明天東京的天氣如何？ (目前時間：2025-10-30 19:04)'}, {'role': 'assistant', 'tool_calls': [{'id': 'toolu_01VDw7Eb9c1fstKVyyLk9abY', 'type': 'function', 'function': {'name': 'tavily-search', 'arguments': '{\"query\":\"明天東京天氣 2025年10月31日\",\"country\":\"japan\",\"max_results\":10}'}}]}, {'role': 'tool', 'tool_call_id': 'toolu_01VDw7Eb9c1fstKVyyLk9abY', 'content': '{\"type\":\"text\",\"text\":\"Detailed Results:\\\\n\\\\nTitle: 東京（東京都) 2025年10月（日ごとの値） 主な要素\\\\nURL: https://www.data.jma.go.jp/stats/etrn/view/daily_s1.php?prec_no=44&block_no=47662&year=2025&month=10&day=&view=p1\\\\nContent: | 日 | 気圧(hPa) | 降水量(mm) | 気温(℃) | 湿度(％) | 風向・風速(m/s) | 日照 時間 (h) | 雪(cm) | 天気概況 | | 平均 | 平均 | 合計 | 最大 | 平均 | 最高 | 最低 | 平均 | 最小 | 平均 風速 | 最大風速 | 最大瞬間風速 | 降雪 | 最深積雪 | 昼 (06:00-18:00) | 夜 (18:00-翌日06:00) | | 1時間 | 10分間 | 風速 | 風向 | 風速 | 風向 | 合計 | 値 | | 1 | 1009.7 | 1012.5 | 4.5 | 1.0 | 0.5 | 20.5 | 23.6 | 18.3 | 93 | 73 | 2.1 | 5.6 | 北西 | 8.2 | 北西 | 0.0 | -- | -- | 雨 | 晴一時曇 |\\\\n\\\\nTitle: 東京都 2025年10月（日ごとの値） 最高気温（℃）\\\\nURL: https://www.data.jma.go.jp/stats/etrn/view/daily_h1.php?prec_no=44&block_no=00&year=2025&month=10&day=&view=p3\\\\nContent: * Other Languages * ENGLISH * ホーム * 防災情報 * 各種データ・資料 * 地域の情報 * 知識・解説 * 各種申請・ご案内 * ホーム\\xa0> * 各種データ・資料\\xa0> * 過去の気象データ検索\\xa0> * 日ごとの値 # 日ごとの値 ### 東京都\\u30002025年10月（日ごとの値）\\u3000最高気温（℃） | 日 | 小河内 | 八王子 | 東京\\\\\\\\* | 江戸川臨海 | 羽田 | 大島\\\\\\\\* | 三宅島\\\\\\\\* | 八丈島\\\\\\\\* | 青梅 | 練馬 | 府中 | 父島\\\\\\\\* | 大島北ノ山 | 八重見ヶ原 | 三宅坪田 | 新島 | 神津島 | 南鳥島\\\\\\\\* | * 値欄の記号の説明 * アスタリスク(\\\\\\\\*)が付いた地点は地上気象観測地点(気象台・測候所・特別地域気象観測所等)です。 * アスタリスクの付いていない地点はアメダス地点です。2021年3月2日より、アメダスの日照時間は「推計気象分布（日照時間）」から得る推計値となりましたので、日照計による観測値と単純比較できません。詳しくは要素ごとの値の補足説明をご覧ください。 | * 利用される方へ | * よくある質問（FAQ） | * 気象観測統計の解説 | * 年・季節・各月の天候 | このページのトップへ\\\\n\\\\nTitle: 東京, 東京都, 日本の月間予報 | AccuWeather\\\\nURL: https://www.accuweather.com/ja/jp/tokyo/226396/october-weather/226396\\\\nContent: 戻る  # 東京, 東京都 55°F  55° 東京, 東京都の天気 今日 WinterCast ローカル{stormName}トラッカー 毎時 毎日 レーダー MinuteCast® 月間 大気質 健康・アクティビティ ### ハリケーン ### 悪天候 ### レーダー&地図 ### ビデオ 今日   毎時   毎日   レーダー   MinuteCast®  ## 月間  大気質   健康・アクティビティ ## 10月 1月   2月   3月   4月   5月   6月   7月   8月   9月   10月   11月   12月 ## 毎日 84° 69° 29 88° 76° 30 83° 72° 1 74° 66° 2 82° 63° 3 79° 67° 4 77° 69° 5 84° 67° 6 85° 72° 7 77° 68° 8 83° 67° 9 76° 65° 10 76° 63° 11 69° 61° 12 75° 61° 13 ### 11月 2025 ### 12月 2025 ### 1月 2026 ### ハリケーン ### 悪天候 ### レーダー&地図 ### ビデオ 世界 アジア 日本 東京都 東京 * 八王子市, 東京都\\\\n\\\\nTitle: 10月31日(木) 東京都の天気\\\\nURL: https://weathernews.jp/news/202410/310500tokyo/\\\\nContent: 明後日31日(金)は太平洋側で雨雲発達 三連休初日は北日本で風雨強まる · 明日10月30日(木)の天気予報 全国的に晴れる所が多い 朝と昼間の気温差大 · 10月30\\\\n\\\\nTitle: 東京都の過去の天気(実況天気・2025年10月)\\\\nURL: https://tenki.jp/past/2025/10/weather/3/16/\\\\nContent: tenki.jpトップ｜ サイトマップ｜ ヘルプ # tenki.jp ## 東京都の過去の天気 翌月 前月   09月 * 2015年 * 2016年 * 2017年 * 2018年 * 2019年 * 2020年 * 2021年 * 2022年 * 1月 * 2月 * 3月 * 4月 * 5月 * 6月 * 7月 * 8月 * 9月 * 10月 * 11月 * 12月 * 雨雲レーダー[東京都 ： 伊豆諸島 ] * アメダス[気温 ：降水量 ：風向・風速 ：日照時間 ：積雪深 ] * 実況天気 [東京都心(大手町)： 大島： 三宅島： 八丈島： 父島： 南鳥島 ] | 日 | 月 | 火 | 水 | 木 | 金 | 土 | * ツイート%20-%20tenki.jp%20%40tenkijp&count=horizontal&lang=ja) ### 東京の過去天気(実況天気)(2025年10月) | 東京都 | * 東京都心(大手町) * 大島 * 三宅島 * 八丈島 * 父島 * 南鳥島 | * アメダス) ### 今日の天気 26日07:00発表 * 東京都(千代田区) tenki.jp公式SNS tenki.jp公式アプリ * tenki.jp * tenki.jp 登山天気\\\\n\\\\nTitle: 東京都心(大手町)(東京都)の過去の天気 2025年10月30日現在\\\\nURL: https://tenki.jp/past/2025/10/weather/3/16/47662/\\\\nContent: # tenki.jp ## 東京都心(大手町)(東京都)の過去の天気 * 雨雲レーダー[東京都 ： 伊豆諸島 ] * アメダス[気温 ： 降水量 ： 風向・風速 ： 日照時間 ： 積雪深 ] | 日 | 月 | 火 | 水 | 木 | 金 | 土 | | 12   曇  23.8 /15.9 | 13   曇のち晴  25.2 /19.8 | 14   曇  21.3 /17.6 | 15   雨のち曇  20.3 /15.2 | 16   雨  20.7 /15.8 | 17   晴  25.1 /16.7 | 18   曇のち晴  25.9 /15.5 | | 19   曇のち雨  24.5 /19.5 | 20   雨のち曇  19.7 /15.1 | 21   曇一時雨  17.2 /13.9 | 22   雨  15.4 /11.5 | 23   曇  17.9 /11.0 | 24   曇のち雨  16.9 /12.0 | 25   雨  13.5 /12.0 | tenki.jp公式SNS tenki.jp公式アプリ * tenki.jp * tenki.jp 登山天気\\\\n\\\\nTitle: 東京の天気・気温：今日・明日と14日間(2週間)の1時間ごと ...\\\\nURL: https://www.toshin.com/weather/forecast90days?id=56681\\\\nContent: 11月3日(月) 11月10日(月) 20℃ 12℃ 18℃ 11℃ 18℃ 12℃ 19℃ 11℃ 18℃ 11℃ 11月17日(月) 19℃ 10℃ 19℃ 10℃ 16℃ 11℃ 18℃ 11℃ 19℃ 11℃ 18℃ 9℃ 14℃ 7℃ 11月24日(月) 14℃ 9℃ 17℃ 9℃ 15℃ 9℃ 15℃ 9℃ 15℃ 9℃ 14℃ 9℃ 14℃ 9℃ 12月1日(月) 13℃ 8℃ 14℃ 6℃ 12℃ 4℃ 12℃ 6℃ 14℃ 8℃ 16℃ 5℃ 15℃ 6℃ 12月8日(月) 16℃ 4℃ 13℃ 4℃ 13℃ 3℃ 12℃ 4℃ 13℃ 3℃ 12℃ 7℃ 11℃ 7℃ 12月15日(月) 11℃ 7℃ 12℃ 8℃ 11℃ 6℃ 11℃ 6℃ 10℃ 6℃ 11℃ 7℃ 12℃ 7℃ 12月22日(月) 11℃ 7℃ 11℃ 6℃ 11℃ 7℃ 11℃ 6℃ 11℃ 6℃ 11℃ 5℃ 9℃ 4℃ 12月29日(月) 10℃ 6℃ 11℃ 5℃ 10℃ 5℃ 11℃ 5℃ 11℃ 5℃ 10℃ 5℃ 11℃ 5℃ 1月5日(月) 10℃ 5℃\\\\n\\\\nTitle: 東京の天気・気温：今日・明日と14日間(2週間)の1時間ごと ...\\\\nURL: https://www.toshin.com/weather/detail?id=66124\\\\nContent: Home  >  東京都  >  千代田区  >  東京  >  14日間(2週間)の1時間ごとの天気予報 天気 天気 風速(m/s) 天気 風速(m/s) | 0時 | 1時 | 2時 | 3時 | 4時 | 5時 | 6時 | 7時 | 8時 | 9時 | 10時 | 11時 | 12時 | 13時 | 14時 | 15時 | 16時 | 17時 | 18時 | 19時 | 20時 | 21時 | 22時 | 23時 | 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 天気 風速(m/s) 小金井公園(東京都) 遠賀川(福岡県) 万博記念公園(大阪府) 乗鞍岳(岐阜県) 磐梯吾妻スカイライン(福島県) リゾナーレ八ヶ岳(山梨県) 二子玉川ライズ(東京都) 志摩スペイン村(三重県) むさしの村(埼玉県) 富士急ハイランド(山梨県) 大阪 天気 横浜 天気 札幌 天気 名古屋 天気 東京 天気 東京ディズニーランド ユニバーサルスタジオ・ジャパン 上高地 小金井公園(東京都) 遠賀川(福岡県) 万博記念公園(大阪府) 乗鞍岳(岐阜県) 磐梯吾妻スカイライン(福島県) リゾナーレ八ヶ岳(山梨県) 二子玉川ライズ(東京都) 志摩スペイン村(三重県) むさしの村(埼玉県) 富士急ハイランド(山梨県)\\\\n\\\\nTitle: 30日（今天）\\\\nURL: https://www.weather.com.cn/weather/103010100.shtml\\\\nContent: 首页 预报 预警 雷达 云图 天气地图 专业产品 资讯 视频 节气 我的天空 更多 台风路径 空间天气 图片 专题 环境 旅游 碳中和 气象科普 一带一路 产创平台 国内) 本地) 国际) :   北京 上海 成都 杭州 南京 天津 深圳 重庆 西安 广州 青岛 武汉 热门景点 :   故宫 阳朔漓江 龙门石窟 野三坡 颐和园 九寨沟 东方明珠 凤凰古城 秦始皇陵 桃花源 选择省市 高球 :   佘山 春城湖畔 华彬庄园 观澜湖 依必朗 旭宝 博鳌 玉龙雪山 番禺南沙 东方明珠 <<返回 全国 河北下辖区域 周边城市 周边景点 本地乡镇 热门城市 :   曼谷 东京 首尔 吉隆坡 新加坡 巴黎 罗马 伦敦 雅典 柏林 纽约 温哥华 墨西哥城 哈瓦那 圣何塞 巴西利亚 布宜诺斯艾利斯 圣地亚哥 利马 基多 悉尼 墨尔本 惠灵顿 奥克兰 苏瓦 开罗 内罗毕 开普敦 维多利亚 拉巴特 选择洲际 :   亚洲 欧洲 北美洲 南美洲 非洲 大洋洲 *13℃* 15℃/*13℃* 18℃/*15℃* 21℃/*13℃* 19℃/*11℃* 16℃/*10℃* 17℃/*11℃* # 更多>>高清图集 # 热点 *视频* *图片* *文章*\\\\n\\\\nTitle: SMG - 澳門特別行政區政府地球物理氣象局\\\\nURL: https://www.smg.gov.mo/\\\\nContent: SMG - 澳門特別行政區政府地球物理氣象局 Image 1 Image 3 *    天氣警告   熱帶氣旋現時熱帶氣旋信號熱帶氣旋路徑資訊熱帶氣旋路徑圖之說明信號之意義信號圖示風暴潮現時風暴潮警告警告級別說明各警告級別下受影響的地區暴雨現時暴雨警告信號雷達圖信號之意義雷暴現時雷暴警告信號閃電圖信號之意義強烈季候風信號(黑球)現時強烈季候風信號信號之意義       *    資源共享   氣象報告下載天氣報告惡劣天氣報告海浪報告氣象資料查詢資料查詢申請監測資料氣候資料統計資料各類報告下載百年氣候惡劣天氣記錄熱帶氣旋警告風暴潮警告暴雨警告信號記錄雷暴警告信號強烈季候風信號(黑球)空氣質量報告輻射監測報告地震發佈紀錄       *    關於我們   氣象局簡介架構和法規國際合作監測網絡氣象局服務服務項目服務承諾資訊發佈途徑滿意度調查特別支援設施氣象局總部導覽氣象局面面觀參觀申請意見反饋網頁資料使用登記表聯絡我們聲明使用聲明私隱聲明其他連結特區政府氣象航空氣象空氣質量輻射地震潮汐       Image 4 2025年08月28日 星期四 乙巳蛇年 七月初六日 Image 5 Image 10 Image 11 Image 12 Image 13 2025年08月27日 星期三 乙巳蛇年 七月初五日 Image 14 6 km/h  *   Image 21 *   Image 22 *   Image 23 *   Image 24 *   Image 25 *   Image 26 溫度(℃) 溫度(℃)日高溫(℃)日低溫(℃)濕度(%)風速(km/h)陣風(km/h)風向每小時雨量每日總雨量水位監測空氣質量指數 Himawari (IR)衛星 Himawari (IR)衛星Himawari (VIS)衛星 氹仔 - 雷達塔(向北) 氹仔 - 雷達塔(向北)氹仔 - 雷達塔(向東北)氹仔 - 雷達塔(向南)氹仔 - 雷達塔(向西)澳門 - 松山(向北)澳門 - 松山(向東)澳門 - 松山(向南)澳門 - 松山(向西)澳門 - 外港路環 - 颱風委員會 Image 27 Image 29 70% - 95%  Image 30 Image 32 75% - 95%  Image 33 *   特別推送 2025-08-26 低壓區再現，本週後期天氣趨不穩 *   特別推送 2025-08-21 週末天氣酷熱 打風與否仍需視乎距離 關於我們  澳門特別行政區政府地球物理氣象局 電子郵箱： meteo@smg.gov.mo\",\"annotations\":null,\"meta\":null}'}], 'tools': [{'type': 'function', 'function': {'name': 'tavily-search', 'description': \"A powerful web search tool that provides comprehensive, real-time results using Tavily's AI search engine. Returns relevant web content with customizable parameters for result count, content type, and domain filtering. Ideal for gathering current information, news, and detailed web content analysis.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'search_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"The depth of the search. It can be 'basic' or 'advanced'\", 'default': 'basic'}, 'topic': {'type': 'string', 'enum': ['general', 'news'], 'description': 'The category of the search. This will determine which of our agents will be used for the search', 'default': 'general'}, 'days': {'type': 'number', 'description': \"The number of days back from the current date to include in the search results. This specifies the time frame of data to be retrieved. Please note that this feature is only available when using the 'news' search topic\", 'default': 3}, 'time_range': {'type': 'string', 'description': \"The time range back from the current date to include in the search results. This feature is available for both 'general' and 'news' search topics\", 'enum': ['day', 'week', 'month', 'year', 'd', 'w', 'm', 'y']}, 'start_date': {'type': 'string', 'description': 'Will return all results after the specified start date. Required to be written in the format YYYY-MM-DD.', 'default': ''}, 'end_date': {'type': 'string', 'description': 'Will return all results before the specified end date. Required to be written in the format YYYY-MM-DD', 'default': ''}, 'max_results': {'type': 'number', 'description': 'The maximum number of search results to return', 'default': 10, 'minimum': 5, 'maximum': 20}, 'include_images': {'type': 'boolean', 'description': 'Include a list of query-related images in the response', 'default': False}, 'include_image_descriptions': {'type': 'boolean', 'description': 'Include a list of query-related images and their descriptions in the response', 'default': False}, 'include_raw_content': {'type': 'boolean', 'description': 'Include the cleaned and parsed HTML content of each search result', 'default': False}, 'include_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of domains to specifically include in the search results, if the user asks to search on specific sites set this to the domain of the site', 'default': []}, 'exclude_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of domains to specifically exclude, if the user asks to exclude a domain set this to the domain of the site', 'default': []}, 'country': {'type': 'string', 'enum': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'denmark', 'djibouti', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'guatemala', 'guinea', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'north macedonia', 'norway', 'oman', 'pakistan', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saudi arabia', 'senegal', 'serbia', 'singapore', 'slovakia', 'slovenia', 'somalia', 'south africa', 'south korea', 'south sudan', 'spain', 'sri lanka', 'sudan', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states', 'uruguay', 'uzbekistan', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'description': 'Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general. Country names MUST be written in lowercase, plain English, with spaces and no underscores.', 'default': ''}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'tavily-extract', 'description': 'A powerful web content extraction tool that retrieves and processes raw content from specified URLs, ideal for data collection, content analysis, and research tasks.', 'parameters': {'type': 'object', 'properties': {'urls': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of URLs to extract content from'}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': \"Depth of extraction - 'basic' or 'advanced', if usrls are linkedin use 'advanced' or if explicitly told to use advanced\", 'default': 'basic'}, 'include_images': {'type': 'boolean', 'description': 'Include a list of images extracted from the urls in the response', 'default': False}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['urls']}}}, {'type': 'function', 'function': {'name': 'tavily-crawl', 'description': 'A powerful web crawler that initiates a structured web crawl starting from a specified base URL. The crawler expands from that point like a graph, following internal links across pages. You can control how deep and wide it goes, and guide it to focus on specific sections of the site.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the crawl'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the crawl. Defines how far from the base URL the crawler can explore.', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler. Instructions specify which types of pages the crawler should return.'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}, 'extract_depth': {'type': 'string', 'enum': ['basic', 'advanced'], 'description': 'Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency', 'default': 'basic'}, 'format': {'type': 'string', 'enum': ['markdown', 'text'], 'description': 'The format of the extracted web page content. markdown returns content in markdown format. text returns plain text and may increase latency.', 'default': 'markdown'}, 'include_favicon': {'type': 'boolean', 'description': 'Whether to include the favicon URL for each result', 'default': False}}, 'required': ['url']}}}, {'type': 'function', 'function': {'name': 'tavily-map', 'description': 'A powerful web mapping tool that creates a structured map of website URLs, allowing you to discover and analyze site structure, content organization, and navigation paths. Perfect for site audits, content discovery, and understanding website architecture.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The root URL to begin the mapping'}, 'max_depth': {'type': 'integer', 'description': 'Max depth of the mapping. Defines how far from the base URL the crawler can explore', 'default': 1, 'minimum': 1}, 'max_breadth': {'type': 'integer', 'description': 'Max number of links to follow per level of the tree (i.e., per page)', 'default': 20, 'minimum': 1}, 'limit': {'type': 'integer', 'description': 'Total number of links the crawler will process before stopping', 'default': 50, 'minimum': 1}, 'instructions': {'type': 'string', 'description': 'Natural language instructions for the crawler'}, 'select_paths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to select only URLs with specific path patterns (e.g., /docs/.*, /api/v1.*)', 'default': []}, 'select_domains': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Regex patterns to restrict crawling to specific domains or subdomains (e.g., ^docs\\\\.example\\\\.com$)', 'default': []}, 'allow_external': {'type': 'boolean', 'description': 'Whether to return external links in the final response', 'default': True}}, 'required': ['url']}}}], 'extra_body': {}, 'extra_headers': {'User-Agent': 'Agents/Python 0.4.0', 'editor-version': 'vscode/1.85.1', 'Copilot-Integration-Id': 'vscode-chat'}}'\n",
      "\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1027 - RAW RESPONSE:\n",
      "{\"id\": \"msg_01HxNnxob64ojVAzdoKdU4ad\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": null, \"logprobs\": null, \"message\": {\"content\": \"\\u611f\\u8b1d\\u60a8\\u7684\\u63d0\\u554f\\uff01\\u6839\\u64da\\u641c\\u7d22\\u7d50\\u679c\\uff0c\\u6211\\u9700\\u8981\\u544a\\u77e5\\u60a8\\u4e00\\u500b\\u91cd\\u8981\\u7684\\u60c5\\u6cc1\\uff1a\\n\\n## \\u6642\\u9593\\u554f\\u984c\\n\\n\\u60a8\\u63d0\\u5230\\u7684\\u7576\\u524d\\u6642\\u9593\\u662f **2025-10-30 19:04**\\uff0c\\u9019\\u610f\\u5473\\u8457\\u660e\\u5929\\u662f **2025\\u5e7410\\u670831\\u65e5**\\u3002\\u4f46\\u6839\\u64da\\u641c\\u7d22\\u7d50\\u679c\\u4e2d\\u7684\\u65e5\\u672c\\u6c23\\u8c61\\u6578\\u64da\\uff0c\\u9019\\u4e9b\\u6578\\u64da\\u662f\\u904e\\u53bb\\u5df2\\u767c\\u751f\\u7684\\u5929\\u6c23\\u8a18\\u9304\\uff0810\\u6708\\u5df2\\u7d93\\u904e\\u5b8c\\uff09\\uff0c\\u800c\\u6211\\u627e\\u5230\\u7684\\u9810\\u5831\\u4fe1\\u606f\\u4e0d\\u5920\\u660e\\u78ba\\u3002\\n\\n## \\u53ef\\u7528\\u7684\\u4fe1\\u606f\\n\\n\\u6839\\u64da\\u641c\\u7d22\\u7d50\\u679c\\uff0c\\u6211\\u80fd\\u770b\\u5230\\uff1a\\n- \\u641c\\u7d22\\u7d50\\u679c\\u4e2d\\u63d0\\u5230\\u4e86\\u300c10\\u670831\\u65e5\\u300d\\u7684\\u5929\\u6c23\\u4fe1\\u606f\\uff0c\\u4f46\\u8a73\\u7d30\\u5167\\u5bb9\\u672a\\u5b8c\\u6574\\u986f\\u793a\\n- \\u4e00\\u689d\\u7d50\\u679c\\u63d0\\u5230\\u300c\\u660e\\u5f8c\\u65e531\\u65e5(\\u91d1)\\u306f\\u592a\\u5e73\\u6d0b\\u5074\\u3067\\u96e8\\u96f2\\u767a\\u9054\\u300d\\uff08\\u5f8c\\u592931\\u65e5\\u91d1\\u66dc\\u65e5\\uff0c\\u592a\\u5e73\\u6d0b\\u5074\\u6703\\u6709\\u96e8\\u96f2\\u767c\\u5c55\\uff09\\n\\n## \\u5efa\\u8b70\\n\\n\\u7531\\u65bc\\u641c\\u7d22\\u7d50\\u679c\\u7684\\u4fe1\\u606f\\u6709\\u9650\\uff0c\\u6211\\u5efa\\u8b70\\u60a8\\u76f4\\u63a5\\u67e5\\u95b1\\u4ee5\\u4e0b\\u65e5\\u672c\\u5b98\\u65b9\\u5929\\u6c23\\u9810\\u5831\\u4f86\\u6e90\\uff1a\\n\\n1. **\\u65e5\\u672c\\u6c23\\u8c61\\u5ef3** (JMA): https://www.jma.go.jp/ \\n2. **\\u5929\\u6c23\\u65b0\\u805e** (Weather News): https://weathernews.jp/\\n3. **Tenki.jp**: https://tenki.jp/\\n4. **AccuWeather \\u65e5\\u672c\\u7248**: https://www.accuweather.com/ja/jp/\\n\\n\\u9019\\u4e9b\\u7db2\\u7ad9\\u6703\\u63d0\\u4f9b\\u6700\\u6e96\\u78ba\\u7684\\u5be6\\u6642\\u5929\\u6c23\\u9810\\u5831\\u3002\\u6839\\u64da\\u73fe\\u5728\\u662f\\u665a\\u4e0a7\\u9ede\\uff0c\\u60a8\\u61c9\\u8a72\\u80fd\\u627e\\u5230\\u660e\\u592931\\u65e5\\u7684\\u8a73\\u7d30\\u9810\\u5831\\u3002\", \"refusal\": null, \"role\": \"assistant\", \"annotations\": null, \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1761822281, \"model\": \"claude-haiku-4.5\", \"object\": null, \"service_tier\": null, \"system_fingerprint\": null, \"usage\": {\"completion_tokens\": 441, \"prompt_tokens\": 9121, \"total_tokens\": 9562, \"completion_tokens_details\": null, \"prompt_tokens_details\": {\"audio_tokens\": null, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2918 - Filtered callbacks: []\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:775 - selected model name for cost calculation: github_copilot/claude-haiku-4.5\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:1048 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=github_copilot/claude-haiku-4.5 - This model isn't mapped yet. model=github_copilot/claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:775 - selected model name for cost calculation: github_copilot/claude-haiku-4.5\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:1048 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=github_copilot/claude-haiku-4.5 - This model isn't mapped yet. model=github_copilot/claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1322 - response_cost_failure_debug_information: {'error_str': \"This model isn't mapped yet. model=github_copilot/claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\", 'traceback_str': 'Traceback (most recent call last):\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 4851, in _get_model_info_helper\\n    raise ValueError(\\nValueError: This model isn\\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/litellm_logging.py\", line 1304, in _response_cost_calculator\\n    response_cost = litellm.response_cost_calculator(\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1166, in response_cost_calculator\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1149, in response_cost_calculator\\n    response_cost = completion_cost(\\n                    ^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1061, in completion_cost\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1054, in completion_cost\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 993, in completion_cost\\n    ) = cost_per_token(\\n        ^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 368, in cost_per_token\\n    model_info = _cached_get_model_info_helper(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 4703, in _cached_get_model_info_helper\\n    return _get_model_info_helper(model=model, custom_llm_provider=custom_llm_provider)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 5004, in _get_model_info_helper\\n    raise Exception(\\nException: This model isn\\'t mapped yet. model=github_copilot/claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\\n', 'model': 'github_copilot/claude-haiku-4.5', 'cache_hit': False, 'custom_llm_provider': 'github_copilot', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - Async Wrapper: Completed Call, calling async_success_handler: <bound method Logging.async_success_handler of <litellm.litellm_core_utils.litellm_logging.Logging object at 0x1581a8ce0>>\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2918 - Filtered callbacks: []\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - Logging Details LiteLLM-Async Success Call, cache_hit=None\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:2111 - Model not found or error in checking supports_reasoning support. You passed model=claude-haiku-4.5, custom_llm_provider=github_copilot. Error: This model isn't mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:4169 - Model=github_copilot/claude-haiku-4.5 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:366 - Async success callbacks: Got a complete streaming response\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:775 - selected model name for cost calculation: github_copilot/claude-haiku-4.5\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:1048 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=github_copilot/claude-haiku-4.5 - This model isn't mapped yet. model=github_copilot/claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:775 - selected model name for cost calculation: claude-haiku-4.5\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:1048 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=claude-haiku-4.5 - This model isn't mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1322 - response_cost_failure_debug_information: {'error_str': \"This model isn't mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\", 'traceback_str': 'Traceback (most recent call last):\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 4851, in _get_model_info_helper\\n    raise ValueError(\\nValueError: This model isn\\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/litellm_logging.py\", line 1304, in _response_cost_calculator\\n    response_cost = litellm.response_cost_calculator(\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1166, in response_cost_calculator\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1149, in response_cost_calculator\\n    response_cost = completion_cost(\\n                    ^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1061, in completion_cost\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 1054, in completion_cost\\n    raise e\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 993, in completion_cost\\n    ) = cost_per_token(\\n        ^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/cost_calculator.py\", line 368, in cost_per_token\\n    model_info = _cached_get_model_info_helper(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 4703, in _cached_get_model_info_helper\\n    return _get_model_info_helper(model=model, custom_llm_provider=custom_llm_provider)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/sacahan/Documents/workspace/CasualTrader/.venv/lib/python3.12/site-packages/litellm/utils.py\", line 5004, in _get_model_info_helper\\n    raise Exception(\\nException: This model isn\\'t mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\\n', 'model': 'claude-haiku-4.5', 'cache_hit': None, 'custom_llm_provider': 'github_copilot', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2255 - Model=claude-haiku-4.5; cost=None\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:2111 - Model not found or error in checking supports_reasoning support. You passed model=claude-haiku-4.5, custom_llm_provider=github_copilot. Error: This model isn't mapped yet. model=claude-haiku-4.5, custom_llm_provider=github_copilot. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:4762 - checking potential_model_names in litellm.model_cost: {'split_model': 'claude-haiku-4.5', 'combined_model_name': 'github_copilot/claude-haiku-4.5', 'stripped_model_name': 'claude-haiku-4.5', 'combined_stripped_model_name': 'github_copilot/claude-haiku-4.5', 'custom_llm_provider': 'github_copilot'}\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: utils.py:5001 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m19:04:41 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:4169 - Model=github_copilot/claude-haiku-4.5 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"感謝您的提問！根據搜索結果，我需要告知您一個重要的情況：\\n\\n## 時間問題\\n\\n您提到的當前時間是 **2025-10-30 19:04**，這意味著明天是 **2025年10月31日**。但根據搜索結果中的日本氣象數據，這些數據是過去已發生的天氣記錄（10月已經過完），而我找到的預報信息不夠明確。\\n\\n## 可用的信息\\n\\n根據搜索結果，我能看到：\\n- 搜索結果中提到了「10月31日」的天氣信息，但詳細內容未完整顯示\\n- 一條結果提到「明後日31日(金)は太平洋側で雨雲発達」（後天31日金曜日，太平洋側會有雨雲發展）\\n\\n## 建議\\n\\n由於搜索結果的信息有限，我建議您直接查閱以下日本官方天氣預報來源：\\n\\n1. **日本氣象廳** (JMA): https://www.jma.go.jp/ \\n2. **天氣新聞** (Weather News): https://weathernews.jp/\\n3. **Tenki.jp**: https://tenki.jp/\\n4. **AccuWeather 日本版**: https://www.accuweather.com/ja/jp/\\n\\n這些網站會提供最準確的實時天氣預報。根據現在是晚上7點，您應該能找到明天31日的詳細預報。\"\n",
      "\n",
      "=== Agent with MCP Tool Integration ===\n"
     ]
    }
   ],
   "source": [
    "from contextlib import AsyncExitStack\n",
    "from agents import Agent, Runner, function_tool, ModelSettings, gen_trace_id, trace\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from agents.mcp import MCPServerStdio\n",
    "import json\n",
    "from datetime import datetime\n",
    "import litellm\n",
    "\n",
    "litellm._turn_on_debug()\n",
    "model = \"github_copilot/claude-haiku-4.5\"\n",
    "print(f\"\\nUsing model: {model}\")\n",
    "\n",
    "# Initialize MCP servers\n",
    "async def get_tavily_mcp():\n",
    "    \"\"\"\n",
    "    初始化 MCP 伺服器並註冊到 exit stack\n",
    "\n",
    "    Raises:\n",
    "        Exception: 初始化失敗\n",
    "    \"\"\"\n",
    "    global _exit_stack  # 修正 UnboundLocalError\n",
    "    try:\n",
    "        if not _exit_stack:\n",
    "            _exit_stack = AsyncExitStack() \n",
    "\n",
    "        # Tavily MCP Server\n",
    "        # 參數在 MCPServerStdio 的 params 內配置\n",
    "        tavily_mcp = await _exit_stack.enter_async_context(\n",
    "            MCPServerStdio(\n",
    "                name=\"tavily_mcp\",\n",
    "                params={\n",
    "                    \"command\": \"npx\",\n",
    "                    \"args\": [\"-y\", \"tavily-mcp@latest\"],\n",
    "                    \"env\": {\"TAVILY_API_KEY\": f\"{TAVILY_API_KEY}\"},\n",
    "                },\n",
    "                client_session_timeout_seconds=30.0,\n",
    "            )\n",
    "        )\n",
    "        print(\"tavily_mcp server initialized\")\n",
    "        return tavily_mcp\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize MCP server: {e}\")\n",
    "        # 如果初始化失敗，清理已創建的資源\n",
    "        if _exit_stack:\n",
    "            await _exit_stack.aclose()\n",
    "            _exit_stack = None\n",
    "\n",
    "tavily_mcp = await get_tavily_mcp()\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Analyst\",\n",
    "    instructions=\"You using web search to answer user queries.\",\n",
    "    model=LitellmModel(model=model),\n",
    "    mcp_servers=[tavily_mcp],\n",
    "    model_settings=ModelSettings(\n",
    "        include_usage=True,\n",
    "        tool_choice=\"required\",\n",
    "        extra_headers={\n",
    "            \"editor-version\": \"vscode/1.85.1\",\n",
    "            \"Copilot-Integration-Id\": \"vscode-chat\",\n",
    "        },\n",
    "    ),\n",
    ")\n",
    "\n",
    "trace_id = gen_trace_id()\n",
    "with trace(workflow_name=\"lab_section_5\", trace_id=trace_id):\n",
    "    message = f\"明天東京的天氣如何？ (目前時間：{datetime.now().strftime('%Y-%m-%d %H:%M')})\"\n",
    "    print(f\"message: {message}\")\n",
    "    print(\"-\" * 50)\n",
    "    result = await Runner.run(agent, message)\n",
    "    print(json.dumps(result.final_output, indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\n=== Agent with MCP Tool Integration ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
