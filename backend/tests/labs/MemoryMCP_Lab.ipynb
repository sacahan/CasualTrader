{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e35ff41",
   "metadata": {},
   "source": [
    "# Memory MCP Lab - Testing mcp-memory-libsql API\n",
    "\n",
    "æœ¬ Notebook ç”¨æ–¼é©—è­‰ `memory_tools.py` ä¸­çš„ `memory_mcp.session.call_tool()` ä½¿ç”¨æ–¹å¼ï¼Œ\n",
    "ä»¥åŠç†è§£ mcp-memory-libsql æä¾›çš„ API å·¥å…·ï¼ŒåŒ…æ‹¬ï¼š\n",
    "- `create_entities`: å»ºç«‹è¨˜æ†¶é«”å¯¦é«”\n",
    "- `search_nodes`: æœå°‹ç¯€é»\n",
    "- `read_graph`: è®€å–å®Œæ•´åœ–è¡¨\n",
    "- `delete_entity`: åˆªé™¤å¯¦é«”\n",
    "\n",
    "ç›®æ¨™ï¼šé€éå¯¦éš›æ¸¬è©¦ä¾†é©—è­‰ memory_tools.py ä¸­çš„å‡½æ•¸é‚è¼¯æ˜¯å¦æ­£ç¢ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10958778",
   "metadata": {},
   "source": [
    "## Section 1: ç’°å¢ƒè¨­ç½®èˆ‡ä¾è³´å®‰è£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import dotenv_values\n",
    "import asyncio\n",
    "import json\n",
    "from contextlib import AsyncExitStack\n",
    "from datetime import datetime\n",
    "\n",
    "# è¨­å®š Python è·¯å¾‘ï¼Œä»¥ä¾¿å°å…¥å°ˆæ¡ˆæ¨¡çµ„\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "sys.path.insert(0, str(project_root / \"backend\" / \"src\"))\n",
    "\n",
    "# æ‰¾åˆ° .env æª”æ¡ˆ\n",
    "env_file = project_root / \"backend\" / \".env\"\n",
    "if not env_file.exists():\n",
    "    env_file = Path.home() / \"Documents/workspace/CasualTrader/backend/.env\"\n",
    "\n",
    "# è®€å–ä¸¦è¨­å®šç’°å¢ƒè®Šæ•¸\n",
    "if env_file.exists():\n",
    "    env_vars = dotenv_values(env_file)\n",
    "    for key, value in env_vars.items():\n",
    "        os.environ[key] = value.strip('\"').strip(\"'\") if value else \"\"\n",
    "    print(f\"âœ“ .env å·²è¼‰å…¥: {env_file}\")\n",
    "else:\n",
    "    print(f\"âœ— .env æª”æ¡ˆæœªæ‰¾åˆ°: {env_file}\")\n",
    "\n",
    "# é©—è­‰å¿…è¦çš„ç’°å¢ƒè®Šæ•¸\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"âœ“ OPENAI_API_KEY: {'å·²è¨­å®š' if OPENAI_API_KEY else 'æœªè¨­å®š'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441baa39",
   "metadata": {},
   "source": [
    "## Section 2: MCP Memory LibSQL åŸºæœ¬æ¦‚å¿µ\n",
    "\n",
    "MCP (Model Context Protocol) Memory LibSQL æ˜¯ä¸€å€‹ç‚º AI æ¨¡å‹æä¾›æŒä¹…åŒ–è¨˜æ†¶é«”çš„ MCP ä¼ºæœå™¨ã€‚\n",
    "å®ƒä½¿ç”¨ LibSQL (SQLite çš„è¼•é‡ç´šè¡ç”Ÿç‰ˆæœ¬) ä½œç‚ºå¾Œç«¯å­˜å„²ã€‚\n",
    "\n",
    "### æ ¸å¿ƒç‰¹æ€§ï¼š\n",
    "1. **Entity å¯¦é«”ç®¡ç†**ï¼šå„²å­˜å¸¶æœ‰è§€å¯Ÿå€¼çš„å‘½åå¯¦é«”\n",
    "2. **é—œä¿‚ç®¡ç†**ï¼šå®šç¾©å¯¦é«”ä¹‹é–“çš„é€£æ¥\n",
    "3. **å‘é‡æœå°‹**ï¼šæ”¯æ´èªç¾©æœå°‹åŠŸèƒ½\n",
    "4. **åœ–è¡¨æ“ä½œ**ï¼šå®Œæ•´çš„çŸ¥è­˜åœ–è¡¨ç®¡ç†\n",
    "\n",
    "### ä¸»è¦å·¥å…·ï¼š\n",
    "- `create_entities`: å»ºç«‹æˆ–æ›´æ–°å¯¦é«”åŠå…¶è§€å¯Ÿ\n",
    "- `search_nodes`: åŸºæ–¼æŸ¥è©¢æœå°‹ç›¸ä¼¼ç¯€é»\n",
    "- `read_graph`: è®€å–å®Œæ•´æˆ–éƒ¨åˆ†åœ–è¡¨\n",
    "- `delete_entity`: åˆªé™¤å¯¦é«”åŠå…¶é—œè¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e16c9",
   "metadata": {},
   "source": [
    "## Section 3: åˆå§‹åŒ– Memory MCP é€£æ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941be106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.mcp import MCPServerStdio\n",
    "import logging\n",
    "\n",
    "# è¨­ç½®æ—¥èªŒ\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# å…¨åŸŸè®Šæ•¸ç”¨æ–¼å­˜å„² MCP ä¼ºæœå™¨å¯¦ä¾‹å’Œ exit stack\n",
    "memory_mcp = None\n",
    "_exit_stack = None\n",
    "\n",
    "async def initialize_memory_mcp():\n",
    "    \"\"\"\n",
    "    åˆå§‹åŒ– Memory MCP ä¼ºæœå™¨\n",
    "    \n",
    "    Returns:\n",
    "        MCPServerStdio: Memory MCP ä¼ºæœå™¨å¯¦ä¾‹\n",
    "    \"\"\"\n",
    "    global memory_mcp, _exit_stack\n",
    "    \n",
    "    try:\n",
    "        if not _exit_stack:\n",
    "            _exit_stack = AsyncExitStack()\n",
    "        \n",
    "        # é…ç½® LibSQL è³‡æ–™åº«è·¯å¾‘\n",
    "        memory_db_path = project_root / \"backend\" / \"memory\" / \"test_memory.db\"\n",
    "        memory_db_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(\"ğŸ“¦ åˆå§‹åŒ– Memory MCP...\")\n",
    "        print(f\"   Database: {memory_db_path}\")\n",
    "        \n",
    "        memory_mcp = await _exit_stack.enter_async_context(\n",
    "            MCPServerStdio(\n",
    "                name=\"memory_mcp\",\n",
    "                params={\n",
    "                    \"command\": \"npx\",\n",
    "                    \"args\": [\"-y\", \"mcp-memory-libsql\"],\n",
    "                    \"env\": {\"LIBSQL_URL\": f\"file:{memory_db_path}\"},\n",
    "                },\n",
    "                client_session_timeout_seconds=30.0,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(\"âœ“ Memory MCP åˆå§‹åŒ–å®Œæˆ\")\n",
    "        return memory_mcp\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— åˆå§‹åŒ–å¤±æ•—: {type(e).__name__}: {str(e)}\")\n",
    "        if _exit_stack:\n",
    "            await _exit_stack.aclose()\n",
    "            _exit_stack = None\n",
    "        raise\n",
    "\n",
    "async def list_available_tools():\n",
    "    \"\"\"\n",
    "    åˆ—å‡º Memory MCP æä¾›çš„æ‰€æœ‰å·¥å…·\n",
    "    \"\"\"\n",
    "    global memory_mcp\n",
    "    \n",
    "    try:\n",
    "        if not memory_mcp:\n",
    "            print(\"âœ— Memory MCP æœªåˆå§‹åŒ–\")\n",
    "            return []\n",
    "        \n",
    "        # åˆ—å‡ºå¯ç”¨å·¥å…·\n",
    "        tools_result = await memory_mcp.session.list_tools()\n",
    "        tools = tools_result.tools if hasattr(tools_result, 'tools') else []\n",
    "        \n",
    "        print(\"\\nğŸ“‹ Memory MCP å¯ç”¨å·¥å…·:\")\n",
    "        print(\"-\" * 60)\n",
    "        for tool in tools:\n",
    "            print(f\"  â€¢ {tool.name}\")\n",
    "            if hasattr(tool, 'description'):\n",
    "                print(f\"    æè¿°: {tool.description}\")\n",
    "        \n",
    "        return tools\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— åˆ—å‡ºå·¥å…·å¤±æ•—: {type(e).__name__}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# åŸ·è¡Œåˆå§‹åŒ–\n",
    "print(\"=\" * 60)\n",
    "print(\"æ­£åœ¨åˆå§‹åŒ– Memory MCP...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "memory_mcp = await initialize_memory_mcp()\n",
    "tools = await list_available_tools()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2615a82",
   "metadata": {},
   "source": [
    "## Section 4: æ¸¬è©¦ create_entities å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_create_entities():\n",
    "    \"\"\"\n",
    "    æ¸¬è©¦ create_entities å·¥å…·\n",
    "    \n",
    "    æ­¤å·¥å…·ç”¨æ–¼å»ºç«‹æˆ–æ›´æ–°è¨˜æ†¶é«”ä¸­çš„å¯¦é«”ã€‚\n",
    "    éŸ¿æ‡‰æ ¼å¼ï¼šåŒ…å« content åˆ—è¡¨ï¼Œå…¶ä¸­ç¬¬ä¸€é …æ˜¯ TextContent\n",
    "    \"\"\"\n",
    "    global memory_mcp\n",
    "    \n",
    "    if not memory_mcp:\n",
    "        print(\"âœ— Memory MCP æœªåˆå§‹åŒ–\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"æ¸¬è©¦: create_entities\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # å»ºç«‹æ¸¬è©¦å¯¦é«”\n",
    "        test_entity = {\n",
    "            \"name\": \"agent_test_123_execution_2025\",\n",
    "            \"entityType\": \"trading_execution\",\n",
    "            \"observations\": [\n",
    "                \"Mode: AUTO_TRADING\",\n",
    "                \"Buy TSMC 2330 100 shares\",\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        print(\"\\nğŸ“¤ ç™¼é€è«‹æ±‚:\")\n",
    "        print(\"   å·¥å…·: create_entities\")\n",
    "        print(f\"   å¯¦é«”: {test_entity['name']}\")\n",
    "        print(f\"   é¡å‹: {test_entity['entityType']}\")\n",
    "        \n",
    "        result = await memory_mcp.session.call_tool(\n",
    "            \"create_entities\",\n",
    "            {\n",
    "                \"entities\": [test_entity]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # è§£æå›æ‡‰\n",
    "        print(f\"\\nğŸ“¥ æ”¶åˆ°å›æ‡‰:\")\n",
    "        print(f\"   é¡å‹: {type(result)}\")\n",
    "        print(f\"   å±¬æ€§: {dir(result)}\")\n",
    "        \n",
    "        if hasattr(result, \"content\") and result.content:\n",
    "            print(f\"   Content é¡å‹: {type(result.content)}\")\n",
    "            print(f\"   Content é•·åº¦: {len(result.content)}\")\n",
    "            \n",
    "            for i, content_item in enumerate(result.content):\n",
    "                print(f\"\\n   [Content {i}]\")\n",
    "                print(f\"     é¡å‹: {type(content_item)}\")\n",
    "                print(f\"     å±¬æ€§: {dir(content_item)}\")\n",
    "                \n",
    "                if hasattr(content_item, \"text\"):\n",
    "                    print(f\"     æ–‡æœ¬: {content_item.text[:200]}...\")\n",
    "                elif hasattr(content_item, \"value\"):\n",
    "                    print(f\"     å€¼: {content_item.value}\")\n",
    "        else:\n",
    "            print(f\"   ç„¡ content å±¬æ€§æˆ–ç‚ºç©º\")\n",
    "        \n",
    "        print(f\"\\nâœ“ create_entities æ¸¬è©¦å®Œæˆ\")\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— éŒ¯èª¤: {type(e).__name__}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# åŸ·è¡Œæ¸¬è©¦\n",
    "result_create = await test_create_entities()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a9db1",
   "metadata": {},
   "source": [
    "## Section 5: æ¸¬è©¦ search_nodes å·¥å…·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5588ba0b",
   "metadata": {},
   "source": [
    "## Section 5.5: search_nodes å·¥ä½œåŸç†è©³è§£\n",
    "\n",
    "æ ¹æ“šå®˜æ–¹æºç¢¼åˆ†æï¼ˆhttps://github.com/joleyline/mcp-memory-libsqlï¼‰ï¼Œ`search_nodes` çš„æŸ¥è©¢é‚è¼¯å¦‚ä¸‹ï¼š\n",
    "\n",
    "### æŸ¥è©¢æµç¨‹\n",
    "\n",
    "1. **å‘é‡æœå°‹å„ªå…ˆ**ï¼ˆå¦‚æœæœ‰ embeddingï¼‰\n",
    "   - å°‡æ–‡æœ¬æŸ¥è©¢è½‰æ›ç‚º embedding å‘é‡\n",
    "   - ä½¿ç”¨ `vector_distance_cos()` é€²è¡Œå‘é‡ç›¸ä¼¼åº¦æœå°‹\n",
    "   - è¿”å›æœ€ç›¸ä¼¼çš„ 5 å€‹å¯¦é«”\n",
    "\n",
    "2. **å›é€€åˆ°æ–‡æœ¬æœå°‹**ï¼ˆembedding ç”Ÿæˆå¤±æ•—æˆ–æœå°‹ç„¡çµæœæ™‚ï¼‰\n",
    "   - ä½¿ç”¨ `LIKE` èªå¥é€²è¡Œæ¨¡ç³ŠåŒ¹é…\n",
    "   - åœ¨ `name`ã€`entity_type`ã€`observations` ä¸­æœå°‹\n",
    "   - è¿”å›æœ€å¤š 5 å€‹çµæœ\n",
    "\n",
    "3. **é‡è¦é™åˆ¶**\n",
    "   - âš ï¸ **æœ€å¤šè¿”å› 5 å€‹çµæœ**ï¼ˆä¸å— limit åƒæ•¸å½±éŸ¿ï¼‰\n",
    "   - âš ï¸ å‘é‡æœå°‹åªæœå°‹ `embedding IS NOT NULL` çš„å¯¦é«”\n",
    "   - âš ï¸ æ–‡æœ¬æœå°‹æ˜¯æ¨¡ç³ŠåŒ¹é…ï¼ˆLIKE %query%ï¼‰\n",
    "\n",
    "### æŸ¥è©¢ç„¡çµæœçš„åŸå› \n",
    "\n",
    "| åŸå›  | æè¿° |\n",
    "|-----|------|\n",
    "| è³‡æ–™åº«ç‚ºç©º | æ²’æœ‰ä»»ä½•å¯¦é«”è¢«ä¿å­˜ |\n",
    "| æ²’æœ‰ embedding | å¯¦é«”è¢«ä¿å­˜ï¼Œä½†æ²’æœ‰å‘é‡åŒ–ä¿¡æ¯ |\n",
    "| æŸ¥è©¢ä¸åŒ¹é… | æ–‡æœ¬æœå°‹æ™‚ï¼ŒæŸ¥è©¢é—œéµå­—ä¸åŒ¹é…ä»»ä½•å¯¦é«” |\n",
    "| å‘é‡ç›¸ä¼¼åº¦éä½ | æŸ¥è©¢èˆ‡ä»»ä½•å¯¦é«”çš„å‘é‡è·é›¢éƒ½è¶…éé–¾å€¼ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488b4bdc",
   "metadata": {},
   "source": [
    "## Entity, Observation, Relation ä¹‹é–“çš„é—œä¿‚\n",
    "\n",
    "æ ¹æ“šå®˜æ–¹æºç¢¼åˆ†æï¼Œmcp-memory-libsql çš„æ•¸æ“šæ¨¡å‹æ¡ç”¨**çŸ¥è­˜åœ–è­œï¼ˆKnowledge Graphï¼‰**çµæ§‹ã€‚\n",
    "\n",
    "### ğŸ“Š æ•¸æ“šçµæ§‹åœ–\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    KNOWLEDGE GRAPH                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "              \n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚   ENTITY 1   â”‚\n",
    "              â”‚ (çŸ¥è­˜åœ–çš„ç¯€é») â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚           â”‚           â”‚\n",
    "    â”Œâ”€â”€â”€â”€vâ”€â”€â”€â”€â”€â” â”Œâ”€â”€vâ”€â”€â”€â”€â”€â”€â” â”Œâ”€vâ”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚Obs 1     â”‚ â”‚Obs 2    â”‚ â”‚Obs 3     â”‚\n",
    "    â”‚(è§€æ¸¬/æ€§è³ª)â”‚ â”‚(è§€æ¸¬/æ€§è³ª)â”‚ â”‚(è§€æ¸¬/æ€§è³ª)â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "    â”Œâ”€â”€â”€â”€vâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ RELATION      â”‚\n",
    "    â”‚ (é€£æ¥é—œä¿‚)     â”‚\n",
    "    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â”‚\n",
    "    â”Œâ”€â”€â”€vâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚   ENTITY 2   â”‚\n",
    "    â”‚ (çŸ¥è­˜åœ–çš„ç¯€é») â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "    â”Œâ”€â”€â”€â”€vâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ Obs A, B, C   â”‚\n",
    "    â”‚  (è§€æ¸¬/æ€§è³ª)   â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### ğŸ“‘ æ•¸æ“šåº«è¡¨çµæ§‹\n",
    "\n",
    "æ ¹æ“š `database-service.ts` çš„ schemaï¼š\n",
    "\n",
    "#### 1. **ENTITIES è¡¨**ï¼ˆçŸ¥è­˜åœ–çš„ç¯€é»ï¼‰\n",
    "```sql\n",
    "CREATE TABLE entities (\n",
    "  name TEXT PRIMARY KEY,          -- å¯¦é«”å”¯ä¸€åç¨± (å¦‚ \"TSMC_stock\")\n",
    "  entity_type TEXT NOT NULL,      -- å¯¦é«”é¡å‹ (å¦‚ \"stock\", \"decision\", \"analysis\")\n",
    "  embedding F32_BLOB,             -- å‘é‡è¡¨ç¤ºï¼ˆç”¨æ–¼èªç¾©æœå°‹ï¼‰\n",
    "  created_at DATETIME             -- å»ºç«‹æ™‚é–“\n",
    ")\n",
    "```\n",
    "\n",
    "**ä¾‹å­ï¼š**\n",
    "```\n",
    "name: \"trading_decision_2025_01_15\"\n",
    "entity_type: \"trading_decision\"\n",
    "embedding: [0.1, 0.2, 0.3, ...]  -- 384ç¶­å‘é‡\n",
    "created_at: 2025-01-15 10:30:00\n",
    "```\n",
    "\n",
    "#### 2. **OBSERVATIONS è¡¨**ï¼ˆå¯¦é«”çš„å±¬æ€§/è§€æ¸¬ï¼‰\n",
    "```sql\n",
    "CREATE TABLE observations (\n",
    "  id INTEGER PRIMARY KEY,\n",
    "  entity_name TEXT NOT NULL,      -- å¤–éµï¼šæŒ‡å‘ entities è¡¨\n",
    "  content TEXT NOT NULL,          -- è§€æ¸¬å…§å®¹\n",
    "  created_at DATETIME,\n",
    "  FOREIGN KEY (entity_name) REFERENCES entities(name)\n",
    ")\n",
    "```\n",
    "\n",
    "**ä¾‹å­ï¼š**\n",
    "```\n",
    "id: 1\n",
    "entity_name: \"trading_decision_2025_01_15\"\n",
    "content: \"2025-01-15 10:30 è²·å…¥æ±ºç­–\"\n",
    "\n",
    "id: 2\n",
    "entity_name: \"trading_decision_2025_01_15\"\n",
    "content: \"TSMC 2330 ç›®æ¨™åƒ¹ 620 å…ƒ\"\n",
    "\n",
    "id: 3\n",
    "entity_name: \"trading_decision_2025_01_15\"\n",
    "content: \"æŠ€è¡“æŒ‡æ¨™: RSI 40, MACD æ­£å‘\"\n",
    "```\n",
    "\n",
    "#### 3. **RELATIONS è¡¨**ï¼ˆå¯¦é«”ä¹‹é–“çš„é€£æ¥ï¼‰\n",
    "```sql\n",
    "CREATE TABLE relations (\n",
    "  id INTEGER PRIMARY KEY,\n",
    "  source TEXT NOT NULL,           -- å¤–éµï¼šæºå¯¦é«”åç¨±\n",
    "  target TEXT NOT NULL,           -- å¤–éµï¼šç›®æ¨™å¯¦é«”åç¨±\n",
    "  relation_type TEXT NOT NULL,    -- é—œä¿‚é¡å‹ (å¦‚ \"caused_by\", \"related_to\")\n",
    "  created_at DATETIME,\n",
    "  FOREIGN KEY (source) REFERENCES entities(name),\n",
    "  FOREIGN KEY (target) REFERENCES entities(name)\n",
    ")\n",
    "```\n",
    "\n",
    "**ä¾‹å­ï¼š**\n",
    "```\n",
    "id: 1\n",
    "source: \"trading_decision_2025_01_15\"\n",
    "target: \"market_analysis_2025_01_15\"\n",
    "relation_type: \"based_on\"\n",
    "\n",
    "id: 2\n",
    "source: \"trading_decision_2025_01_15\"\n",
    "target: \"trading_result_2025_01_14\"\n",
    "relation_type: \"follows_up\"\n",
    "```\n",
    "\n",
    "### ğŸ”— å®Œæ•´é—œä¿‚ç¤ºæ„\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    ENTITY (å¯¦é«”/ç¯€é»)                            â”‚\n",
    "â”‚  name: \"trading_decision_2025_01_15\"                            â”‚\n",
    "â”‚  type: \"trading_decision\"                                       â”‚\n",
    "â”‚  embedding: [0.1, 0.2, ...]                                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚                             â”‚\n",
    "         â”‚ (1:N é—œä¿‚)                  â”‚ (N:N é—œä¿‚)\n",
    "         â”‚                             â”‚\n",
    "    â”Œâ”€â”€â”€â”€vâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€vâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚  OBSERVATIONS     â”‚         â”‚   RELATIONS         â”‚\n",
    "    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "    â”‚ id: 1             â”‚         â”‚ id: 1               â”‚\n",
    "    â”‚ content: \"è²·å…¥...\"â”‚         â”‚ source: this entity â”‚\n",
    "    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚ target: other entityâ”‚\n",
    "    â”‚ id: 2             â”‚         â”‚ type: \"based_on\"    â”‚\n",
    "    â”‚ content: \"ç›®æ¨™...\"â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "    â”‚ id: 3             â”‚\n",
    "    â”‚ content: \"æŠ€è¡“...\"â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### ğŸ’¡ ä¸‰è€…çš„è§’è‰²å®šç¾©\n",
    "\n",
    "| çµ„ä»¶ | ç”¨é€” | ä¾‹å­ |\n",
    "|-----|------|------|\n",
    "| **Entity** | çŸ¥è­˜åœ–çš„**ç¯€é»** | \"TSMCè‚¡ç¥¨\", \"è²·å…¥æ±ºç­–\", \"å¸‚å ´åˆ†æ\" |\n",
    "| **Observation** | Entity çš„**å±¬æ€§æˆ–äº‹å¯¦** | \"TSMCè‚¡åƒ¹ 615å…ƒ\", \"æŠ€è¡“æŒ‡æ¨™çœ‹å¥½\" |\n",
    "| **Relation** | Entity é–“çš„**é€£æ¥** | \"æ±ºç­–åŸºæ–¼åˆ†æ\", \"çµæœä¾†è‡ªæ±ºç­–\" |\n",
    "\n",
    "### ğŸ” å¯¦éš›å·¥ä½œæµç¨‹ç¤ºä¾‹\n",
    "\n",
    "```python\n",
    "# 1. å‰µå»ºç¬¬ä¸€å€‹å¯¦é«” + è§€æ¸¬\n",
    "await memory_mcp.session.call_tool(\n",
    "  \"create_entities\",\n",
    "  {\n",
    "    \"entities\": [{\n",
    "      \"name\": \"market_analysis_2025_01_15\",      # Entity\n",
    "      \"entityType\": \"market_analysis\",\n",
    "      \"observations\": [                          # Observations\n",
    "        \"å°ç£è‚¡å¸‚é–‹ç›¤ 17,500\",\n",
    "        \"åŠå°é«”æ¿å¡Šæ¼²å¹… 2.3%\",\n",
    "        \"TSMC å‡ºç¾è²·å…¥æ©Ÿæœƒ\"\n",
    "      ]\n",
    "    }]\n",
    "  }\n",
    ")\n",
    "\n",
    "# 2. å‰µå»ºç¬¬äºŒå€‹å¯¦é«” + è§€æ¸¬ + é—œä¿‚\n",
    "await memory_mcp.session.call_tool(\n",
    "  \"create_entities\",\n",
    "  {\n",
    "    \"entities\": [{\n",
    "      \"name\": \"trading_decision_2025_01_15\",     # Entity\n",
    "      \"entityType\": \"trading_decision\",\n",
    "      \"observations\": [                          # Observations\n",
    "        \"åŸºæ–¼å¸‚å ´åˆ†ææ±ºå®šè²·å…¥\",\n",
    "        \"TSMC 2330 ç›®æ¨™åƒ¹ 620 å…ƒ\",\n",
    "        \"è²·å…¥ 1000 è‚¡\"\n",
    "      ],\n",
    "      \"relations\": [{                            # Relations\n",
    "        \"target\": \"market_analysis_2025_01_15\",\n",
    "        \"relationType\": \"based_on\"\n",
    "      }]\n",
    "    }]\n",
    "  }\n",
    ")\n",
    "\n",
    "# 3. æŸ¥è©¢æ™‚ï¼Œæœƒè¿”å›å®Œæ•´çš„é—œä¿‚åœ–\n",
    "result = await memory_mcp.session.call_tool(\"read_graph\", {})\n",
    "# è¿”å›:\n",
    "# {\n",
    "#   \"nodes\": [\n",
    "#     {entity data},\n",
    "#     {entity data}\n",
    "#   ],\n",
    "#   \"relations\": [\n",
    "#     {relation data}\n",
    "#   ]\n",
    "# }\n",
    "```\n",
    "\n",
    "### ğŸ¯ è¨­è¨ˆå„ªå‹¢\n",
    "\n",
    "1. **éˆæ´»çš„å±¬æ€§ç³»çµ±**\n",
    "   - Entity æœ¬èº«åªæœ‰ nameã€typeã€embedding\n",
    "   - æ‰€æœ‰ç´°ç¯€ä¿¡æ¯å­˜åœ¨ Observationsï¼ˆå¯ä»¥ä»»æ„æ·»åŠ ï¼‰\n",
    "\n",
    "2. **å®Œæ•´çš„çŸ¥è­˜åœ–è­œ**\n",
    "   - é€šé Relations é€£æ¥ä¸åŒå¯¦é«”\n",
    "   - æ”¯æŒè¤‡é›œçš„æ¥­å‹™é‚è¼¯è¡¨é”\n",
    "\n",
    "3. **é«˜æ•ˆçš„å‘é‡æœå°‹**\n",
    "   - Entity ç´šåˆ¥çš„ embedding ç”¨æ–¼èªç¾©æœå°‹\n",
    "   - Observation æ–‡æœ¬ç”¨æ–¼é—œéµè©æœå°‹\n",
    "\n",
    "4. **å¤–éµç´„æŸ**\n",
    "   - ä¿è­‰æ•¸æ“šå®Œæ•´æ€§\n",
    "   - Observations å’Œ Relations å¿…é ˆæŒ‡å‘æœ‰æ•ˆçš„ Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demo_entity_observation_relation():\n",
    "    \"\"\"\n",
    "    æ¼”ç¤º Entityã€Observationã€Relation ä¹‹é–“çš„å¯¦éš›é—œä¿‚\n",
    "    \n",
    "    ä½¿ç”¨äº¤æ˜“å ´æ™¯å±•ç¤ºå®Œæ•´çš„çŸ¥è­˜åœ–è­œæ§‹å»º\n",
    "    \"\"\"\n",
    "    global memory_mcp\n",
    "    \n",
    "    if not memory_mcp:\n",
    "        print(\"âœ— Memory MCP æœªåˆå§‹åŒ–\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"æ¼”ç¤º: Entityã€Observationã€Relation çš„å®Œæ•´é—œä¿‚\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ç¬¬ä¸€æ­¥: å‰µå»ºå¸‚å ´åˆ†æå¯¦é«”ï¼ˆåªæœ‰è§€æ¸¬ï¼Œæ²’æœ‰é—œä¿‚ï¼‰\n",
    "    print(\"\\n1ï¸âƒ£  å‰µå»ºå¸‚å ´åˆ†æå¯¦é«”ï¼ˆEntity + Observationsï¼‰\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    market_analysis = {\n",
    "        \"name\": \"market_analysis_2025_01_15\",\n",
    "        \"entityType\": \"market_analysis\",\n",
    "        \"observations\": [\n",
    "            \"å°ç£è‚¡å¸‚é–‹ç›¤ 17,500 é»\",\n",
    "            \"åŠå°é«”æ¿å¡Šæ¼²å¹… 2.3%\",\n",
    "            \"å¤–è³‡æ·¨è²·è¶… 150 å„„\",\n",
    "            \"TSMC å‡ºç¾æŠ€è¡“è²·å…¥æ©Ÿæœƒ\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ“ Entity ä¿¡æ¯:\")\n",
    "    print(f\"  â€¢ name: {market_analysis['name']}\")\n",
    "    print(f\"  â€¢ entityType: {market_analysis['entityType']}\")\n",
    "    print(f\"\\nğŸ“Š Observations ({len(market_analysis['observations'])} å€‹):\")\n",
    "    for i, obs in enumerate(market_analysis['observations'], 1):\n",
    "        print(f\"  {i}. {obs}\")\n",
    "    \n",
    "    try:\n",
    "        result = await memory_mcp.session.call_tool(\n",
    "            \"create_entities\",\n",
    "            {\"entities\": [market_analysis]}\n",
    "        )\n",
    "        print(f\"\\nâœ… å¯¦é«”å‰µå»ºæˆåŠŸ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å‰µå»ºå¤±æ•—: {e}\")\n",
    "        return\n",
    "    \n",
    "    # ç¬¬äºŒæ­¥: å‰µå»ºäº¤æ˜“æ±ºç­–å¯¦é«”ï¼ˆåŒ…å« Relationï¼‰\n",
    "    print(\"\\n\\n2ï¸âƒ£  å‰µå»ºäº¤æ˜“æ±ºç­–å¯¦é«”ï¼ˆEntity + Observations + Relationsï¼‰\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    trading_decision = {\n",
    "        \"name\": \"trading_decision_2025_01_15\",\n",
    "        \"entityType\": \"trading_decision\",\n",
    "        \"observations\": [\n",
    "            \"æ™‚é–“: 2025-01-15 10:30\",\n",
    "            \"æ±ºç­–: è²·å…¥ TSMC 2330\",\n",
    "            \"æ•¸é‡: 1000 è‚¡\",\n",
    "            \"ç›®æ¨™åƒ¹: 620 å…ƒ\",\n",
    "            \"æŠ€è¡“æŒ‡æ¨™: RSI 35(è¶…è³£), MACD æ­£å‘äº¤å‰\",\n",
    "            \"ç†ç”±: åŸºæ–¼å¸‚å ´åˆ†æå’ŒæŠ€è¡“ä¿¡è™Ÿ\"\n",
    "        ],\n",
    "        \"relations\": [{\n",
    "            \"target\": \"market_analysis_2025_01_15\",\n",
    "            \"relationType\": \"based_on\"  # æ­¤æ±ºç­–åŸºæ–¼é‚£å€‹å¸‚å ´åˆ†æ\n",
    "        }]\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ“ Entity ä¿¡æ¯:\")\n",
    "    print(f\"  â€¢ name: {trading_decision['name']}\")\n",
    "    print(f\"  â€¢ entityType: {trading_decision['entityType']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Observations ({len(trading_decision['observations'])} å€‹):\")\n",
    "    for i, obs in enumerate(trading_decision['observations'], 1):\n",
    "        print(f\"  {i}. {obs}\")\n",
    "    \n",
    "    print(f\"\\nğŸ”— Relations ({len(trading_decision['relations'])} å€‹):\")\n",
    "    for i, rel in enumerate(trading_decision['relations'], 1):\n",
    "        print(f\"  {i}. é—œä¿‚é¡å‹: {rel['relationType']}\")\n",
    "        print(f\"     ç›®æ¨™: {rel['target']}\")\n",
    "    \n",
    "    try:\n",
    "        result = await memory_mcp.session.call_tool(\n",
    "            \"create_entities\",\n",
    "            {\"entities\": [trading_decision]}\n",
    "        )\n",
    "        print(f\"\\nâœ… å¯¦é«”å‰µå»ºæˆåŠŸ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å‰µå»ºå¤±æ•—: {e}\")\n",
    "        return\n",
    "    \n",
    "    # ç¬¬ä¸‰æ­¥: å‰µå»ºäº¤æ˜“çµæœå¯¦é«”ï¼ˆæœ‰å¤šå€‹relationï¼‰\n",
    "    print(\"\\n\\n3ï¸âƒ£  å‰µå»ºäº¤æ˜“çµæœå¯¦é«”ï¼ˆå¤šå€‹ Relationsï¼‰\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    trading_result = {\n",
    "        \"name\": \"trading_result_2025_01_15\",\n",
    "        \"entityType\": \"trading_result\",\n",
    "        \"observations\": [\n",
    "            \"äº¤æ˜“æˆäº¤æ™‚é–“: 2025-01-15 10:35\",\n",
    "            \"æˆäº¤åƒ¹: 615 å…ƒ\",\n",
    "            \"æˆäº¤è‚¡æ•¸: 1000 è‚¡\",\n",
    "            \"äº¤æ˜“ç¸½é¡: 615,000 å…ƒ\",\n",
    "            \"æ‰‹çºŒè²»: 123 å…ƒ\",\n",
    "            \"å¯¦éš›æˆæœ¬: 615,123 å…ƒ\",\n",
    "            \"äº¤æ˜“ç‹€æ…‹: æˆåŠŸ\"\n",
    "        ],\n",
    "        \"relations\": [\n",
    "            {\n",
    "                \"target\": \"trading_decision_2025_01_15\",\n",
    "                \"relationType\": \"executes\"  # åŸ·è¡Œé€™å€‹æ±ºç­–\n",
    "            },\n",
    "            {\n",
    "                \"target\": \"market_analysis_2025_01_15\",\n",
    "                \"relationType\": \"related_to\"  # èˆ‡å¸‚å ´åˆ†æç›¸é—œ\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ“ Entity ä¿¡æ¯:\")\n",
    "    print(f\"  â€¢ name: {trading_result['name']}\")\n",
    "    print(f\"  â€¢ entityType: {trading_result['entityType']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Observations ({len(trading_result['observations'])} å€‹):\")\n",
    "    for i, obs in enumerate(trading_result['observations'], 1):\n",
    "        print(f\"  {i}. {obs}\")\n",
    "    \n",
    "    print(f\"\\nğŸ”— Relations ({len(trading_result['relations'])} å€‹):\")\n",
    "    for i, rel in enumerate(trading_result['relations'], 1):\n",
    "        print(f\"  {i}. é—œä¿‚é¡å‹: {rel['relationType']}\")\n",
    "        print(f\"     ç›®æ¨™: {rel['target']}\")\n",
    "    \n",
    "    try:\n",
    "        result = await memory_mcp.session.call_tool(\n",
    "            \"create_entities\",\n",
    "            {\"entities\": [trading_result]}\n",
    "        )\n",
    "        print(f\"\\nâœ… å¯¦é«”å‰µå»ºæˆåŠŸ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å‰µå»ºå¤±æ•—: {e}\")\n",
    "        return\n",
    "    \n",
    "    # ç¬¬å››æ­¥: è®€å–å®Œæ•´çŸ¥è­˜åœ–è­œ\n",
    "    print(\"\\n\\n4ï¸âƒ£  è®€å–å®Œæ•´çŸ¥è­˜åœ–è­œ\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    try:\n",
    "        result = await memory_mcp.session.call_tool(\n",
    "            \"read_graph\",\n",
    "            {}\n",
    "        )\n",
    "        \n",
    "        if hasattr(result, \"content\") and result.content:\n",
    "            content_item = result.content[0]\n",
    "            text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(text_content)\n",
    "                entities = data.get(\"nodes\", [])\n",
    "                relations = data.get(\"relations\", [])\n",
    "                \n",
    "                print(f\"âœ… åœ–è­œè®€å–æˆåŠŸ\")\n",
    "                print(f\"\\nğŸ“Š åœ–è­œçµ±è¨ˆ:\")\n",
    "                print(f\"  â€¢ ç¸½å¯¦é«”æ•¸: {len(entities)}\")\n",
    "                print(f\"  â€¢ ç¸½é—œä¿‚æ•¸: {len(relations)}\")\n",
    "                \n",
    "                # é¡¯ç¤ºå¯¦é«”åˆ—è¡¨\n",
    "                print(f\"\\nğŸ”¹ å¯¦é«”åˆ—è¡¨:\")\n",
    "                for i, entity in enumerate(entities, 1):\n",
    "                    obs_count = len(entity.get('observations', []))\n",
    "                    print(f\"  {i}. {entity.get('name', 'N/A')}\")\n",
    "                    print(f\"     é¡å‹: {entity.get('entityType', 'N/A')}\")\n",
    "                    print(f\"     è§€æ¸¬æ•¸: {obs_count}\")\n",
    "                \n",
    "                # é¡¯ç¤ºé—œä¿‚åˆ—è¡¨\n",
    "                print(f\"\\nğŸ”— é—œä¿‚åˆ—è¡¨:\")\n",
    "                for i, relation in enumerate(relations, 1):\n",
    "                    print(f\"  {i}. {relation.get('from', 'N/A')}\")\n",
    "                    print(f\"     â”€({relation.get('relationType', 'N/A')})â†’\")\n",
    "                    print(f\"     {relation.get('to', 'N/A')}\")\n",
    "                \n",
    "                # ç¹ªè£½çŸ¥è­˜åœ–è­œ\n",
    "                print(f\"\\nğŸ“ˆ çŸ¥è­˜åœ–è­œå¯è¦–åŒ–:\")\n",
    "                print(f\"\\n  å¸‚å ´åˆ†æ\")\n",
    "                print(f\"       â†‘\")\n",
    "                print(f\"  based_on\")\n",
    "                print(f\"       â†‘\")\n",
    "                print(f\"   äº¤æ˜“æ±ºç­– â†â”€â”€related_toâ”€â”€ äº¤æ˜“çµæœ\")\n",
    "                print(f\"       â†‘                    â†“\")\n",
    "                print(f\"       â””â”€â”€â”€â”€executesâ”€â”€â”€â”€â†’ (åŸ·è¡Œæ±ºç­–)\")\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"âŒ JSON è§£æå¤±æ•—: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è®€å–åœ–è­œå¤±æ•—: {e}\")\n",
    "    \n",
    "    # ç¬¬äº”æ­¥: æ¼”ç¤ºæœå°‹\n",
    "    print(\"\\n\\n5ï¸âƒ£  æ¼”ç¤ºæœå°‹åŠŸèƒ½\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    search_queries = [\n",
    "        \"TSMC è²·å…¥\",\n",
    "        \"äº¤æ˜“æ±ºç­–\",\n",
    "        \"å¸‚å ´åˆ†æ\"\n",
    "    ]\n",
    "    \n",
    "    for query in search_queries:\n",
    "        print(f\"\\næœå°‹: '{query}'\")\n",
    "        try:\n",
    "            result = await memory_mcp.session.call_tool(\n",
    "                \"search_nodes\",\n",
    "                {\"query\": query, \"limit\": 10}\n",
    "            )\n",
    "            \n",
    "            if hasattr(result, \"content\") and result.content:\n",
    "                content_item = result.content[0]\n",
    "                text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "                \n",
    "                try:\n",
    "                    data = json.loads(text_content)\n",
    "                    found_nodes = data.get(\"nodes\", [])\n",
    "                    \n",
    "                    if found_nodes:\n",
    "                        print(f\"  âœ… æ‰¾åˆ° {len(found_nodes)} å€‹çµæœ:\")\n",
    "                        for i, node in enumerate(found_nodes[:3], 1):\n",
    "                            print(f\"    {i}. {node.get('name')}\")\n",
    "                    else:\n",
    "                        print(f\"  âš ï¸  ç„¡çµæœ\")\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"  âŒ è§£æå¤±æ•—\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ æŸ¥è©¢å¤±æ•—: {e}\")\n",
    "    \n",
    "    print(f\"\\nâœ… æ¼”ç¤ºå®Œæˆ\")\n",
    "\n",
    "# åŸ·è¡Œæ¼”ç¤º\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"é–‹å§‹ Entityã€Observationã€Relation é—œä¿‚æ¼”ç¤º\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "await demo_entity_observation_relation()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ce2d8",
   "metadata": {},
   "source": [
    "## æ ¸å¿ƒç™¼ç¾ï¼šsearch_nodes æŸ¥è©¢ç„¡çµæœçš„çœŸæ­£åŸå› \n",
    "\n",
    "åŸºæ–¼å®˜æ–¹æºç¢¼å’Œå¯¦éš›æ¸¬è©¦çš„åˆ†æï¼Œå•é¡Œç¢ºèªå¦‚ä¸‹ï¼š\n",
    "\n",
    "### å•é¡Œåˆ†æ\n",
    "\n",
    "`search_nodes` ç„¡æ³•æŸ¥åˆ°è¨˜éŒ„çš„æ ¹æœ¬åŸå› ä¸æ˜¯**æŸ¥è©¢èªå¥å•é¡Œ**ï¼Œè€Œæ˜¯ï¼š\n",
    "\n",
    "1. **search_nodes çš„å·¥ä½œåŸç†**ï¼ˆä¾†è‡ªå®˜æ–¹æºç¢¼ï¼‰\n",
    "   ```\n",
    "   if æŸ¥è©¢æ˜¯æ–‡æœ¬:\n",
    "       1. å…ˆå˜—è©¦ç‚ºæ–‡æœ¬ç”Ÿæˆ embedding å‘é‡\n",
    "       2. ä½¿ç”¨ vector_distance_cos() é€²è¡Œå‘é‡ç›¸ä¼¼åº¦æœå°‹\n",
    "       3. å¦‚æœå‘é‡æœå°‹æœ‰çµæœï¼Œè¿”å›ï¼ˆæœ€å¤š 5 å€‹ï¼‰\n",
    "       4. å¦å‰‡é™ç´šåˆ°æ–‡æœ¬æœå°‹ï¼šLIKE %query%\n",
    "   else æŸ¥è©¢æ˜¯å‘é‡:\n",
    "       ç›´æ¥é€²è¡Œå‘é‡ç›¸ä¼¼åº¦æœå°‹\n",
    "   ```\n",
    "\n",
    "2. **search_nodes çš„è¿”å›è¡Œç‚º**\n",
    "   - âœ… è¿”å›æ ¼å¼ï¼š`{\"nodes\": [], \"relations\": []}`\n",
    "   - âœ… å³ä½¿ç„¡çµæœä¹Ÿè¿”å›ç©ºæ•¸çµ„ï¼Œä¸æœƒå ±éŒ¯\n",
    "   - âš ï¸ æœ€å¤šè¿”å› 5 å€‹çµæœï¼ˆç¡¬é™åˆ¶ï¼Œä¸å— limit åƒæ•¸å½±éŸ¿ï¼‰\n",
    "   - âš ï¸ å‘é‡æœå°‹åªæœç´¢æœ‰ `embedding IS NOT NULL` çš„å¯¦é«”\n",
    "\n",
    "3. **ä½ é‡åˆ°çš„å…·é«”å•é¡Œ**\n",
    "   ```\n",
    "   create_entities: èªªæˆåŠŸå‰µå»º\n",
    "   ä½† read_graph: è¿”å› 0 å€‹å¯¦é«”\n",
    "   search_nodes: å› æ­¤ç„¡æ³•æ‰¾åˆ°ä»»ä½•è¨˜éŒ„\n",
    "   ```\n",
    "   \n",
    "   å¯èƒ½åŸå› ï¼š\n",
    "   - ğŸ¯ **è³‡æ–™åº«è·¯å¾‘å•é¡Œ**ï¼šæ¯æ¬¡åˆå§‹åŒ–æŒ‡å‘çš„å¯èƒ½æ˜¯ä¸åŒçš„ `.db` æ–‡ä»¶\n",
    "   - æˆ–ï¼šMCP server å‰µå»ºäº†å…§å­˜ä¸­çš„å¯¦é«”ï¼Œä½†æ²’æœ‰æŒä¹…åŒ–åˆ°ç£ç›¤\n",
    "\n",
    "### é©—è­‰æ–¹æ³•\n",
    "\n",
    "```python\n",
    "# 1. æª¢æŸ¥ read_graph è¿”å›çš„å¯¦é«”æ•¸\n",
    "result = await memory_mcp.session.call_tool(\"read_graph\", {})\n",
    "data = json.loads(result.content[0].text)\n",
    "print(f\"å¯¦é«”æ•¸: {len(data['nodes'])}\")  # æ‡‰è©² > 0\n",
    "\n",
    "# 2. å¦‚æœæ˜¯ 0ï¼Œç¢ºèª DB è·¯å¾‘\n",
    "print(memory_db_path)  # ç¢ºèªæŒ‡å‘çš„æ˜¯é æœŸçš„ .db æ–‡ä»¶\n",
    "\n",
    "# 3. å¦‚æœæœ‰å¯¦é«”ï¼Œæ¸¬è©¦ search_nodes\n",
    "result = await memory_mcp.session.call_tool(\n",
    "    \"search_nodes\", \n",
    "    {\"query\": \"ä½ çš„æŸ¥è©¢è©\"}\n",
    ")\n",
    "data = json.loads(result.content[0].text)\n",
    "print(f\"æ‰¾åˆ°: {len(data['nodes'])} å€‹çµæœ\")\n",
    "```\n",
    "\n",
    "### è§£æ±ºæ–¹æ¡ˆ\n",
    "\n",
    "1. **ç¢ºä¿è³‡æ–™åº«è·¯å¾‘ä¸€è‡´**\n",
    "   - æª¢æŸ¥ `initialize_memory_mcp()` ä¸­çš„ `LIBSQL_URL`\n",
    "   - ç¢ºä¿æ¯æ¬¡éƒ½æŒ‡å‘**åŒä¸€å€‹** `.db` æ–‡ä»¶\n",
    "\n",
    "2. **æŸ¥è©¢éœ€è¦åŒ¹é…å¯¦é«”å…§å®¹**\n",
    "   - æ–‡æœ¬æœå°‹ä½¿ç”¨ LIKE %query%ï¼Œå³ substring åŒ¹é…\n",
    "   - éœ€è¦æŸ¥è©¢è¯å‡ºç¾åœ¨å¯¦é«”çš„ `name`ã€`entityType` æˆ– `observations` ä¸­\n",
    "\n",
    "3. **æŸ¥è©¢èªå¥ç¤ºä¾‹**\n",
    "   ```python\n",
    "   # âœ… æ­£ç¢ºçš„æŸ¥è©¢\n",
    "   await memory_mcp.session.call_tool(\n",
    "       \"search_nodes\",\n",
    "       {\"query\": \"TSMC\"}  # å­—ç¬¦ä¸²æŸ¥è©¢\n",
    "   )\n",
    "   \n",
    "   # âœ… ä¹Ÿå¯ä»¥ç”¨å‘é‡\n",
    "   embedding = [0.1, 0.2, 0.3, ...]  # embedding æ•¸çµ„\n",
    "   await memory_mcp.session.call_tool(\n",
    "       \"search_nodes\",\n",
    "       {\"query\": embedding}  # å‘é‡æŸ¥è©¢\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33526f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_search_nodes_correct_usage():\n",
    "    \"\"\"\n",
    "    æ¼”ç¤º search_nodes çš„æ­£ç¢ºä½¿ç”¨æ–¹å¼\n",
    "    \n",
    "    åŸºæ–¼å®˜æ–¹æºç¢¼çš„ç†è§£ï¼š\n",
    "    - éœ€è¦å…ˆå‰µå»ºå¯¦é«”\n",
    "    - search_nodes æ”¯æŒæ–‡æœ¬æŸ¥è©¢å’Œå‘é‡æŸ¥è©¢\n",
    "    - è¿”å›æœ€å¤š 5 å€‹çµæœï¼ˆå…§éƒ¨é™åˆ¶ï¼‰\n",
    "    \"\"\"\n",
    "    global memory_mcp\n",
    "    \n",
    "    if not memory_mcp:\n",
    "        print(\"âœ— Memory MCP æœªåˆå§‹åŒ–\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"æ¼”ç¤º: search_nodes æ­£ç¢ºç”¨æ³•\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # æ­¥é©Ÿ 1: å‰µå»ºæ¸¬è©¦å¯¦é«”\n",
    "    print(\"\\n1ï¸âƒ£  å‰µå»ºæ¸¬è©¦å¯¦é«”\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    test_entities = [\n",
    "        {\n",
    "            \"name\": \"trading_decision_2025_01_15\",\n",
    "            \"entityType\": \"trading_decision\",\n",
    "            \"observations\": [\n",
    "                \"2025-01-15 10:30 è²·å…¥æ±ºç­–\",\n",
    "                \"TSMC 2330 ç›®æ¨™åƒ¹ 600 å…ƒ\",\n",
    "                \"æŠ€è¡“æŒ‡æ¨™: RSI 40, MACD æ­£å‘\",\n",
    "                \"æˆäº¤é‡ç¢ºèªä¸Šå‡è¶¨å‹¢\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"market_analysis_2025_01_15\",\n",
    "            \"entityType\": \"market_analysis\",\n",
    "            \"observations\": [\n",
    "                \"å°ç£è‚¡å¸‚é–‹ç›¤ 17,500\",\n",
    "                \"åŠå°é«”æ¿å¡Šæ¼²å¹… 2.3%\",\n",
    "                \"TSMC å‡ºç¾è²·å…¥æ©Ÿæœƒ\",\n",
    "                \"å¤–è³‡æ·¨è²·è¶… 150 å„„\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"trading_result_2025_01_14\",\n",
    "            \"entityType\": \"trading_result\",\n",
    "            \"observations\": [\n",
    "                \"2025-01-14 å®Œæˆäº¤æ˜“\",\n",
    "                \"è²·å…¥ TSMC 1000 è‚¡\",\n",
    "                \"æˆäº¤åƒ¹ 615 å…ƒ\",\n",
    "                \"ç›ˆåˆ© 3000 å…ƒ\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        for entity in test_entities:\n",
    "            result = await memory_mcp.session.call_tool(\n",
    "                \"create_entities\",\n",
    "                {\"entities\": [entity]}\n",
    "            )\n",
    "            print(f\"  âœ“ å‰µå»ºå¯¦é«”: {entity['name']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— å‰µå»ºå¯¦é«”å¤±æ•—: {e}\")\n",
    "        return\n",
    "    \n",
    "    # æ­¥é©Ÿ 2: æ¸¬è©¦æ–‡æœ¬æŸ¥è©¢\n",
    "    print(\"\\n2ï¸âƒ£  æ–‡æœ¬æŸ¥è©¢ç¤ºä¾‹\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    text_queries = [\n",
    "        \"TSMC è²·å…¥\",\n",
    "        \"trading decision\",\n",
    "        \"å¸‚å ´åˆ†æ\",\n",
    "        \"2025-01-15\",\n",
    "        \"æŠ€è¡“æŒ‡æ¨™\"\n",
    "    ]\n",
    "    \n",
    "    for query in text_queries:\n",
    "        print(f\"\\n  æŸ¥è©¢: '{query}'\")\n",
    "        try:\n",
    "            result = await memory_mcp.session.call_tool(\n",
    "                \"search_nodes\",\n",
    "                {\n",
    "                    \"query\": query,\n",
    "                    \"limit\": 10  # å¯¦éš›ä¸Šæœ€å¤šè¿”å› 5 å€‹\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            if hasattr(result, \"content\") and result.content:\n",
    "                content_item = result.content[0]\n",
    "                text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "                \n",
    "                try:\n",
    "                    data = json.loads(text_content)\n",
    "                    found_nodes = data.get(\"nodes\", [])\n",
    "                    print(f\"  çµæœ: æ‰¾åˆ° {len(found_nodes)} å€‹å¯¦é«”\")\n",
    "                    for i, node in enumerate(found_nodes[:3], 1):\n",
    "                        print(f\"    {i}. {node.get('name')} ({node.get('entityType')})\")\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"  âœ— è§£æå›æ‡‰å¤±æ•—\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— æŸ¥è©¢å¤±æ•—: {e}\")\n",
    "    \n",
    "    # æ­¥é©Ÿ 3: é©—è­‰å®Œæ•´åœ–è¡¨\n",
    "    print(\"\\n3ï¸âƒ£  é©—è­‰ä¿å­˜çµæœ\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        result = await memory_mcp.session.call_tool(\n",
    "            \"read_graph\",\n",
    "            {}\n",
    "        )\n",
    "        \n",
    "        if hasattr(result, \"content\") and result.content:\n",
    "            content_item = result.content[0]\n",
    "            text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(text_content)\n",
    "                nodes = data.get(\"nodes\", [])\n",
    "                print(f\"âœ“ è³‡æ–™åº«ç¾åœ¨æœ‰ {len(nodes)} å€‹å¯¦é«”\")\n",
    "                print(f\"\\n  [å¯¦é«”åˆ—è¡¨]\")\n",
    "                for i, node in enumerate(nodes, 1):\n",
    "                    print(f\"  {i}. {node.get('name')} - {len(node.get('observations', []))} å€‹è§€æ¸¬\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"âœ— è§£æåœ–è¡¨å¤±æ•—\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— è®€å–åœ–è¡¨å¤±æ•—: {e}\")\n",
    "    \n",
    "    print(f\"\\nâœ… æ¼”ç¤ºå®Œæˆ\")\n",
    "\n",
    "# åŸ·è¡Œæ¼”ç¤º\n",
    "print(\"\\n\\n\" + \"=\" * 70)\n",
    "print(\"ç¾åœ¨åŸ·è¡Œæ­£ç¢ºç”¨æ³•æ¼”ç¤º\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "await test_search_nodes_correct_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60124732",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_search_nodes():\n",
    "    \"\"\"\n",
    "    æ¸¬è©¦ search_nodes å·¥å…· - å®Œæ•´è¨ºæ–·ç‰ˆæœ¬\n",
    "    \n",
    "    æ ¹æ“šå®˜æ–¹æºç¢¼åˆ†æï¼Œsearch_nodes çš„è¡Œç‚ºï¼š\n",
    "    1. å…ˆå˜—è©¦å‘é‡æœå°‹ï¼ˆéœ€è¦ embeddingï¼‰\n",
    "    2. å¤±æ•—å‰‡å›é€€åˆ°æ–‡æœ¬æœå°‹ï¼ˆLIKE %query%ï¼‰\n",
    "    3. æœ€å¤šè¿”å› 5 å€‹çµæœ\n",
    "    \n",
    "    æŸ¥è©¢ç„¡çµæœçš„å¸¸è¦‹åŸå› ï¼š\n",
    "    - è³‡æ–™åº«ç‚ºç©ºï¼ˆ0 å€‹å¯¦é«”ï¼‰\n",
    "    - å¯¦é«”æ²’æœ‰ embedding ä¿¡æ¯\n",
    "    - æŸ¥è©¢é—œéµå­—ä¸åŒ¹é…ä»»ä½•å¯¦é«”\n",
    "    \"\"\"\n",
    "    global memory_mcp\n",
    "    \n",
    "    if not memory_mcp:\n",
    "        print(\"âœ— Memory MCP æœªåˆå§‹åŒ–\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"è¨ºæ–·: search_nodes æŸ¥è©¢ç„¡çµæœ\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # æ­¥é©Ÿ 1: æª¢æŸ¥è³‡æ–™åº«æ˜¯å¦æœ‰æ•¸æ“š\n",
    "    print(\"\\nğŸ” æ­¥é©Ÿ 1: æª¢æŸ¥è³‡æ–™åº«ä¸­æ˜¯å¦æœ‰å¯¦é«”\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        result_read = await memory_mcp.session.call_tool(\n",
    "            \"read_graph\",\n",
    "            {}\n",
    "        )\n",
    "        \n",
    "        if hasattr(result_read, \"content\") and result_read.content:\n",
    "            content_item = result_read.content[0]\n",
    "            text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(text_content)\n",
    "                nodes = data.get(\"nodes\", [])\n",
    "                \n",
    "                print(f\"âœ“ è³‡æ–™åº«é€£æ¥æ­£å¸¸\")\n",
    "                print(f\"  â€¢ ç•¶å‰å¯¦é«”æ•¸é‡: {len(nodes)}\")\n",
    "                \n",
    "                if len(nodes) == 0:\n",
    "                    print(\"\\nâš ï¸  å•é¡Œç¢ºèª: è³‡æ–™åº«ä¸­æ²’æœ‰ä»»ä½•å¯¦é«”\")\n",
    "                    print(\"\\nâœ… è§£æ±ºæ–¹æ¡ˆ:\")\n",
    "                    print(\"  1. å…ˆåŸ·è¡Œ create_entities å‰µå»ºæ¸¬è©¦å¯¦é«”\")\n",
    "                    print(\"  2. ç¢ºä¿å¯¦é«”è¢«æ­£ç¢ºä¿å­˜\")\n",
    "                    print(\"  3. ç„¶å¾Œå†åŸ·è¡Œ search_nodes\")\n",
    "                    return None\n",
    "                \n",
    "                # åˆ†æå¯¦é«”çµæ§‹\n",
    "                print(f\"\\nâœ“ è³‡æ–™åº«æœ‰ {len(nodes)} å€‹å¯¦é«”\")\n",
    "                print(f\"\\n  [å¯¦é«”çµæ§‹åˆ†æ]\")\n",
    "                sample_node = nodes[0]\n",
    "                print(f\"  â€¢ ç¯€é»å­—æ®µ: {list(sample_node.keys())}\")\n",
    "                print(f\"  â€¢ æ˜¯å¦æœ‰ embedding: {'embedding' in sample_node and sample_node['embedding'] is not None}\")\n",
    "                \n",
    "                # çµ±è¨ˆæœ‰ embedding çš„å¯¦é«”\n",
    "                entities_with_embedding = sum(1 for n in nodes if 'embedding' in n and n['embedding'] is not None)\n",
    "                print(f\"  â€¢ æœ‰ embedding çš„å¯¦é«”: {entities_with_embedding}/{len(nodes)}\")\n",
    "                \n",
    "                # é¡¯ç¤ºæ‰€æœ‰å¯¦é«”\n",
    "                print(f\"\\n  [æ‰€æœ‰å¯¦é«”åˆ—è¡¨]\")\n",
    "                for i, node in enumerate(nodes, 1):\n",
    "                    has_emb = \"æœ‰\" if ('embedding' in node and node['embedding'] is not None) else \"ç„¡\"\n",
    "                    print(f\"    {i}. {node.get('name', 'N/A'):40} [{has_emb} embedding]\")\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"âœ— JSON è§£æå¤±æ•—: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"âœ— ç„¡æ³•è®€å–åœ–è¡¨\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— è®€å–åœ–è¡¨å¤±æ•—: {type(e).__name__}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # æ­¥é©Ÿ 2: å˜—è©¦å¤šç¨®æŸ¥è©¢ç­–ç•¥\n",
    "    print(\"\\n\\nğŸ” æ­¥é©Ÿ 2: æ¸¬è©¦æŸ¥è©¢ç­–ç•¥\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # ä½¿ç”¨å¯¦éš›å­˜åœ¨çš„å¯¦é«”åç¨±é€²è¡Œæ¸¬è©¦\n",
    "    search_strategies = []\n",
    "    if nodes:\n",
    "        # ç­–ç•¥1: å®Œæ•´çš„å¯¦é«”åç¨±\n",
    "        full_name = nodes[0].get('name', '')\n",
    "        search_strategies.append((\"å®Œæ•´å¯¦é«”åç¨±\", full_name))\n",
    "        \n",
    "        # ç­–ç•¥2: å¯¦é«”åç¨±çš„å‰ç¶´\n",
    "        if len(full_name) > 5:\n",
    "            prefix = full_name[:5]\n",
    "            search_strategies.append((\"åç¨±å‰ç¶´\", prefix))\n",
    "        \n",
    "        # ç­–ç•¥3: ä½¿ç”¨ entityType\n",
    "        entity_type = nodes[0].get('entityType', '')\n",
    "        if entity_type:\n",
    "            search_strategies.append((\"å¯¦é«”é¡å‹\", entity_type))\n",
    "        \n",
    "        # ç­–ç•¥4: ä½¿ç”¨ observations\n",
    "        observations = nodes[0].get('observations', [])\n",
    "        if observations and len(observations) > 0:\n",
    "            obs_word = observations[0].split()[0] if observations[0] else \"\"\n",
    "            if obs_word:\n",
    "                search_strategies.append((\"è§€æ¸¬è©\", obs_word))\n",
    "    \n",
    "    # æ·»åŠ ä¸€äº›é€šç”¨ç­–ç•¥\n",
    "    search_strategies.extend([\n",
    "        (\"ç©ºå­—ç¬¦ä¸²\", \"\"),\n",
    "        (\"ç°¡å–®è©\", \"agent\"),\n",
    "    ])\n",
    "    \n",
    "    search_results = {}\n",
    "    \n",
    "    for strategy_name, query in search_strategies:\n",
    "        print(f\"\\n  [{strategy_name}]\")\n",
    "        print(f\"  æŸ¥è©¢: '{query}'\")\n",
    "        \n",
    "        try:\n",
    "            result = await memory_mcp.session.call_tool(\n",
    "                \"search_nodes\",\n",
    "                {\n",
    "                    \"query\": query,\n",
    "                    \"limit\": 10,  # æ³¨: å¯¦éš›ä¸Šæœ€å¤šè¿”å› 5 å€‹\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            if hasattr(result, \"content\") and result.content:\n",
    "                content_item = result.content[0]\n",
    "                text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "                \n",
    "                try:\n",
    "                    data = json.loads(text_content)\n",
    "                    found_nodes = data.get(\"nodes\", [])\n",
    "                    print(f\"  âœ“ æ‰¾åˆ° {len(found_nodes)} å€‹ç¯€é»\")\n",
    "                    \n",
    "                    search_results[strategy_name] = {\n",
    "                        \"query\": query,\n",
    "                        \"count\": len(found_nodes),\n",
    "                        \"nodes\": found_nodes\n",
    "                    }\n",
    "                    \n",
    "                    if found_nodes:\n",
    "                        print(f\"  [å‰ 3 å€‹çµæœ]\")\n",
    "                        for i, node in enumerate(found_nodes[:3], 1):\n",
    "                            print(f\"    {i}. {node.get('name', 'N/A')}\")\n",
    "                    \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"  âœ— å›æ‡‰è§£æå¤±æ•—: {str(e)[:50]}\")\n",
    "            else:\n",
    "                print(f\"  âœ— ç„¡æœ‰æ•ˆå›æ‡‰\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— æŸ¥è©¢ç•°å¸¸: {type(e).__name__}\")\n",
    "    \n",
    "    # æ­¥é©Ÿ 3: å½™ç¸½è¨ºæ–·çµæœ\n",
    "    print(\"\\n\\nğŸ” æ­¥é©Ÿ 3: è¨ºæ–·çµè«–\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    successful_queries = {k: v for k, v in search_results.items() if v[\"count\"] > 0}\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æŸ¥è©¢çµ±è¨ˆ:\")\n",
    "    print(f\"  â€¢ ç¸½ç­–ç•¥æ•¸: {len(search_results)}\")\n",
    "    print(f\"  â€¢ æˆåŠŸçš„æŸ¥è©¢: {len(successful_queries)}\")\n",
    "    print(f\"  â€¢ å¤±æ•—çš„æŸ¥è©¢: {len(search_results) - len(successful_queries)}\")\n",
    "    \n",
    "    if successful_queries:\n",
    "        print(f\"\\nâœ… å¥½æ¶ˆæ¯: æŸäº›æŸ¥è©¢ç­–ç•¥æœ‰æ•ˆ\")\n",
    "        for strategy, result in successful_queries.items():\n",
    "            print(f\"  âœ“ {strategy}: æ‰¾åˆ° {result['count']} å€‹ç¯€é»\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ è¨ºæ–·: æ‰€æœ‰æŸ¥è©¢ç­–ç•¥éƒ½å¤±æ•—\")\n",
    "        print(f\"\\nå¯èƒ½çš„åŸå› å’Œè§£æ±ºæ–¹æ¡ˆ:\")\n",
    "        print(f\"  1. è³‡æ–™åº«ä¸­çš„å¯¦é«”å¯èƒ½æ²’æœ‰ embedding ä¿¡æ¯\")\n",
    "        print(f\"     â†’ æª¢æŸ¥ä¸Šæ–¹çš„ embedding çµ±è¨ˆ\")\n",
    "        print(f\"  2. æ–‡æœ¬æœå°‹ä½¿ç”¨ LIKE %query% é€²è¡Œæ¨¡ç³ŠåŒ¹é…\")\n",
    "        print(f\"     â†’ å˜—è©¦ä½¿ç”¨æ›´é€šç”¨çš„é—œéµå­—\")\n",
    "        print(f\"  3. å‘é‡æœå°‹å¯èƒ½éœ€è¦ç‰¹å®šçš„ embedding æ ¼å¼\")\n",
    "        print(f\"     â†’ ç¢ºä¿ embedding æ˜¯æœ‰æ•ˆçš„æ•¸å­—é™£åˆ—\")\n",
    "    \n",
    "    print(f\"\\nâœ“ è¨ºæ–·å®Œæˆ\")\n",
    "    return search_results\n",
    "\n",
    "# åŸ·è¡Œè¨ºæ–·æ¸¬è©¦\n",
    "result_search_diag = await test_search_nodes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aea6e0",
   "metadata": {},
   "source": [
    "## Section 6: æ¸¬è©¦ read_graph å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf70410",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_read_graph():\n",
    "    \"\"\"\n",
    "    æ¸¬è©¦ read_graph å·¥å…·\n",
    "    \n",
    "    æ­¤å·¥å…·ç”¨æ–¼è®€å–å®Œæ•´æˆ–éƒ¨åˆ†çš„çŸ¥è­˜åœ–è¡¨ã€‚\n",
    "    åœ¨ clear_old_memories ä¸­ä½¿ç”¨ï¼Œç”¨æ–¼æª¢ç´¢æ‰€æœ‰ç¯€é»ä»¥é€²è¡Œéæ¿¾å’Œåˆªé™¤ã€‚\n",
    "    \n",
    "    é æœŸéŸ¿æ‡‰: åŒ…å«ç¯€é»å’Œé—œä¿‚çš„å®Œæ•´åœ–è¡¨\n",
    "    \"\"\"\n",
    "    global memory_mcp\n",
    "    \n",
    "    if not memory_mcp:\n",
    "        print(\"âœ— Memory MCP æœªåˆå§‹åŒ–\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"æ¸¬è©¦: read_graph\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nğŸ“¤ ç™¼é€è«‹æ±‚:\")\n",
    "        print(f\"   å·¥å…·: read_graph\")\n",
    "        print(f\"   è®€å–å®Œæ•´åœ–è¡¨\")\n",
    "        \n",
    "        result = await memory_mcp.session.call_tool(\n",
    "            \"read_graph\",\n",
    "            {}\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ“¥ æ”¶åˆ°å›æ‡‰:\")\n",
    "        print(f\"   é¡å‹: {type(result)}\")\n",
    "        \n",
    "        if hasattr(result, \"content\") and result.content:\n",
    "            content_item = result.content[0]\n",
    "            text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "            \n",
    "            print(f\"   åŸå§‹æ–‡æœ¬é•·åº¦: {len(text_content)}\")\n",
    "            \n",
    "            # å˜—è©¦è§£æç‚º JSON\n",
    "            try:\n",
    "                data = json.loads(text_content)\n",
    "                print(f\"\\n   âœ“ JSON è§£ææˆåŠŸ\")\n",
    "                \n",
    "                nodes = data.get(\"nodes\", [])\n",
    "                relations = data.get(\"relations\", [])\n",
    "                \n",
    "                print(f\"   ç¯€é»ç¸½æ•¸: {len(nodes)}\")\n",
    "                print(f\"   é—œä¿‚ç¸½æ•¸: {len(relations)}\")\n",
    "                \n",
    "                # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯\n",
    "                if nodes:\n",
    "                    print(f\"\\n   [åœ–è¡¨çµ±è¨ˆ]\")\n",
    "                    entity_types = set()\n",
    "                    for node in nodes:\n",
    "                        if \"entityType\" in node:\n",
    "                            entity_types.add(node[\"entityType\"])\n",
    "                    \n",
    "                    print(f\"   å¯¦é«”é¡å‹: {entity_types}\")\n",
    "                    print(f\"\\n   [ç¯€é»ç¤ºä¾‹ (å‰ 3 å€‹)]\")\n",
    "                    for i, node in enumerate(nodes[:3]):\n",
    "                        print(f\"     {i+1}. {node.get('name', 'N/A')}\")\n",
    "                        print(f\"        é¡å‹: {node.get('entityType', 'N/A')}\")\n",
    "                        print(f\"        å‰µå»º: {node.get('created_at', 'N/A')}\")\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"\\n   âœ— JSON è§£æå¤±æ•—: {e}\")\n",
    "        \n",
    "        print(f\"\\nâœ“ read_graph æ¸¬è©¦å®Œæˆ\")\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— éŒ¯èª¤: {type(e).__name__}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# åŸ·è¡Œæ¸¬è©¦\n",
    "result_read = await test_read_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b995043",
   "metadata": {},
   "source": [
    "## Section 7: æ¸¬è©¦ delete_entity å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd739094",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_delete_entity():\n",
    "    \"\"\"\n",
    "    æ¸¬è©¦ delete_entity å·¥å…·\n",
    "    \n",
    "    æ­¤å·¥å…·ç”¨æ–¼åˆªé™¤æŒ‡å®šåç¨±çš„å¯¦é«”åŠå…¶æ‰€æœ‰é—œè¯ã€‚\n",
    "    åœ¨ clear_old_memories ä¸­ä½¿ç”¨ï¼Œç”¨æ–¼åˆªé™¤éæœŸçš„è¨˜æ†¶é«”ã€‚\n",
    "    \n",
    "    é æœŸéŸ¿æ‡‰: æˆåŠŸ/å¤±æ•—æ¶ˆæ¯\n",
    "    \"\"\"\n",
    "    global memory_mcp\n",
    "    \n",
    "    if not memory_mcp:\n",
    "        print(\"âœ— Memory MCP æœªåˆå§‹åŒ–\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"æ¸¬è©¦: delete_entity\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # å…ˆå»ºç«‹ä¸€å€‹å¾…åˆªé™¤çš„å¯¦é«”\n",
    "        test_entity_name = \"agent_test_delete_2025\"\n",
    "        \n",
    "        print(f\"\\n1ï¸âƒ£  å…ˆå»ºç«‹æ¸¬è©¦å¯¦é«”é€²è¡Œåˆªé™¤\")\n",
    "        create_result = await memory_mcp.session.call_tool(\n",
    "            \"create_entities\",\n",
    "            {\n",
    "                \"entities\": [{\n",
    "                    \"name\": test_entity_name,\n",
    "                    \"entityType\": \"test_deletion\",\n",
    "                    \"observations\": [\"This entity will be deleted\"]\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "        print(f\"   âœ“ å¯¦é«”å·²å»ºç«‹: {test_entity_name}\")\n",
    "        \n",
    "        # ç¾åœ¨åˆªé™¤è©²å¯¦é«”\n",
    "        print(f\"\\n2ï¸âƒ£  åˆªé™¤å¯¦é«”\")\n",
    "        print(f\"   å·¥å…·: delete_entity\")\n",
    "        print(f\"   å¯¦é«”åç¨±: {test_entity_name}\")\n",
    "        \n",
    "        delete_result = await memory_mcp.session.call_tool(\n",
    "            \"delete_entity\",\n",
    "            {\"name\": test_entity_name}\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ“¥ æ”¶åˆ°å›æ‡‰:\")\n",
    "        print(f\"   é¡å‹: {type(delete_result)}\")\n",
    "        \n",
    "        if hasattr(delete_result, \"content\") and delete_result.content:\n",
    "            content_item = delete_result.content[0]\n",
    "            text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "            print(f\"   å›æ‡‰: {text_content[:200]}\")\n",
    "            \n",
    "            if \"success\" in text_content.lower() or \"deleted\" in text_content.lower():\n",
    "                print(f\"   âœ“ åˆªé™¤æ“ä½œæˆåŠŸ\")\n",
    "            else:\n",
    "                print(f\"   âš  å›æ‡‰ä¸æ˜ç¢ºï¼Œå¯èƒ½å·²åˆªé™¤\")\n",
    "        \n",
    "        print(f\"\\nâœ“ delete_entity æ¸¬è©¦å®Œæˆ\")\n",
    "        return delete_result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— éŒ¯èª¤: {type(e).__name__}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# åŸ·è¡Œæ¸¬è©¦\n",
    "result_delete = await test_delete_entity()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da53cb68",
   "metadata": {},
   "source": [
    "## Section 8: é©—è­‰ memory_tools.py ä¸­çš„å‡½æ•¸é‚è¼¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df615b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trading.tools.memory_tools import (\n",
    "    load_execution_memory,\n",
    "    save_execution_memory,\n",
    "    recall_recent_decisions,\n",
    ")\n",
    "\n",
    "async def test_load_execution_memory():\n",
    "    \"\"\"\n",
    "    é©—è­‰ load_execution_memory å‡½æ•¸\n",
    "    \n",
    "    æ­¤å‡½æ•¸æ‡‰è©²ï¼š\n",
    "    1. ä½¿ç”¨ search_nodes æŸ¥è©¢éå»çš„æ±ºç­–\n",
    "    2. è§£æ JSON éŸ¿æ‡‰\n",
    "    3. è½‰æ›ç‚ºè¨˜æ†¶é«”æ ¼å¼\n",
    "    \"\"\"\n",
    "    global memory_mcp\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"é©—è­‰: load_execution_memory (ä¾†è‡ª memory_tools.py)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        agent_id = \"test_123\"\n",
    "        \n",
    "        # å…ˆå»ºç«‹ä¸€äº›æ¸¬è©¦æ•¸æ“š\n",
    "        print(f\"\\n1ï¸âƒ£  å»ºç«‹æ¸¬è©¦æ±ºç­–æ•¸æ“š\")\n",
    "        await memory_mcp.session.call_tool(\n",
    "            \"create_entities\",\n",
    "            {\n",
    "                \"entities\": [{\n",
    "                    \"name\": f\"agent_{agent_id}_decision_2025\",\n",
    "                    \"entityType\": \"trading_decision\",\n",
    "                    \"observations\": [\n",
    "                        \"2025-01-10 10:30\",\n",
    "                        \"è²·å…¥æ±ºç­–\",\n",
    "                        \"TSMC 2330 100è‚¡\",\n",
    "                        \"æŠ€è¡“æŒ‡æ¨™çœ‹å¥½\"\n",
    "                    ]\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "        print(f\"   âœ“ æ¸¬è©¦æ±ºç­–å·²å»ºç«‹\")\n",
    "        \n",
    "        # ç¾åœ¨æ¸¬è©¦ load_execution_memory\n",
    "        print(f\"\\n2ï¸âƒ£  èª¿ç”¨ load_execution_memory\")\n",
    "        memory = await load_execution_memory(memory_mcp, agent_id)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š çµæœ:\")\n",
    "        print(f\"   è¿”å›é¡å‹: {type(memory)}\")\n",
    "        print(f\"   éå»æ±ºç­–æ•¸é‡: {len(memory.get('past_decisions', []))}\")\n",
    "        \n",
    "        if memory.get(\"past_decisions\"):\n",
    "            print(f\"\\n   [æ±ºç­–ç¤ºä¾‹]\")\n",
    "            for i, decision in enumerate(memory[\"past_decisions\"][:3]):\n",
    "                print(f\"     {i+1}. æ—¥æœŸ: {decision.get('date', 'N/A')}\")\n",
    "                print(f\"        å‹•ä½œ: {decision.get('action', 'N/A')}\")\n",
    "                print(f\"        åŸå› : {decision.get('reason', 'N/A')}\")\n",
    "        \n",
    "        print(f\"\\nâœ“ load_execution_memory é©—è­‰å®Œæˆ\")\n",
    "        return memory\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— éŒ¯èª¤: {type(e).__name__}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "async def test_save_execution_memory():\n",
    "    \"\"\"\n",
    "    é©—è­‰ save_execution_memory å‡½æ•¸\n",
    "    \n",
    "    æ­¤å‡½æ•¸æ‡‰è©²ï¼š\n",
    "    1. æº–å‚™åŸ·è¡Œçµæœæ‘˜è¦\n",
    "    2. ä½¿ç”¨ create_entities ä¿å­˜åˆ°è¨˜æ†¶é«”\n",
    "    3. è¿”å›æˆåŠŸ/å¤±æ•—ç‹€æ…‹\n",
    "    \"\"\"\n",
    "    global memory_mcp\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"é©—è­‰: save_execution_memory (ä¾†è‡ª memory_tools.py)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        agent_id = \"test_456\"\n",
    "        execution_result = \"è²·å…¥ 2330 100 è‚¡ï¼Œæˆäº¤åƒ¹ 620 å…ƒï¼Œç¸½æˆæœ¬ 62,000 å…ƒã€‚äº¤æ˜“æˆåŠŸã€‚\"\n",
    "        mode = \"AUTO_TRADING\"\n",
    "        \n",
    "        print(f\"\\n1ï¸âƒ£  ä¿å­˜åŸ·è¡Œçµæœ\")\n",
    "        print(f\"   Agent ID: {agent_id}\")\n",
    "        print(f\"   çµæœ: {execution_result[:60]}...\")\n",
    "        print(f\"   æ¨¡å¼: {mode}\")\n",
    "        \n",
    "        success = await save_execution_memory(\n",
    "            memory_mcp,\n",
    "            agent_id,\n",
    "            execution_result,\n",
    "            mode=mode\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nâœ“ ä¿å­˜çµæœ: {'æˆåŠŸ' if success else 'å¤±æ•—'}\")\n",
    "        return success\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— éŒ¯èª¤: {type(e).__name__}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# åŸ·è¡Œé©—è­‰æ¸¬è©¦\n",
    "print(\"\\n\\n\" + \"=\" * 60)\n",
    "print(\"é–‹å§‹é©—è­‰ memory_tools.py ä¸­çš„å‡½æ•¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "memory_result = await test_load_execution_memory()\n",
    "save_result = await test_save_execution_memory()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b43c436",
   "metadata": {},
   "source": [
    "## Section 9: ç¸½çµèˆ‡æœ€ä½³å¯¦è¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac3ec4",
   "metadata": {},
   "source": [
    "### é—œéµç™¼ç¾\n",
    "\n",
    "1. **call_tool è¿”å›çµæ§‹**\n",
    "   - è¿”å›å°è±¡åŒ…å« `content` å±¬æ€§ï¼ˆåˆ—è¡¨ï¼‰\n",
    "   - æ¯å€‹ content é …ç›®éƒ½æ˜¯ TextContentï¼ŒåŒ…å« `text` å±¬æ€§\n",
    "   - æ–‡æœ¬å…§å®¹é€šå¸¸æ˜¯ JSON å­—ç¬¦ä¸²ï¼Œéœ€è¦è§£æ\n",
    "\n",
    "2. **å›æ‡‰è§£ææ¨¡å¼**\n",
    "   ```python\n",
    "   result = await memory_mcp.session.call_tool(tool_name, params)\n",
    "   content_item = result.content[0]\n",
    "   text_content = content_item.text\n",
    "   data = json.loads(text_content)  # è§£æ JSON\n",
    "   ```\n",
    "\n",
    "3. **memory_tools.py ä¸­çš„ä¸‰å€‹é—œéµå·¥å…·**\n",
    "   \n",
    "   | å·¥å…· | ç”¨é€” | è¿”å›æ ¼å¼ |\n",
    "   |-----|------|--------|\n",
    "   | `create_entities` | å»ºç«‹/æ›´æ–°å¯¦é«” | JSON with creation status |\n",
    "   | `search_nodes` | æŸ¥è©¢ç›¸ä¼¼ç¯€é» | JSON with nodes array |\n",
    "   | `read_graph` | è®€å–å®Œæ•´åœ–è¡¨ | JSON with nodes and relations |\n",
    "   | `delete_entity` | åˆªé™¤å¯¦é«” | æˆåŠŸ/å¤±æ•—æ¶ˆæ¯ |\n",
    "\n",
    "4. **éŒ¯èª¤è™•ç†å»ºè­°**\n",
    "   - å§‹çµ‚æª¢æŸ¥ `hasattr(result, \"content\")` å’Œ `result.content`\n",
    "   - ä½¿ç”¨ try/except æ•æ‰ JSON è§£æéŒ¯èª¤\n",
    "   - è¨˜éŒ„åŸå§‹å›æ‡‰ç”¨æ–¼èª¿è©¦\n",
    "\n",
    "### æ”¹é€²å»ºè­°\n",
    "\n",
    "é‡å° `memory_tools.py` çš„æ”¹é€²é»ï¼š\n",
    "\n",
    "1. âœ“ ç•¶å‰è§£æé‚è¼¯æ­£ç¢º\n",
    "2. âœ“ éŒ¯èª¤è™•ç†é©ç•¶\n",
    "3. âœ“ æ—¥èªŒè¨˜éŒ„å……è¶³\n",
    "4. ğŸ“ å¯è€ƒæ…®å¢åŠ å›æ‡‰é©—è­‰å±¤\n",
    "5. ğŸ“ å¯è€ƒæ…®å»ºç«‹å›æ‡‰æ¨¡å‹ï¼ˆPydanticï¼‰ç”¨æ–¼é¡å‹å®‰å…¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea6ad71",
   "metadata": {},
   "source": [
    "## Section 10: æ¸…ç†è³‡æº"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341ec28",
   "metadata": {},
   "source": [
    "## search_nodes å¿«é€Ÿåƒè€ƒæŒ‡å—\n",
    "\n",
    "### âœ… æ­£ç¢ºçš„æŸ¥è©¢æ–¹å¼\n",
    "\n",
    "#### 1. æ–‡æœ¬æŸ¥è©¢ï¼ˆè‡ªå‹•è½‰å‘é‡â†’å‘é‡æœå°‹â†’æ–‡æœ¬æœå°‹ï¼‰\n",
    "```python\n",
    "result = await memory_mcp.session.call_tool(\n",
    "    \"search_nodes\",\n",
    "    {\n",
    "        \"query\": \"TSMC\",  # å­—ç¬¦ä¸²æŸ¥è©¢\n",
    "        \"limit\": 10  # æ³¨æ„ï¼šå¯¦éš›æœ€å¤šè¿”å› 5 å€‹\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "#### 2. å‘é‡æŸ¥è©¢ï¼ˆç›´æ¥å‘é‡ç›¸ä¼¼åº¦æœå°‹ï¼‰\n",
    "```python\n",
    "# embedding æ˜¯ä¸€å€‹æ•¸å­—é™£åˆ—\n",
    "result = await memory_mcp.session.call_tool(\n",
    "    \"search_nodes\",\n",
    "    {\n",
    "        \"query\": [0.1, 0.2, 0.3, ...],  # å‘é‡é™£åˆ—\n",
    "        \"limit\": 10\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "#### 3. æå–çµæœ\n",
    "```python\n",
    "data = json.loads(result.content[0].text)\n",
    "nodes = data.get(\"nodes\", [])  # æœç´¢çµæœå¯¦é«”åˆ—è¡¨\n",
    "relations = data.get(\"relations\", [])  # å¯¦é«”é–“çš„é—œä¿‚\n",
    "```\n",
    "\n",
    "### âŒ å¸¸è¦‹éŒ¯èª¤\n",
    "\n",
    "| éŒ¯èª¤ | åŸå›  | ä¿®å¾© |\n",
    "|-----|------|------|\n",
    "| è¿”å› `nodes: []` | è³‡æ–™åº«ç„¡å¯¦é«”æˆ–æŸ¥è©¢ä¸åŒ¹é… | å…ˆ `create_entities`ï¼Œç¢ºèª `read_graph` æœ‰æ•¸æ“š |\n",
    "| è¿”å›è¶…é 5 å€‹çµæœ | æœŸæœ›ä¸ç¬¦ | search_nodes æœ€å¤šè¿”å› 5 å€‹ï¼Œé€™æ˜¯æºç¢¼é™åˆ¶ |\n",
    "| ä½¿ç”¨ `query=\"\"` æ‹‹éŒ¯ | ä¸å…è¨±ç©ºå­—ç¬¦ä¸²æŸ¥è©¢ | ä½¿ç”¨æœ‰æ•ˆçš„æŸ¥è©¢è©æˆ–å‘é‡é™£åˆ— |\n",
    "| æ”¶ä¸åˆ°å‘é‡æœå°‹çµæœ | å¯¦é«”æ²’æœ‰ embedding | create_entities æ™‚éœ€æä¾› `embedding` å­—æ®µ |\n",
    "\n",
    "### ğŸ”§ èª¿è©¦æ­¥é©Ÿ\n",
    "\n",
    "```python\n",
    "# 1. é©—è­‰è³‡æ–™åº«æœ‰å¯¦é«”\n",
    "result = await memory_mcp.session.call_tool(\"read_graph\", {})\n",
    "nodes = json.loads(result.content[0].text).get(\"nodes\", [])\n",
    "print(f\"è³‡æ–™åº«æœ‰ {len(nodes)} å€‹å¯¦é«”\")  # æ‡‰ > 0\n",
    "\n",
    "# 2. æª¢æŸ¥å¯¦é«”çµæ§‹\n",
    "if nodes:\n",
    "    print(nodes[0].keys())  # æŸ¥çœ‹å¯ç”¨å­—æ®µ\n",
    "    print(nodes[0])  # æŸ¥çœ‹å®Œæ•´å…§å®¹\n",
    "\n",
    "# 3. å˜—è©¦æ–‡æœ¬æŸ¥è©¢\n",
    "result = await memory_mcp.session.call_tool(\n",
    "    \"search_nodes\",\n",
    "    {\"query\": \"ä½ çš„é—œéµè©\"}  # ä½¿ç”¨å¯¦é«”åç¨±çš„ä¸€éƒ¨åˆ†\n",
    ")\n",
    "found = json.loads(result.content[0].text).get(\"nodes\", [])\n",
    "print(f\"æ‰¾åˆ° {len(found)} å€‹çµæœ\")\n",
    "```\n",
    "\n",
    "### ğŸ“š å®˜æ–¹æºç¢¼åƒè€ƒ\n",
    "\n",
    "- Repository: https://github.com/joleyline/mcp-memory-libsql\n",
    "- æ ¸å¿ƒæ–‡ä»¶: `src/services/graph-service.ts`\n",
    "- API å®šç¾©: `src/index.ts` ä¸­çš„ `ListToolsRequestSchema`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0a465",
   "metadata": {},
   "source": [
    "## Entityã€Observationã€Relation å¿«é€Ÿåƒè€ƒ\n",
    "\n",
    "### ğŸ“Š æ ¸å¿ƒæ¦‚å¿µé€ŸæŸ¥è¡¨\n",
    "\n",
    "| çµ„ä»¶ | å®šç¾© | ä¾‹å­ | èˆ‡DBçš„é—œä¿‚ |\n",
    "|-----|------|------|----------|\n",
    "| **Entity** | çŸ¥è­˜åœ–çš„**ç¯€é»**<br/>ä»£è¡¨ä¸€å€‹é‡è¦æ¦‚å¿µ | \"trading_decision_2025_01_15\" | 1 è¡Œåœ¨ `entities` è¡¨ |\n",
    "| **Observation** | Entity çš„**å±¬æ€§/äº‹å¯¦** <br/>è©³ç´°æè¿°ä¿¡æ¯ | \"è²·å…¥ 1000 è‚¡ TSMC\" | N è¡Œåœ¨ `observations` è¡¨<br/>å¤–éµæŒ‡å‘ entity |\n",
    "| **Relation** | Entity é–“çš„**æœ‰å‘é‚Š** <br/>è¡¨ç¤ºé‚è¼¯é—œä¿‚ | \"æ±ºç­–åŸºæ–¼å¸‚å ´åˆ†æ\" | 1 è¡Œåœ¨ `relations` è¡¨<br/>sourceâ†’target |\n",
    "\n",
    "### ğŸ”‘ å·¥ä½œæµç¨‹\n",
    "\n",
    "```\n",
    "Step 1: å‰µå»º Entity\n",
    "â”‚\n",
    "â”œâ”€ name: å”¯ä¸€æ¨™è­˜ (å¦‚ \"market_analysis_2025_01_15\")\n",
    "â”œâ”€ entityType: åˆ†é¡ (å¦‚ \"market_analysis\")\n",
    "â”œâ”€ embedding: [å‘é‡]ï¼ˆç”¨æ–¼èªç¾©æœå°‹ï¼‰\n",
    "â””â”€ created_at: æ™‚é–“æˆ³\n",
    "\n",
    "Step 2: æ·»åŠ  Observations\n",
    "â”‚\n",
    "â”œâ”€ Obs 1: \"å°ç£è‚¡å¸‚é–‹ç›¤ 17,500\"\n",
    "â”œâ”€ Obs 2: \"åŠå°é«”æ¼² 2.3%\"\n",
    "â””â”€ ... (å¯å¤šå€‹)\n",
    "\n",
    "Step 3: å‰µå»º Relationsï¼ˆæŒ‡å‘å…¶ä»– Entitiesï¼‰\n",
    "â”‚\n",
    "â””â”€ source (ç•¶å‰ entity)\n",
    "   â”€(relation_type: \"based_on\")â†’\n",
    "   target (å¦ä¸€å€‹ entity)\n",
    "\n",
    "Step 4: æŸ¥è©¢\n",
    "â”‚\n",
    "â”œâ”€ read_graph(): ç²å¾—å®Œæ•´çŸ¥è­˜åœ–\n",
    "â”œâ”€ search_nodes(): åŸºæ–¼æŸ¥è©¢è©æœå°‹\n",
    "â””â”€ çµæœåŒ…å« nodes å’Œ relations\n",
    "```\n",
    "\n",
    "### ğŸ’» API èª¿ç”¨æ¨¡å¼\n",
    "\n",
    "#### å‰µå»ºå®Œæ•´å¯¦é«”ï¼ˆåŒ…å«è§€æ¸¬å’Œé—œä¿‚ï¼‰\n",
    "```python\n",
    "await memory_mcp.session.call_tool(\n",
    "  \"create_entities\",\n",
    "  {\n",
    "    \"entities\": [{\n",
    "      \"name\": \"entity_name\",\n",
    "      \"entityType\": \"type_name\",\n",
    "      \"observations\": [\n",
    "        \"obs1\",\n",
    "        \"obs2\",\n",
    "        \"obs3\"\n",
    "      ],\n",
    "      \"relations\": [{\n",
    "        \"target\": \"other_entity_name\",\n",
    "        \"relationType\": \"relation_type\"\n",
    "      }]\n",
    "    }]\n",
    "  }\n",
    ")\n",
    "```\n",
    "\n",
    "#### å–®ç¨å‰µå»ºé—œä¿‚\n",
    "```python\n",
    "await memory_mcp.session.call_tool(\n",
    "  \"create_relations\",\n",
    "  {\n",
    "    \"relations\": [{\n",
    "      \"source\": \"entity1\",\n",
    "      \"target\": \"entity2\",\n",
    "      \"type\": \"relation_type\"\n",
    "    }]\n",
    "  }\n",
    ")\n",
    "```\n",
    "\n",
    "#### è®€å–å®Œæ•´åœ–è­œ\n",
    "```python\n",
    "result = await memory_mcp.session.call_tool(\"read_graph\", {})\n",
    "data = json.loads(result.content[0].text)\n",
    "\n",
    "nodes = data[\"nodes\"]       # Entity åˆ—è¡¨\n",
    "relations = data[\"relations\"]  # Relation åˆ—è¡¨\n",
    "\n",
    "# æ§‹é€ åœ–è­œ\n",
    "for relation in relations:\n",
    "    from_entity = relation[\"from\"]      # source entity name\n",
    "    to_entity = relation[\"to\"]          # target entity name\n",
    "    rel_type = relation[\"relationType\"]\n",
    "    # from_entity -[rel_type]-> to_entity\n",
    "```\n",
    "\n",
    "### ğŸ—„ï¸ æ•¸æ“šåº«æŸ¥è©¢ç¤ºä¾‹\n",
    "\n",
    "å¦‚æœä½ æƒ³ç›´æ¥æŸ¥è©¢ SQLite æ•¸æ“šåº«ï¼š\n",
    "\n",
    "```sql\n",
    "-- ç²å–æ‰€æœ‰å¯¦é«”\n",
    "SELECT * FROM entities;\n",
    "\n",
    "-- ç²å–æŸå¯¦é«”çš„æ‰€æœ‰è§€æ¸¬\n",
    "SELECT content FROM observations \n",
    "WHERE entity_name = 'trading_decision_2025_01_15'\n",
    "ORDER BY created_at;\n",
    "\n",
    "-- ç²å–æŸå¯¦é«”çš„æ‰€æœ‰å‡ºç«™é—œä¿‚\n",
    "SELECT target, relation_type FROM relations\n",
    "WHERE source = 'trading_decision_2025_01_15';\n",
    "\n",
    "-- ç²å–æŒ‡å‘æŸå¯¦é«”çš„æ‰€æœ‰å…¥ç«™é—œä¿‚\n",
    "SELECT source, relation_type FROM relations\n",
    "WHERE target = 'trading_decision_2025_01_15';\n",
    "\n",
    "-- å®Œæ•´çš„çŸ¥è­˜åœ–è­œï¼ˆE-O-Rï¼‰\n",
    "SELECT \n",
    "  e.name,\n",
    "  e.entity_type,\n",
    "  o.content as observation,\n",
    "  r.target as related_entity,\n",
    "  r.relation_type\n",
    "FROM entities e\n",
    "LEFT JOIN observations o ON e.name = o.entity_name\n",
    "LEFT JOIN relations r ON e.name = r.source\n",
    "ORDER BY e.name, o.id, r.id;\n",
    "```\n",
    "\n",
    "### ğŸ¯ è¨­è¨ˆåŸå‰‡\n",
    "\n",
    "1. **åŸå­æ€§**ï¼šEntity æ˜¯æœ€å°å–®ä½ï¼Œä¸èƒ½å†åˆ†å‰²\n",
    "2. **éˆæ´»æ€§**ï¼šObservations å¯ä»¥ä»»æ„å¢åŠ ï¼Œç„¡éœ€æ”¹è®Š schema\n",
    "3. **é—œè¯æ€§**ï¼šRelation å®šç¾©å¯¦é«”é–“çš„é‚è¼¯ï¼Œæ”¯æŒè¤‡é›œæ¥­å‹™æ¨¡å‹\n",
    "4. **å¯æœå°‹æ€§**ï¼šEntity æœ‰ embedding ç”¨æ–¼èªç¾©æœå°‹ï¼ŒObservation ç”¨æ–¼é—œéµè©æœå°‹\n",
    "5. **å¯è¿½æº¯æ€§**ï¼šæ‰€æœ‰çµ„ä»¶éƒ½æœ‰ created_at æ™‚é–“æˆ³\n",
    "\n",
    "### â“ å¸¸è¦‹è¨­è¨ˆå•é¡Œ\n",
    "\n",
    "**Q: ä½•æ™‚è©²å»ºç«‹æ–° Entity vs æ–° Observation?**\n",
    "```\n",
    "ç­”: \n",
    "- å¦‚æœæ˜¯ç¨ç«‹çš„æ¦‚å¿µ/äº‹ä»¶ â†’ æ–° Entity\n",
    "- å¦‚æœæ˜¯å·²çŸ¥ Entity çš„å±¬æ€§/è©³æƒ… â†’ æ–° Observation\n",
    "\n",
    "ä¾‹:\n",
    "âœ… \"TSMCè‚¡ç¥¨\" å’Œ \"è²·å…¥æ±ºç­–\" â†’ å…©å€‹ Entity\n",
    "âœ… \"TSMCè‚¡åƒ¹615å…ƒ\" â†’ \"TSMCè‚¡ç¥¨\" çš„ Observation\n",
    "âŒ \"615å…ƒ\" ä¸å–®ç¨å»º Entityï¼ˆæ²’æœ‰ç¨ç«‹æ„ç¾©ï¼‰\n",
    "```\n",
    "\n",
    "**Q: ä½•æ™‚ç”¨ Relation?**\n",
    "```\n",
    "ç­”:\n",
    "- ç•¶ä½ è¦è¡¨é”å¯¦é«”é–“çš„é‚è¼¯é—œä¿‚æ™‚\n",
    "- ç”¨æ–¼æŸ¥è©¢ç›¸é—œå¯¦é«”çš„ç¶²çµ¡\n",
    "\n",
    "ä¾‹:\n",
    "âœ… æ±ºç­– -[based_on]-> å¸‚å ´åˆ†æ\n",
    "âœ… çµæœ -[executes]-> æ±ºç­–\n",
    "âŒ ä¸ç”¨ Relation è¡¨é”å¯¦é«”çš„å±¬æ€§ï¼ˆç”¨ Observationï¼‰\n",
    "```\n",
    "\n",
    "**Q: Embedding æ”¾åœ¨ Entity é‚„æ˜¯ Observation?**\n",
    "```\n",
    "ç­”: éƒ½å¯ä»¥ï¼Œä½†é€šå¸¸:\n",
    "- Entity embedding: æ•´å€‹å¯¦é«”çš„èªç¾©å‘é‡ï¼ˆç”±ç³»çµ±è‡ªå‹•ç”Ÿæˆæˆ–ä½ æä¾›ï¼‰\n",
    "- Observation: å­˜æ–‡æœ¬ï¼Œæ²’æœ‰å–®ç¨çš„ embedding\n",
    "\n",
    "ç•¶ search_nodes æ™‚:\n",
    "- ç”¨ Entity çš„ embedding é€²è¡Œå‘é‡æœå°‹\n",
    "- ç”¨ Observation çš„æ–‡æœ¬é€²è¡Œé—œéµè©æœå°‹ï¼ˆLIKEï¼‰\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f59632",
   "metadata": {},
   "source": [
    "## æŒ‰ entity_type é€²è¡ŒæŸ¥è©¢\n",
    "\n",
    "### å•é¡Œï¼šèƒ½å¦ç›´æ¥æŒ‡å®š entity_type éæ¿¾ï¼Ÿ\n",
    "\n",
    "æ ¹æ“šå®˜æ–¹æºç¢¼åˆ†æï¼Œ`search_nodes` **æ²’æœ‰ç›´æ¥çš„ `entity_type` åƒæ•¸**ï¼Œä½†å¯ä»¥é€šéæŸ¥è©¢ entity_type å€¼é–“æ¥å¯¦ç¾ï¼š\n",
    "\n",
    "### å®˜æ–¹æºç¢¼ä¸­çš„æœå°‹é‚è¼¯\n",
    "\n",
    "```sql\n",
    "-- æ–‡æœ¬æœå°‹æ™‚ï¼Œæœƒåœ¨ä»¥ä¸‹ä¸‰å€‹å­—æ®µä¸­æœå°‹ï¼š\n",
    "WHERE e.name LIKE ? \n",
    "  OR e.entity_type LIKE ? \n",
    "  OR o.content LIKE ?\n",
    "```\n",
    "\n",
    "ä¹Ÿå°±æ˜¯èªªï¼ŒæŸ¥è©¢èªå¥æœƒæœç´¢ï¼š\n",
    "- `Entity.name`ï¼šå¯¦é«”çš„å”¯ä¸€åç¨±\n",
    "- `Entity.entity_type`ï¼šå¯¦é«”çš„é¡å‹å­—æ®µ âœ…\n",
    "- `Observation.content`ï¼šè§€æ¸¬å…§å®¹\n",
    "\n",
    "### æŒ‰ entity_type æŸ¥è©¢çš„æ–¹æ³•\n",
    "\n",
    "#### æ–¹å¼ 1ï¼šç›´æ¥æŸ¥è©¢ entity_type åç¨±ï¼ˆæ¨è–¦ï¼‰\n",
    "\n",
    "```python\n",
    "# æŸ¥è©¢æ‰€æœ‰ \"trading_decision\" é¡å‹çš„å¯¦é«”\n",
    "result = await memory_mcp.session.call_tool(\n",
    "    \"search_nodes\",\n",
    "    {\n",
    "        \"query\": \"trading_decision\",  # é€™æœƒåŒ¹é… entity_type=\"trading_decision\"\n",
    "        \"limit\": 10\n",
    "    }\n",
    ")\n",
    "\n",
    "data = json.loads(result.content[0].text)\n",
    "entities = data[\"nodes\"]\n",
    "# è¿”å›çš„å¯¦é«”æœƒåŒ…æ‹¬æ‰€æœ‰ entity_type ç‚º \"trading_decision\" çš„å¯¦é«”\n",
    "```\n",
    "\n",
    "#### æ–¹å¼ 2ï¼šçµåˆ entity_type å’Œå…¶ä»–ä¿¡æ¯\n",
    "\n",
    "```python\n",
    "# æŸ¥è©¢ \"trading\" é¡å‹ä¸­åŒ…å« \"TSMC\" çš„å¯¦é«”\n",
    "result = await memory_mcp.session.call_tool(\n",
    "    \"search_nodes\",\n",
    "    {\n",
    "        \"query\": \"trading_decision TSMC\",  # æœƒåŒ¹é…åŒ…å«é€™äº›è©çš„å¯¦é«”\n",
    "        \"limit\": 10\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "#### æ–¹å¼ 3ï¼šåœ¨æ‡‰ç”¨å±¤é€²è¡Œéæ¿¾ï¼ˆç²¾ç¢ºåŒ¹é…ï¼‰\n",
    "\n",
    "å¦‚æœéœ€è¦ç²¾ç¢ºåŒ¹é… `entity_type`ï¼Œå¯ä»¥åœ¨æ‡‰ç”¨å±¤éæ¿¾çµæœï¼š\n",
    "\n",
    "```python\n",
    "async def search_by_entity_type(memory_mcp, entity_type: str, limit: int = 10):\n",
    "    \"\"\"\n",
    "    æŒ‰ entity_type ç²¾ç¢ºæŸ¥è©¢\n",
    "    \"\"\"\n",
    "    # æŸ¥è©¢ entity_type\n",
    "    result = await memory_mcp.session.call_tool(\n",
    "        \"search_nodes\",\n",
    "        {\n",
    "            \"query\": entity_type,\n",
    "            \"limit\": limit\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    data = json.loads(result.content[0].text)\n",
    "    entities = data[\"nodes\"]\n",
    "    \n",
    "    # æ‡‰ç”¨å±¤éæ¿¾ï¼šåªè¿”å›ç²¾ç¢ºåŒ¹é…çš„å¯¦é«”\n",
    "    filtered = [e for e in entities if e.get(\"entityType\") == entity_type]\n",
    "    \n",
    "    return {\n",
    "        \"nodes\": filtered,\n",
    "        \"relations\": data[\"relations\"]\n",
    "    }\n",
    "\n",
    "# ä½¿ç”¨\n",
    "result = await search_by_entity_type(memory_mcp, \"trading_decision\")\n",
    "```\n",
    "\n",
    "### å¯¦éš›ä¾‹å­\n",
    "\n",
    "```python\n",
    "# å‡è¨­å·²å‰µå»ºä»¥ä¸‹å¯¦é«”ï¼š\n",
    "# 1. market_analysis_2025_01_15 (entityType: \"market_analysis\")\n",
    "# 2. trading_decision_2025_01_15 (entityType: \"trading_decision\")\n",
    "# 3. trading_result_2025_01_15 (entityType: \"trading_result\")\n",
    "\n",
    "# æŸ¥è©¢æ‰€æœ‰äº¤æ˜“æ±ºç­–\n",
    "result = await memory_mcp.session.call_tool(\n",
    "    \"search_nodes\",\n",
    "    {\"query\": \"trading_decision\"}\n",
    ")\n",
    "\n",
    "data = json.loads(result.content[0].text)\n",
    "print(f\"æ‰¾åˆ° {len(data['nodes'])} å€‹äº¤æ˜“æ±ºç­–å¯¦é«”\")\n",
    "\n",
    "# è¼¸å‡ºç¤ºä¾‹ï¼š\n",
    "# æ‰¾åˆ° 1 å€‹äº¤æ˜“æ±ºç­–å¯¦é«”\n",
    "# {\n",
    "#   \"nodes\": [\n",
    "#     {\n",
    "#       \"name\": \"trading_decision_2025_01_15\",\n",
    "#       \"entityType\": \"trading_decision\",\n",
    "#       \"observations\": [...],\n",
    "#       ...\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "```\n",
    "\n",
    "### é‡è¦é™åˆ¶\n",
    "\n",
    "| é™åˆ¶é … | èªªæ˜ |\n",
    "|-------|------|\n",
    "| **æœ€å¤š 5 å€‹çµæœ** | ç„¡è«– `limit` åƒæ•¸æ˜¯å¤šå°‘ï¼Œæœ€å¤šè¿”å› 5 å€‹çµæœï¼ˆç¡¬é™åˆ¶ï¼‰ |\n",
    "| **æ¨¡ç³ŠåŒ¹é…** | ä½¿ç”¨ LIKE %query%ï¼Œå³å­å­—ç¬¦ä¸²åŒ¹é…ï¼Œä¸æ˜¯ç²¾ç¢ºåŒ¹é… |\n",
    "| **æœç´¢ç¯„åœ** | åŒæ™‚æœç´¢ nameã€entity_type å’Œ observations |\n",
    "| **ç„¡éæ¿¾å™¨åƒæ•¸** | search_nodes æœ¬èº«æ²’æœ‰ `filter` æˆ– `entityType` åƒæ•¸ |\n",
    "\n",
    "### æœ€ä½³å¯¦è¸\n",
    "\n",
    "1. **ç‚º entity_type ä½¿ç”¨æœ‰æ„ç¾©çš„åç¨±**\n",
    "   ```python\n",
    "   # âœ… å¥½çš„å‘½å\n",
    "   \"entityType\": \"trading_decision\"\n",
    "   \"entityType\": \"market_analysis\"\n",
    "   \n",
    "   # âŒ å®¹æ˜“æ··æ·†çš„å‘½å\n",
    "   \"entityType\": \"t1\"\n",
    "   \"entityType\": \"m1\"\n",
    "   ```\n",
    "\n",
    "2. **ä½¿ç”¨è©³ç´°çš„æœå°‹è©**\n",
    "   ```python\n",
    "   # âœ… æ›´å®¹æ˜“æ‰¾åˆ°\n",
    "   await memory_mcp.session.call_tool(\n",
    "       \"search_nodes\",\n",
    "       {\"query\": \"trading_decision TSMC 2330\"}\n",
    "   )\n",
    "   \n",
    "   # âš ï¸ å¯èƒ½èˆ‡å…¶ä»–å¯¦é«”æ··æ·†\n",
    "   await memory_mcp.session.call_tool(\n",
    "       \"search_nodes\",\n",
    "       {\"query\": \"trading\"}\n",
    "   )\n",
    "   ```\n",
    "\n",
    "3. **åœ¨æ‡‰ç”¨å±¤ç¶­è­·ç´¢å¼•**\n",
    "   å¦‚æœéœ€è¦é »ç¹æŒ‰ entity_type æŸ¥è©¢ï¼Œå»ºè­°åœ¨æ‡‰ç”¨å±¤ç¶­è­·ä¸€å€‹ç´¢å¼•ï¼š\n",
    "   ```python\n",
    "   # åˆå§‹åŒ–æ™‚æ§‹å»ºç´¢å¼•\n",
    "   async def build_entity_type_index(memory_mcp):\n",
    "       result = await memory_mcp.session.call_tool(\"read_graph\", {})\n",
    "       data = json.loads(result.content[0].text)\n",
    "       \n",
    "       entity_type_index = {}\n",
    "       for entity in data[\"nodes\"]:\n",
    "           entity_type = entity.get(\"entityType\")\n",
    "           if entity_type not in entity_type_index:\n",
    "               entity_type_index[entity_type] = []\n",
    "           entity_type_index[entity_type].append(entity.get(\"name\"))\n",
    "       \n",
    "       return entity_type_index\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_search_by_entity_type():\n",
    "    \"\"\"\n",
    "    æ¸¬è©¦æŒ‰ entity_type é€²è¡ŒæŸ¥è©¢\n",
    "    \n",
    "    æ¼”ç¤ºä¸‰ç¨®æ–¹å¼ï¼š\n",
    "    1. ç›´æ¥æŸ¥è©¢ entity_type åç¨±\n",
    "    2. çµåˆ entity_type å’Œå…¶ä»–æ¢ä»¶\n",
    "    3. æ‡‰ç”¨å±¤ç²¾ç¢ºéæ¿¾\n",
    "    \"\"\"\n",
    "    global memory_mcp\n",
    "    \n",
    "    if not memory_mcp:\n",
    "        print(\"âœ— Memory MCP æœªåˆå§‹åŒ–\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"æ¸¬è©¦: æŒ‰ entity_type é€²è¡ŒæŸ¥è©¢\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # æº–å‚™æ¸¬è©¦æ•¸æ“š\n",
    "    print(\"\\n1ï¸âƒ£  å‰µå»ºæ¸¬è©¦å¯¦é«”\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    test_entities = [\n",
    "        {\n",
    "            \"name\": \"market_analysis_tech_2025\",\n",
    "            \"entityType\": \"market_analysis\",\n",
    "            \"observations\": [\"æŠ€è¡“æŒ‡æ¨™çœ‹å¥½\", \"åŠå°é«”æ¿å¡Šä¸Šå‡\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"market_analysis_finance_2025\",\n",
    "            \"entityType\": \"market_analysis\",\n",
    "            \"observations\": [\"èè³‡ä½™é¡ä¸‹é™\", \"è³‡é‡‘é¢å¯¬é¬†\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"trading_decision_buy_tsmc\",\n",
    "            \"entityType\": \"trading_decision\",\n",
    "            \"observations\": [\"è²·å…¥ TSMC 2330\", \"æ•¸é‡ 1000 è‚¡\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"trading_decision_sell_amd\",\n",
    "            \"entityType\": \"trading_decision\",\n",
    "            \"observations\": [\"è³£å‡º AMD\", \"ç²åˆ©äº†çµ\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"trading_result_success\",\n",
    "            \"entityType\": \"trading_result\",\n",
    "            \"observations\": [\"æˆäº¤æˆåŠŸ\", \"åƒ¹æ ¼: 615 å…ƒ\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        result = await memory_mcp.session.call_tool(\n",
    "            \"create_entities\",\n",
    "            {\"entities\": test_entities}\n",
    "        )\n",
    "        print(f\"âœ… å‰µå»º {len(test_entities)} å€‹æ¸¬è©¦å¯¦é«”æˆåŠŸ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å‰µå»ºå¤±æ•—: {e}\")\n",
    "        return\n",
    "    \n",
    "    # æ–¹å¼ 1: ç›´æ¥æŸ¥è©¢ entity_type\n",
    "    print(\"\\n\\n2ï¸âƒ£  æ–¹å¼ 1: ç›´æ¥æŸ¥è©¢ entity_type åç¨±\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    entity_types = [\"market_analysis\", \"trading_decision\", \"trading_result\"]\n",
    "    \n",
    "    for entity_type in entity_types:\n",
    "        print(f\"\\næŸ¥è©¢: '{entity_type}'\")\n",
    "        try:\n",
    "            result = await memory_mcp.session.call_tool(\n",
    "                \"search_nodes\",\n",
    "                {\"query\": entity_type, \"limit\": 10}\n",
    "            )\n",
    "            \n",
    "            if hasattr(result, \"content\") and result.content:\n",
    "                content_item = result.content[0]\n",
    "                text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "                data = json.loads(text_content)\n",
    "                nodes = data.get(\"nodes\", [])\n",
    "                \n",
    "                print(f\"  æ‰¾åˆ° {len(nodes)} å€‹çµæœ:\")\n",
    "                for node in nodes:\n",
    "                    print(f\"    â€¢ {node.get('name')} (type: {node.get('entityType')})\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ æŸ¥è©¢å¤±æ•—: {e}\")\n",
    "    \n",
    "    # æ–¹å¼ 2: çµåˆ entity_type å’Œå…¶ä»–æ¢ä»¶\n",
    "    print(\"\\n\\n3ï¸âƒ£  æ–¹å¼ 2: çµåˆ entity_type å’Œå…¶ä»–æ¢ä»¶\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    combined_queries = [\n",
    "        \"trading_decision TSMC\",\n",
    "        \"market_analysis æŠ€è¡“\",\n",
    "        \"trading_result æˆåŠŸ\"\n",
    "    ]\n",
    "    \n",
    "    for query in combined_queries:\n",
    "        print(f\"\\næŸ¥è©¢: '{query}'\")\n",
    "        try:\n",
    "            result = await memory_mcp.session.call_tool(\n",
    "                \"search_nodes\",\n",
    "                {\"query\": query, \"limit\": 10}\n",
    "            )\n",
    "            \n",
    "            if hasattr(result, \"content\") and result.content:\n",
    "                content_item = result.content[0]\n",
    "                text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "                data = json.loads(text_content)\n",
    "                nodes = data.get(\"nodes\", [])\n",
    "                \n",
    "                print(f\"  æ‰¾åˆ° {len(nodes)} å€‹çµæœ:\")\n",
    "                for node in nodes:\n",
    "                    print(f\"    â€¢ {node.get('name')}\")\n",
    "                    observations = node.get('observations', [])\n",
    "                    if observations:\n",
    "                        print(f\"      è§€æ¸¬: {observations[0]}\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ æŸ¥è©¢å¤±æ•—: {e}\")\n",
    "    \n",
    "    # æ–¹å¼ 3: æ‡‰ç”¨å±¤ç²¾ç¢ºéæ¿¾\n",
    "    print(\"\\n\\n4ï¸âƒ£  æ–¹å¼ 3: æ‡‰ç”¨å±¤ç²¾ç¢ºéæ¿¾ (æ¨è–¦ç”¨æ–¼ç²¾ç¢ºåŒ¹é…)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    async def search_by_entity_type_exact(entity_type: str):\n",
    "        \"\"\"ç²¾ç¢ºæŸ¥è©¢æŒ‡å®š entity_type çš„æ‰€æœ‰å¯¦é«”\"\"\"\n",
    "        try:\n",
    "            result = await memory_mcp.session.call_tool(\n",
    "                \"search_nodes\",\n",
    "                {\"query\": entity_type, \"limit\": 10}\n",
    "            )\n",
    "            \n",
    "            if hasattr(result, \"content\") and result.content:\n",
    "                content_item = result.content[0]\n",
    "                text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "                data = json.loads(text_content)\n",
    "                nodes = data.get(\"nodes\", [])\n",
    "                \n",
    "                # æ‡‰ç”¨å±¤éæ¿¾ï¼šåªè¿”å›ç²¾ç¢ºåŒ¹é…çš„å¯¦é«”\n",
    "                filtered = [n for n in nodes if n.get(\"entityType\") == entity_type]\n",
    "                \n",
    "                return {\n",
    "                    \"query_entity_type\": entity_type,\n",
    "                    \"total_found\": len(nodes),\n",
    "                    \"exact_matched\": len(filtered),\n",
    "                    \"nodes\": filtered\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ æŸ¥è©¢å¤±æ•—: {e}\")\n",
    "            return None\n",
    "    \n",
    "    print(\"\\nç²¾ç¢ºæŸ¥è©¢ 'trading_decision' é¡å‹çš„å¯¦é«”:\")\n",
    "    result = await search_by_entity_type_exact(\"trading_decision\")\n",
    "    if result:\n",
    "        print(f\"  æŸ¥è©¢ entity_type: {result['query_entity_type']}\")\n",
    "        print(f\"  æœå°‹çµæœç¸½æ•¸: {result['total_found']}\")\n",
    "        print(f\"  ç²¾ç¢ºåŒ¹é…æ•¸: {result['exact_matched']}\")\n",
    "        print(f\"  çµæœ:\")\n",
    "        for node in result['nodes']:\n",
    "            print(f\"    â€¢ {node.get('name')}\")\n",
    "    \n",
    "    # é©—è­‰\n",
    "    print(\"\\n\\n5ï¸âƒ£  é©—è­‰: è®€å–å®Œæ•´åœ–è­œç¢ºèª\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    try:\n",
    "        result = await memory_mcp.session.call_tool(\n",
    "            \"read_graph\",\n",
    "            {\"limit\": 100}\n",
    "        )\n",
    "        \n",
    "        if hasattr(result, \"content\") and result.content:\n",
    "            content_item = result.content[0]\n",
    "            text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "            data = json.loads(text_content)\n",
    "            nodes = data.get(\"nodes\", [])\n",
    "            \n",
    "            # çµ±è¨ˆæ¯å€‹ entity_type çš„æ•¸é‡\n",
    "            entity_type_count = {}\n",
    "            for node in nodes:\n",
    "                entity_type = node.get(\"entityType\")\n",
    "                entity_type_count[entity_type] = entity_type_count.get(entity_type, 0) + 1\n",
    "            \n",
    "            print(f\"âœ… åœ–è­œä¸­ entity_type çµ±è¨ˆ:\")\n",
    "            for entity_type, count in entity_type_count.items():\n",
    "                print(f\"  â€¢ {entity_type}: {count} å€‹å¯¦é«”\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è®€å–åœ–è­œå¤±æ•—: {e}\")\n",
    "    \n",
    "    print(f\"\\nâœ… æ¸¬è©¦å®Œæˆ\")\n",
    "\n",
    "# åŸ·è¡Œæ¸¬è©¦\n",
    "print(\"\\né–‹å§‹æ¸¬è©¦æŒ‰ entity_type é€²è¡ŒæŸ¥è©¢\")\n",
    "await test_search_by_entity_type()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# è¨ºæ–·ï¼šæª¢æŸ¥ DB ä¸­çš„å¯¦éš›æ•¸æ“š\n",
    "import sqlite3\n",
    "\n",
    "db_path = \"/Users/sacahan/Documents/workspace/CasualTrader/backend/memory/test_memory.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print(\"\\nğŸ“Š æ•¸æ“šåº«ä¸­çš„å¯¦é«”:\")\n",
    "cursor.execute(\"SELECT name, entity_type FROM entities LIMIT 15\")\n",
    "for row in cursor.fetchall():\n",
    "    print(f\"  â€¢ {row[0]} (type: {row[1]})\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# å˜—è©¦ read_graph\n",
    "print(\"\\nğŸ” å˜—è©¦ read_graph:\")\n",
    "try:\n",
    "    result = await memory_mcp.session.call_tool(\"read_graph\", {\"limit\": 100})\n",
    "    if hasattr(result, \"content\") and result.content:\n",
    "        content_item = result.content[0]\n",
    "        text_content = content_item.text if hasattr(content_item, \"text\") else str(content_item)\n",
    "        data = json.loads(text_content)\n",
    "        print(f\"  æ‰¾åˆ° {len(data.get('nodes', []))} å€‹å¯¦é«”\")\n",
    "except Exception as e:\n",
    "    print(f\"  âŒ éŒ¯èª¤: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f17d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def cleanup():\n",
    "    \"\"\"\n",
    "    æ¸…ç† Memory MCP é€£æ¥å’Œç›¸é—œè³‡æº\n",
    "    \"\"\"\n",
    "    global memory_mcp, _exit_stack\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"æ¸…ç†è³‡æº\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        if _exit_stack:\n",
    "            await _exit_stack.aclose()\n",
    "            print(\"âœ“ Exit stack å·²é—œé–‰\")\n",
    "        \n",
    "        memory_mcp = None\n",
    "        print(\"âœ“ Memory MCP é€£æ¥å·²æ¸…ç†\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— æ¸…ç†å¤±æ•—: {type(e).__name__}: {str(e)}\")\n",
    "\n",
    "# åŸ·è¡Œæ¸…ç†\n",
    "await cleanup()\n",
    "print(\"\\nâœ“ Notebook åŸ·è¡Œå®Œæˆï¼\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
