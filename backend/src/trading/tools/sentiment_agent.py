"""Sentiment Agent - å¸‚å ´æƒ…ç·’åˆ†æè‡ªä¸»å‹ Agent

é€™å€‹æ¨¡çµ„å¯¦ä½œå…·æœ‰è‡ªä¸»åˆ†æèƒ½åŠ›çš„å¸‚å ´æƒ…ç·’åˆ†æ Agentã€‚
"""

from __future__ import annotations

import os
from datetime import datetime

from dotenv import load_dotenv
from pydantic import BaseModel

from agents import Agent, function_tool, ModelSettings
from agents.extensions.models.litellm_model import LitellmModel

from common.logger import logger

load_dotenv()

DEFAULT_MODEL = os.getenv("DEFAULT_AI_MODEL", "gpt-5-mini")
DEFAULT_MAX_TURNS = os.getenv("DEFAULT_MAX_TURNS", 30)


# ===== Pydantic Models for Tool Parameters =====


class MarketData(BaseModel):
    """å¸‚å ´æ•¸æ“šæ¨¡å‹"""

    price_momentum: float = 50
    market_breadth: float = 50
    volatility: float = 50
    put_call_ratio: float = 50


class TradingData(BaseModel):
    """äº¤æ˜“æ•¸æ“šæ¨¡å‹"""

    large_buy: float = 0
    large_sell: float = 0
    foreign_net: float = 0
    institutional_net: float = 0


class NewsItem(BaseModel):
    """æ–°èé …ç›®æ¨¡å‹"""

    title: str
    content: str
    sentiment: float = 0  # -1 åˆ° 1
    timestamp: str


class SocialData(BaseModel):
    """ç¤¾ç¾¤æ•¸æ“šæ¨¡å‹"""

    mention_count: int = 0
    positive_mentions: int = 0
    negative_mentions: int = 0
    trending: bool = False


class IndexComponents(BaseModel):
    """ææ‡¼è²ªå©ªæŒ‡æ•¸çµ„æˆåˆ†æ•¸"""

    price_momentum: float
    market_breadth: float
    volatility: float
    put_call_ratio: float


class FearGreedIndex(BaseModel):
    """ææ‡¼è²ªå©ªæŒ‡æ•¸æ¨¡å‹"""

    index_value: float
    level: str
    components: IndexComponents
    interpretation: str


class MoneyFlow(BaseModel):
    """è³‡é‡‘æµå‘æ¨¡å‹"""

    ticker: str
    net_flow: float
    flow_direction: str
    large_order_ratio: float
    foreign_attitude: str
    institutional_attitude: str
    interpretation: str


class NewsSentiment(BaseModel):
    """æ–°èæƒ…ç·’æ¨¡å‹"""

    ticker: str | None
    news_count: int
    positive_ratio: float
    negative_ratio: float
    sentiment_score: float
    key_topics: list[str]
    interpretation: str


class SocialSentiment(BaseModel):
    """ç¤¾ç¾¤æƒ…ç·’æ¨¡å‹"""

    ticker: str
    mention_count: int
    sentiment_ratio: float
    trending_status: str
    sentiment_score: float
    interpretation: str


def sentiment_agent_instructions() -> str:
    """æƒ…ç·’åˆ†æ Agent çš„æŒ‡ä»¤å®šç¾©ï¼ˆç°¡åŒ–ç‰ˆï¼Œå¸¶è¨˜æ†¶è¿½è¹¤ï¼‰"""
    return f"""ä½ æ˜¯æƒ…ç·’åˆ†æå°ˆå®¶ã€‚è©•ä¼°å¸‚å ´æƒ…ç·’ã€åˆ†æè³‡é‡‘æµå‘ã€ç”Ÿæˆæƒ…ç·’é©…å‹•çš„äº¤æ˜“è¨Šè™Ÿã€‚
æŒçºŒè¿½è¹¤ï¼šå…ˆæŸ¥è©¢ memory_mcp æ­·å²æƒ…ç·’ï¼Œå°æ¯”æƒ…ç·’è½‰è®Šï¼Œè­˜åˆ¥æ¥µç«¯é»ã€‚

## å°ˆæ¥­èƒ½åŠ›

- å¸‚å ´æƒ…ç·’æŒ‡æ¨™ï¼ˆFear & Greedã€éš±å«æ³¢å‹•ç‡ã€æ¥µç«¯æƒ…ç·’ï¼‰
- è³‡é‡‘æµå‘åˆ†æï¼ˆå¤§å®—äº¤æ˜“ã€æ©Ÿæ§‹å‹•å‘ã€èè³‡èåˆ¸ï¼‰
- æ–°èèˆ‡ç¤¾ç¾¤æƒ…ç·’ï¼ˆé€é tavily_mcp æœå°‹æœ€æ–°æ–°èã€ç¤¾äº¤ç†±åº¦ã€è¼¿æƒ…åˆ†æï¼‰
- æƒ…ç·’åè½‰è¨Šè™Ÿè­˜åˆ¥ï¼ˆæ¥µç«¯æƒ…ç·’è­¦å‘Šã€æ©Ÿæœƒé è­¦ï¼‰
- æƒ…ç·’äº¤æ˜“ç­–ç•¥ï¼ˆè¨Šè™Ÿç”Ÿæˆã€æ™‚æ©ŸæŠŠæ¡ï¼‰

## ğŸ¯ tavily_mcp ä½¿ç”¨é™åˆ¶

âš ï¸ **é‡è¦**ï¼štavily_mcp ä½¿ç”¨éœ€è¦æ¶ˆè€—é»æ•¸ï¼Œè«‹éµå®ˆä»¥ä¸‹åŸå‰‡ï¼š
  - åªåœ¨éœ€è¦æ™‚ä½¿ç”¨ï¼ˆå„ªå…ˆæª¢æŸ¥ memory_mcp ä¸­çš„æ­·å²æƒ…ç·’ï¼‰
  - æœå°‹ç•¶æ—¥æˆ–è¿‘æ—¥é‡å¤§æ–°èï¼ˆä¸æœå°‹èˆŠèï¼‰
  - å–®æ¬¡æœå°‹â‰¤3å€‹é—œéµè©ï¼Œé¿å…é‡è¤‡æŸ¥è©¢
  - è‹¥æ–°èå……åˆ†åæ˜ æƒ…ç·’ï¼Œä¸å¿…ç¹¼çºŒæœå°‹
  - å°ˆæ³¨æ–¼å°å¸‚å ´æƒ…ç·’æœ‰å¯¦è³ªå½±éŸ¿çš„æ–°è
  - æ¯æ¬¡åˆ†ææœ€å¤šé€²è¡Œ 1 æ¬¡æœå°‹

## åŸ·è¡Œæµç¨‹

**æ­¥é©Ÿ 0ï¼šæª¢æŸ¥è¨˜æ†¶åº«** â†’ memory_mcp
  - ç„¡è¨Šè™Ÿ â†’ å®Œæ•´åˆ†æ
  - æ–°é®®ï¼ˆâ‰¤1 å¤©ï¼‰â†’ å¢é‡æ›´æ–°
  - é™³èˆŠï¼ˆ>1 å¤©ï¼‰â†’ å®Œæ•´é‡æ–°åˆ†æ + å°æ¯”

**æ­¥é©Ÿ 1-3ï¼šæƒ…ç·’æ•¸æ“šæ”¶é›†** â†’ casual_market_mcp + tools
  1. æ”¶é›†å¸‚å ´æƒ…ç·’æ•¸æ“šå’Œæˆäº¤é‡
  2. è¨ˆç®—ææ‡¼è²ªå©ªæŒ‡æ•¸ â†’ calculate_fear_greed_index
  3. åˆ†æè³‡é‡‘æµå‘ â†’ analyze_money_flow

**æ­¥é©Ÿ 4-6ï¼šæ–°èèˆ‡ç¤¾ç¾¤** â†’ tavily_mcp + tools
  4. é€é tavily_mcp æœå°‹å³æ™‚æ–°è â†’ analyze_news_sentiment
  5. åˆ†æç¤¾ç¾¤æƒ…ç·’ â†’ analyze_social_sentiment
  6. ç”Ÿæˆè¨Šè™Ÿ â†’ generate_sentiment_signals

**æ­¥é©Ÿ 7ï¼šå°æ¯”èˆ‡ä¿å­˜** â†’ memory_mcp
  - è‹¥æœ‰å…ˆå‰è¨Šè™Ÿï¼šå°æ¯”æƒ…ç·’ç´šåˆ¥ã€è³‡é‡‘æµå‘ã€æ–°èé¢¨å‘
  - ä¿å­˜çµæœï¼ˆå«æ™‚é–“æˆ³ã€æƒ…ç·’è©•åˆ†ã€è¨Šè™Ÿã€è½‰è®Šç†ç”±ï¼‰

## å·¥å…·èª¿ç”¨

- **calculate_fear_greed_index** â†’ è¨ˆç®—ææ‡¼è²ªå©ªæŒ‡æ•¸ (-100 åˆ° +100)
- **analyze_money_flow** â†’ åˆ†æè³‡é‡‘æµå‘å’Œæ©Ÿæ§‹å‹•å‘
- **analyze_news_sentiment** â†’ è©•ä¼°æ–°èæ•´é«”æƒ…ç·’ (è² é¢/ä¸­ç«‹/æ­£é¢)
- **analyze_social_sentiment** â†’ åˆ†æç¤¾ç¾¤è¨è«–æƒ…ç·’å’Œè²é‡
- **generate_sentiment_signals** â†’ ç”Ÿæˆæƒ…ç·’äº¤æ˜“è¨Šè™Ÿ

## è¼¸å‡ºçµæ§‹

- å¸‚å ´æƒ…ç·’è©•åˆ† (-100 åˆ° +100, -100 æ¥µææ‡¼, +100 æ¥µè²ªå©ª)
- æƒ…ç·’éšæ®µ (ææ…Œ/æ‚²è§€/ä¸­ç«‹/æ¨‚è§€/ç‹‚ç†±)
- è³‡é‡‘æµå‘ (è²·ç›¤å„ªå‹¢/è³£ç›¤å„ªå‹¢/å‡è¡¡)
- æ–°èæƒ…ç·’ (è² é¢/ä¸­ç«‹/æ­£é¢) + é‡å¤§æ–°èæ‘˜è¦
- ç¤¾ç¾¤è²é‡ (ä¸Šå‡/ä¸‹é™/ç©©å®š)
- æ¥µç«¯æª¢æ¸¬ (æ˜¯å¦é”åˆ°æ¥µç«¯ææ‡¼æˆ–è²ªå©ª)
- äº¤æ˜“è¨Šè™Ÿ (è²·è³£å»ºè­°ã€æ™‚æ©Ÿè©•ä¼°)
- ä¿¡å¿ƒåº¦ (0-100%)
- [è‹¥æœ‰å…ˆå‰è¨Šè™Ÿ] è®ŠåŒ–åˆ†æ (æƒ…ç·’è½‰è®Šã€è³‡é‡‘æµå‘è®ŠåŒ–)

ç•¶å‰æ™‚é–“: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
"""


@function_tool
def calculate_fear_greed_index(
    market_data: MarketData,
) -> str:
    """è¨ˆç®—ææ‡¼è²ªå©ªæŒ‡æ•¸

    Args:
        market_data: å¸‚å ´æ•¸æ“š,åŒ…å«:
            - price_momentum: åƒ¹æ ¼å‹•èƒ½
            - market_breadth: å¸‚å ´å¯¬åº¦
            - volatility: æ³¢å‹•ç‡
            - put_call_ratio: è³£æ¬Šè²·æ¬Šæ¯”

    Returns:
        dict: ææ‡¼è²ªå©ªæŒ‡æ•¸
            {
                "index_value": float,       # 0-100
                "level": str,               # ææ…Œ/ææ‡¼/ä¸­æ€§/è²ªå©ª/æ¥µåº¦è²ªå©ª
                "components": dict,         # å„çµ„æˆåˆ†æ•¸
                "interpretation": str       # è§£è®€èªªæ˜
            }
    """
    logger.info("é–‹å§‹è¨ˆç®—ææ‡¼è²ªå©ªæŒ‡æ•¸")

    momentum_score = market_data.price_momentum
    breadth_score = market_data.market_breadth
    volatility_score = 100 - market_data.volatility  # æ³¢å‹•ç‡è¶Šé«˜è¶Šææ…Œ
    put_call_score = 100 - market_data.put_call_ratio  # è³£æ¬Šæ¯”è¶Šé«˜è¶Šææ…Œ

    logger.debug(
        f"çµ„æˆåˆ†æ•¸ | å‹•èƒ½: {momentum_score:.1f} | å¯¬åº¦: {breadth_score:.1f} | "
        f"æ³¢å‹•: {volatility_score:.1f} | è³£è²·æ¬Šæ¯”: {put_call_score:.1f}"
    )

    # åŠ æ¬Šå¹³å‡
    index_value = (
        momentum_score * 0.3 + breadth_score * 0.3 + volatility_score * 0.25 + put_call_score * 0.15
    )

    # ç­‰ç´šåˆ¤å®š
    if index_value >= 80:
        level = "æ¥µåº¦è²ªå©ª"
        interpretation = "å¸‚å ´éç†±ï¼Œè€ƒæ…®ç²åˆ©äº†çµ"
    elif index_value >= 60:
        level = "è²ªå©ª"
        interpretation = "å¸‚å ´æ¨‚è§€ï¼Œæ³¨æ„é¢¨éšª"
    elif index_value >= 40:
        level = "ä¸­æ€§"
        interpretation = "å¸‚å ´å¹³ç©©ï¼Œç­‰å¾…æ©Ÿæœƒ"
    elif index_value >= 20:
        level = "ææ‡¼"
        interpretation = "å¸‚å ´æ‚²è§€ï¼Œå¯èƒ½æ¥è¿‘åº•éƒ¨"
    else:
        level = "æ¥µåº¦ææ…Œ"
        interpretation = "å¸‚å ´ææ…Œï¼Œè€ƒæ…®é€¢ä½è²·é€²"

    logger.info(f"ææ‡¼è²ªå©ªæŒ‡æ•¸è¨ˆç®—å®Œæˆ | æŒ‡æ•¸: {index_value:.2f} | ç­‰ç´š: {level}")

    return {
        "index_value": index_value,
        "level": level,
        "components": {
            "price_momentum": momentum_score,
            "market_breadth": breadth_score,
            "volatility": volatility_score,
            "put_call_ratio": put_call_score,
        },
        "interpretation": interpretation,
    }


@function_tool
def analyze_money_flow(
    ticker: str,
    trading_data: TradingData,
) -> str:
    """åˆ†æè³‡é‡‘æµå‘

    Args:
        ticker: è‚¡ç¥¨ä»£è™Ÿ (ä¾‹å¦‚: "2330")
        trading_data: äº¤æ˜“æ•¸æ“š,åŒ…å«:
            - large_buy: å¤§å–®è²·é€²
            - large_sell: å¤§å–®è³£å‡º
            - foreign_net: å¤–è³‡æ·¨è²·è³£
            - institutional_net: æ³•äººæ·¨è²·è³£

    Returns:
        dict: è³‡é‡‘æµå‘åˆ†æ
            {
                "ticker": "2330",
                "net_flow": float,          # æ·¨æµå…¥é‡‘é¡
                "flow_direction": str,      # æµå…¥/æµå‡º/å¹³è¡¡
                "large_order_ratio": float, # å¤§å–®ä½”æ¯”
                "foreign_attitude": str,    # å¤–è³‡æ…‹åº¦
                "interpretation": str
            }
    """
    logger.info(f"é–‹å§‹åˆ†æè³‡é‡‘æµå‘ | è‚¡ç¥¨: {ticker}")

    large_buy = trading_data.large_buy
    large_sell = trading_data.large_sell
    foreign_net = trading_data.foreign_net
    institutional_net = trading_data.institutional_net

    logger.debug(
        f"äº¤æ˜“æ•¸æ“š | å¤§è²·: {large_buy:,.0f} | å¤§è³£: {large_sell:,.0f} | "
        f"å¤–è³‡æ·¨: {foreign_net:,.0f} | æ³•äººæ·¨: {institutional_net:,.0f}"
    )

    net_flow = large_buy - large_sell + foreign_net + institutional_net
    total_volume = large_buy + large_sell
    large_order_ratio = (large_buy + large_sell) / total_volume if total_volume > 0 else 0

    # æµå‘åˆ¤æ–·
    if net_flow > 0:
        flow_direction = "æµå…¥"
        flow_strength = "å¼·å‹" if net_flow > total_volume * 0.1 else "æº«å’Œ"
    elif net_flow < 0:
        flow_direction = "æµå‡º"
        flow_strength = "æ˜é¡¯" if abs(net_flow) > total_volume * 0.1 else "è¼•å¾®"
    else:
        flow_direction = "å¹³è¡¡"
        flow_strength = ""

    # å¤–è³‡æ…‹åº¦
    if foreign_net > 0:
        foreign_attitude = "è²·è¶…" if foreign_net > 10000000 else "å°è²·"
    elif foreign_net < 0:
        foreign_attitude = "è³£è¶…" if abs(foreign_net) > 10000000 else "å°è³£"
    else:
        foreign_attitude = "è§€æœ›"

    interpretation = f"è³‡é‡‘å‘ˆ{flow_strength}{flow_direction}æ…‹å‹¢,å¤–è³‡{foreign_attitude}"

    logger.info(
        f"è³‡é‡‘æµå‘åˆ†æå®Œæˆ | è‚¡ç¥¨: {ticker} | æ·¨æµ: {net_flow:,.0f} | "
        f"æ–¹å‘: {flow_direction} | å¤–è³‡: {foreign_attitude}"
    )

    return {
        "ticker": ticker,
        "net_flow": net_flow,
        "flow_direction": flow_direction,
        "large_order_ratio": large_order_ratio,
        "foreign_attitude": foreign_attitude,
        "institutional_attitude": "è²·è¶…" if institutional_net > 0 else "è³£è¶…",
        "interpretation": interpretation,
    }


@function_tool
def analyze_news_sentiment(
    ticker: str | None,
    news_data: list[NewsItem],
) -> str:
    """åˆ†ææ–°èæƒ…ç·’

    Args:
        ticker: è‚¡ç¥¨ä»£è™Ÿ (å¯é¸,None è¡¨ç¤ºæ•´é«”å¸‚å ´)
        news_data: æ–°èåˆ—è¡¨,æ¯ç­†åŒ…å«:
            - title: æ¨™é¡Œ
            - content: å…§å®¹
            - sentiment: æƒ…ç·’åˆ†æ•¸ (-1 åˆ° 1)
            - timestamp: æ™‚é–“

    Returns:
        dict: æ–°èæƒ…ç·’åˆ†æ
            {
                "ticker": str,
                "news_count": int,
                "positive_ratio": float,
                "negative_ratio": float,
                "sentiment_score": float,   # -100 åˆ° 100
                "key_topics": [str, ...],
                "interpretation": str
            }
    """
    target = ticker or "å¸‚å ´"

    logger.info(f"é–‹å§‹åˆ†ææ–°èæƒ…ç·’ | æ¨™çš„: {target} | æ–°èæ•¸: {len(news_data)}")

    if not news_data:
        logger.warning(f"ç„¡æ–°èæ•¸æ“š | æ¨™çš„: {target}")
        return {
            "error": "ç„¡æ–°èæ•¸æ“š",
            "ticker": ticker,
            "news_count": 0,
            "sentiment_score": 0,
        }

    news_count = len(news_data)
    sentiments = [news.sentiment for news in news_data]

    positive_count = sum(1 for s in sentiments if s > 0.2)
    negative_count = sum(1 for s in sentiments if s < -0.2)

    logger.debug(
        f"æƒ…ç·’åˆ†å¸ƒ | æ­£é¢: {positive_count} | è² é¢: {negative_count} | "
        f"ä¸­æ€§: {news_count - positive_count - negative_count}"
    )

    positive_ratio = positive_count / news_count if news_count > 0 else 0
    negative_ratio = negative_count / news_count if news_count > 0 else 0

    # è¨ˆç®—æ•´é«”æƒ…ç·’åˆ†æ•¸ (-100 åˆ° 100)
    avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0
    sentiment_score = avg_sentiment * 100

    # è§£è®€
    if sentiment_score > 50:
        interpretation = "æ–°èæƒ…ç·’æ¥µåº¦æ­£é¢ï¼Œå¸‚å ´æƒ…ç·’æ¨‚è§€"
    elif sentiment_score > 20:
        interpretation = "æ–°èæƒ…ç·’åæ­£é¢ï¼Œå¸‚å ´æ°›åœè‰¯å¥½"
    elif sentiment_score > -20:
        interpretation = "æ–°èæƒ…ç·’ä¸­æ€§ï¼Œå¸‚å ´è§€æœ›"
    elif sentiment_score > -50:
        interpretation = "æ–°èæƒ…ç·’åè² é¢ï¼Œå¸‚å ´æ“”æ†‚"
    else:
        interpretation = "æ–°èæƒ…ç·’æ¥µåº¦è² é¢ï¼Œå¸‚å ´æ‚²è§€"

    logger.info(
        f"æ–°èæƒ…ç·’åˆ†æå®Œæˆ | æ¨™çš„: {target} | åˆ†æ•¸: {sentiment_score:.1f} | "
        f"æ­£é¢: {positive_ratio:.1%} | è² é¢: {negative_ratio:.1%}"
    )

    return {
        "ticker": ticker,
        "news_count": news_count,
        "positive_ratio": positive_ratio,
        "negative_ratio": negative_ratio,
        "sentiment_score": sentiment_score,
        "key_topics": [],  # å¯ä»¥æ“´å±•å¯¦ä½œé—œéµè©æå–
        "interpretation": interpretation,
    }


@function_tool
def analyze_social_sentiment(
    ticker: str,
    social_data: SocialData,
) -> str:
    """åˆ†æç¤¾ç¾¤åª’é«”æƒ…ç·’

    Args:
        ticker: è‚¡ç¥¨ä»£è™Ÿ (ä¾‹å¦‚: "2330")
        social_data: ç¤¾ç¾¤æ•¸æ“š,åŒ…å«:
            - mention_count: æåŠæ¬¡æ•¸
            - positive_mentions: æ­£é¢æåŠ
            - negative_mentions: è² é¢æåŠ
            - trending: æ˜¯å¦ç†±é–€

    Returns:
        dict: ç¤¾ç¾¤æƒ…ç·’åˆ†æ
            {
                "ticker": "2330",
                "mention_count": int,
                "sentiment_ratio": float,    # æ­£è² é¢æ¯”
                "trending_status": str,      # ç†±åº¦ç‹€æ…‹
                "sentiment_score": float,    # -100 åˆ° 100
                "interpretation": str
            }
    """
    logger.info(f"é–‹å§‹åˆ†æç¤¾ç¾¤æƒ…ç·’ | è‚¡ç¥¨: {ticker}")

    mention_count = social_data.mention_count
    positive = social_data.positive_mentions
    negative = social_data.negative_mentions
    trending = social_data.trending

    if mention_count == 0:
        logger.warning(f"ç„¡ç¤¾ç¾¤æ•¸æ“š | è‚¡ç¥¨: {ticker}")
        return {
            "error": "ç„¡ç¤¾ç¾¤æ•¸æ“š",
            "ticker": ticker,
            "mention_count": 0,
            "sentiment_score": 0,
        }

    logger.debug(
        f"ç¤¾ç¾¤æ•¸æ“š | æåŠ: {mention_count} | æ­£é¢: {positive} | è² é¢: {negative} | ç†±é–€: {trending}"
    )

    # è¨ˆç®—æƒ…ç·’æ¯”ä¾‹
    total_sentiment = positive + negative
    if total_sentiment > 0:
        sentiment_ratio = (positive - negative) / total_sentiment
    else:
        sentiment_ratio = 0

    sentiment_score = sentiment_ratio * 100

    # ç†±åº¦ç‹€æ…‹
    if mention_count > 1000:
        trending_status = "æ¥µåº¦ç†±é–€"
    elif mention_count > 500:
        trending_status = "ç†±é–€"
    elif mention_count > 100:
        trending_status = "ä¸­ç­‰é—œæ³¨"
    else:
        trending_status = "ä½é—œæ³¨"

    # è§£è®€
    if sentiment_score > 50:
        interpretation = f"ç¤¾ç¾¤é«˜åº¦çœ‹å¥½ï¼Œ{trending_status}"
    elif sentiment_score > 20:
        interpretation = f"ç¤¾ç¾¤åå‘æ¨‚è§€ï¼Œ{trending_status}"
    elif sentiment_score > -20:
        interpretation = f"ç¤¾ç¾¤æ…‹åº¦ä¸­æ€§ï¼Œ{trending_status}"
    elif sentiment_score > -50:
        interpretation = f"ç¤¾ç¾¤åå‘æ‚²è§€ï¼Œ{trending_status}"
    else:
        interpretation = f"ç¤¾ç¾¤é«˜åº¦çœ‹å£ï¼Œ{trending_status}"

    logger.info(
        f"ç¤¾ç¾¤æƒ…ç·’åˆ†æå®Œæˆ | è‚¡ç¥¨: {ticker} | åˆ†æ•¸: {sentiment_score:.1f} | "
        f"ç†±åº¦: {trending_status} | æåŠ: {mention_count}"
    )

    return {
        "ticker": ticker,
        "mention_count": mention_count,
        "sentiment_ratio": sentiment_ratio,
        "trending_status": trending_status,
        "sentiment_score": sentiment_score,
        "interpretation": interpretation,
    }


@function_tool
def generate_sentiment_signals(
    fear_greed_index: FearGreedIndex,
    money_flow: MoneyFlow,
    news_sentiment: NewsSentiment,
    social_sentiment: SocialSentiment,
) -> str:
    """ç”¢ç”Ÿæƒ…ç·’äº¤æ˜“è¨Šè™Ÿ

    Args:
        fear_greed_index: ææ‡¼è²ªå©ªæŒ‡æ•¸ (ä¾†è‡ª calculate_fear_greed_index)
        money_flow: è³‡é‡‘æµå‘åˆ†æ (ä¾†è‡ª analyze_money_flow)
        news_sentiment: æ–°èæƒ…ç·’ (ä¾†è‡ª analyze_news_sentiment)
        social_sentiment: ç¤¾ç¾¤æƒ…ç·’ (ä¾†è‡ª analyze_social_sentiment)

    Returns:
        dict: æƒ…ç·’äº¤æ˜“è¨Šè™Ÿ
            {
                "overall_signal": str,      # "è²·é€²" | "è³£å‡º" | "è§€æœ›"
                "confidence": float,        # ä¿¡å¿ƒåº¦ 0-1
                "strategy": str,            # "åå‘" | "é †å‹¢" | "è§€æœ›"
                "reasoning": [str, ...],    # åˆ†æç†ç”±
                "risk_level": str,          # "é«˜" | "ä¸­" | "ä½"
                "timestamp": str
            }
    """
    logger.info("é–‹å§‹ç”¢ç”Ÿæƒ…ç·’äº¤æ˜“è¨Šè™Ÿ")

    signals = []
    confidence = 0.5
    reasoning = []

    # åˆ†æææ‡¼è²ªå©ªæŒ‡æ•¸
    fg_value = fear_greed_index.index_value
    if fg_value >= 80:
        signals.append("è³£å‡º")
        reasoning.append(f"ææ‡¼è²ªå©ªæŒ‡æ•¸éé«˜ ({fg_value:.0f})ï¼Œå¸‚å ´éç†±")
        confidence += 0.15
    elif fg_value <= 20:
        signals.append("è²·é€²")
        reasoning.append(f"ææ‡¼è²ªå©ªæŒ‡æ•¸éä½ ({fg_value:.0f})ï¼Œå¸‚å ´ææ…Œ")
        confidence += 0.15

    # åˆ†æè³‡é‡‘æµå‘
    flow_direction = money_flow.flow_direction
    if flow_direction == "æµå…¥":
        signals.append("è²·é€²")
        reasoning.append("è³‡é‡‘æŒçºŒæµå…¥ï¼Œå¤šæ–¹åŠ›é‡å¼·å‹")
        confidence += 0.1
    elif flow_direction == "æµå‡º":
        signals.append("è³£å‡º")
        reasoning.append("è³‡é‡‘æµå‡ºæ˜é¡¯ï¼Œç©ºæ–¹ä½”å„ª")
        confidence += 0.1

    # åˆ†ææ–°èæƒ…ç·’
    news_score = news_sentiment.sentiment_score
    if news_score > 50:
        signals.append("è²·é€²")
        reasoning.append(f"æ–°èæƒ…ç·’æ¥µåº¦æ­£é¢ ({news_score:.0f})")
        confidence += 0.05
    elif news_score < -50:
        signals.append("è³£å‡º")
        reasoning.append(f"æ–°èæƒ…ç·’æ¥µåº¦è² é¢ ({news_score:.0f})")
        confidence += 0.05

    # åˆ†æç¤¾ç¾¤æƒ…ç·’
    social_score = social_sentiment.sentiment_score
    if social_score > 50:
        signals.append("è²·é€²")
        reasoning.append(f"ç¤¾ç¾¤é«˜åº¦çœ‹å¥½ ({social_score:.0f})")
        confidence += 0.05
    elif social_score < -50:
        signals.append("è³£å‡º")
        reasoning.append(f"ç¤¾ç¾¤é«˜åº¦çœ‹å£ ({social_score:.0f})")
        confidence += 0.05

    logger.debug(f"è¨Šè™Ÿå½™ç¸½ | è²·é€²: {signals.count('è²·é€²')} | è³£å‡º: {signals.count('è³£å‡º')}")

    # æ±ºå®šæ•´é«”è¨Šè™Ÿ
    buy_count = signals.count("è²·é€²")
    sell_count = signals.count("è³£å‡º")

    if buy_count > sell_count and buy_count >= 2:
        overall_signal = "è²·é€²"
        strategy = "é †å‹¢" if fg_value < 60 else "åå‘"
    elif sell_count > buy_count and sell_count >= 2:
        overall_signal = "è³£å‡º"
        strategy = "é †å‹¢" if fg_value > 40 else "åå‘"
    else:
        overall_signal = "è§€æœ›"
        strategy = "è§€æœ›"

    # é¢¨éšªè©•ä¼°
    if confidence > 0.75:
        risk_level = "ä½"
    elif confidence > 0.60:
        risk_level = "ä¸­"
    else:
        risk_level = "é«˜"

    confidence = min(0.95, confidence)

    logger.info(
        f"æƒ…ç·’è¨Šè™Ÿç”¢ç”Ÿå®Œæˆ | è¨Šè™Ÿ: {overall_signal} | ç­–ç•¥: {strategy} | "
        f"ä¿¡å¿ƒåº¦: {confidence:.1%} | é¢¨éšª: {risk_level}"
    )

    return {
        "overall_signal": overall_signal,
        "confidence": confidence,
        "strategy": strategy,
        "reasoning": reasoning,
        "risk_level": risk_level,
        "timestamp": datetime.now().isoformat(),
    }


async def get_sentiment_agent(
    llm_model: LitellmModel = None,
    extra_headers: dict[str, str] = None,
    mcp_servers: list | None = None,
) -> Agent:
    """å‰µå»ºå¸‚å ´æƒ…ç·’åˆ†æ Agent

    Args:
        llm_model: ä½¿ç”¨çš„èªè¨€æ¨¡å‹å¯¦ä¾‹ (LitellmModel)ï¼Œå¦‚æœç‚º Noneï¼Œå‰‡ä½¿ç”¨é è¨­æ¨¡å‹
        extra_headers: é¡å¤–çš„ HTTP æ¨™é ­ï¼Œç”¨æ–¼æ¨¡å‹ API è«‹æ±‚
        mcp_servers: MCP servers å¯¦ä¾‹åˆ—è¡¨ï¼ˆMCPServerStdio å°è±¡ï¼‰ï¼Œå¾ TradingAgent å‚³å…¥

    Returns:
        Agent: é…ç½®å¥½çš„å¸‚å ´æƒ…ç·’åˆ†æ Agent

    Note:
        - ä¸ä½¿ç”¨ WebSearchTool å’Œ CodeInterpreterToolï¼ˆè¨—ç®¡å·¥å…·ä¸æ”¯æ´ ChatCompletions APIï¼‰
        - åªä½¿ç”¨è‡ªè¨‚å·¥å…·é€²è¡Œæƒ…ç·’åˆ†æ
        - Timeout ç”±ä¸» TradingAgent çš„ execution_timeout çµ±ä¸€æ§åˆ¶
        - Sub-agent ä½œç‚º Tool åŸ·è¡Œæ™‚æœƒå—åˆ°ä¸» Agent çš„ timeout é™åˆ¶
    """
    logger.info(f"get_sentiment_agent() called with model={llm_model}")

    logger.debug("Creating custom tools with function_tool")
    all_tools = [
        calculate_fear_greed_index,
        analyze_money_flow,
        analyze_news_sentiment,
        analyze_social_sentiment,
        generate_sentiment_signals,
    ]
    logger.debug(f"Total tools: {len(all_tools)}")

    logger.info(
        f"Creating Agent with model={llm_model}, mcp_servers={len(mcp_servers)}, tools={len(all_tools)}"
    )
    analyst = Agent(
        name="sentiment_analyst",
        instructions=sentiment_agent_instructions(),
        model=llm_model,
        mcp_servers=mcp_servers,
        tools=all_tools,
        model_settings=ModelSettings(
            tool_choice="required",
            max_completion_tokens=500,  # æ§åˆ¶å›ç­”é•·åº¦ï¼Œé¿å…éåº¦å†—é•·
            extra_headers=extra_headers if extra_headers else None,  # å‚³éé¡å¤–æ¨™é ­
        ),
    )
    logger.info("Sentiment Analyst Agent created successfully")

    return analyst
